{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "metadata": {
        "id": "Tg3dpsogXYSE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34009253-1724-468d-cc18-3c8323fddf46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 54.8 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "id": "E_MdpTlxXYKc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad859b11-a7f1-4ccd-9901-1c5115e1e717"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "id": "67tfpQ3-XUgj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "756f5fd3-0b5a-41bd-b4fb-42a26e32457b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6ydBP_ChTgV",
        "outputId": "6ef3bf68-eb22-4487-c4c6-5363d50033b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['PYTHONPATH'] += \"/content/drive/MyDrive/scFasterBERT/performer_pytorch\""
      ],
      "metadata": {
        "id": "bd1l6AJ_iQe9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install einops\n",
        "!pip install local_attention\n",
        "!pip install scanpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70BzUhTSiloq",
        "outputId": "f65863ef-bfc4-486d-a49e-9fc1d6eda6a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting einops\n",
            "  Downloading einops-0.8.0-py3-none-any.whl (43 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/43.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: einops\n",
            "Successfully installed einops-0.8.0\n",
            "Collecting local_attention\n",
            "  Downloading local_attention-1.9.1-py3-none-any.whl (8.2 kB)\n",
            "Requirement already satisfied: einops>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from local_attention) (0.8.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from local_attention) (2.2.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->local_attention) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->local_attention) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->local_attention) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->local_attention) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->local_attention) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->local_attention) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->local_attention)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->local_attention)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->local_attention)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->local_attention)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->local_attention)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->local_attention)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->local_attention)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->local_attention)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->local_attention)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch->local_attention)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->local_attention)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->local_attention) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->local_attention)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->local_attention) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->local_attention) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, local_attention\n",
            "Successfully installed local_attention-1.9.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105\n",
            "Collecting scanpy\n",
            "  Downloading scanpy-1.10.1-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting anndata>=0.8 (from scanpy)\n",
            "  Downloading anndata-0.10.7-py3-none-any.whl (122 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.4/122.4 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: h5py>=3.1 in /usr/local/lib/python3.10/dist-packages (from scanpy) (3.9.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from scanpy) (1.4.0)\n",
            "Collecting legacy-api-wrap>=1.4 (from scanpy)\n",
            "  Downloading legacy_api_wrap-1.4-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: matplotlib>=3.6 in /usr/local/lib/python3.10/dist-packages (from scanpy) (3.7.1)\n",
            "Requirement already satisfied: natsort in /usr/local/lib/python3.10/dist-packages (from scanpy) (8.4.0)\n",
            "Requirement already satisfied: networkx>=2.7 in /usr/local/lib/python3.10/dist-packages (from scanpy) (3.3)\n",
            "Requirement already satisfied: numba>=0.56 in /usr/local/lib/python3.10/dist-packages (from scanpy) (0.58.1)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.10/dist-packages (from scanpy) (1.25.2)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from scanpy) (24.0)\n",
            "Requirement already satisfied: pandas>=1.5 in /usr/local/lib/python3.10/dist-packages (from scanpy) (2.0.3)\n",
            "Requirement already satisfied: patsy in /usr/local/lib/python3.10/dist-packages (from scanpy) (0.5.6)\n",
            "Collecting pynndescent>=0.5 (from scanpy)\n",
            "  Downloading pynndescent-0.5.12-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.24 in /usr/local/lib/python3.10/dist-packages (from scanpy) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.8 in /usr/local/lib/python3.10/dist-packages (from scanpy) (1.11.4)\n",
            "Requirement already satisfied: seaborn>=0.13 in /usr/local/lib/python3.10/dist-packages (from scanpy) (0.13.1)\n",
            "Collecting session-info (from scanpy)\n",
            "  Downloading session_info-1.0.0.tar.gz (24 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: statsmodels>=0.13 in /usr/local/lib/python3.10/dist-packages (from scanpy) (0.14.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from scanpy) (4.66.2)\n",
            "Collecting umap-learn!=0.5.0,>=0.5 (from scanpy)\n",
            "  Downloading umap_learn-0.5.6-py3-none-any.whl (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.7/85.7 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting array-api-compat!=1.5,>1.4 (from anndata>=0.8->scanpy)\n",
            "  Downloading array_api_compat-1.6-py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anndata>=0.8->scanpy) (1.2.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->scanpy) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->scanpy) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->scanpy) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->scanpy) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->scanpy) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->scanpy) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->scanpy) (2.8.2)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.56->scanpy) (0.41.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.5->scanpy) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.5->scanpy) (2024.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24->scanpy) (3.4.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy->scanpy) (1.16.0)\n",
            "Collecting stdlib_list (from session-info->scanpy)\n",
            "  Downloading stdlib_list-0.10.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: session-info\n",
            "  Building wheel for session-info (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for session-info: filename=session_info-1.0.0-py3-none-any.whl size=8026 sha256=67bc6d2ea2e958aa8ecfe53de187bdc11493a23f06f7b993d641cdf5554d14f5\n",
            "  Stored in directory: /root/.cache/pip/wheels/6a/aa/b9/eb5d4031476ec10802795b97ccf937b9bd998d68a9b268765a\n",
            "Successfully built session-info\n",
            "Installing collected packages: array-api-compat, stdlib_list, legacy-api-wrap, session-info, pynndescent, anndata, umap-learn, scanpy\n",
            "Successfully installed anndata-0.10.7 array-api-compat-1.6 legacy-api-wrap-1.4 pynndescent-0.5.12 scanpy-1.10.1 session-info-1.0.0 stdlib_list-0.10.0 umap-learn-0.5.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WLddJJ5sXMln"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.insert(1, '/content/drive/MyDrive/scFasterBERT/performer_pytorch')\n",
        "sys.path.insert(2, '/content/drive/MyDrive/scFasterBERT/')\n",
        "import os\n",
        "import gc\n",
        "import argparse\n",
        "import json\n",
        "import random\n",
        "import math\n",
        "import random\n",
        "from functools import reduce\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import sparse\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.optim import Adam\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from performer_pytorch import PerformerLM\n",
        "import scanpy as sc\n",
        "import anndata as ad\n",
        "from utils import *\n",
        "import scipy.sparse\n",
        "import h5py\n",
        "from tqdm import tqdm\n",
        "from torch.utils.tensorboard import SummaryWriter"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Writer = SummaryWriter('./runs/scBERT_ours_pretrained')"
      ],
      "metadata": {
        "id": "7FBmaSkOffL-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Co1cwDfrXMlp"
      },
      "outputs": [],
      "source": [
        "data_path = '../data/panglao_human.h5ad'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4DGWuKE3XMlp"
      },
      "outputs": [],
      "source": [
        "SEED = 2021\n",
        "EPOCHS = 100\n",
        "BATCH_SIZE = 3\n",
        "GRADIENT_ACCUMULATION = 60\n",
        "LEARNING_RATE = 1e-4\n",
        "SEQ_LEN = 16907\n",
        "VALIDATE_EVERY = 1\n",
        "CLASS = 7\n",
        "MASK_PROB = 0.15\n",
        "REPLACE_PROB = 0.9\n",
        "RANDOM_TOKEN_PROB = 0.\n",
        "MASK_TOKEN_ID = CLASS - 1\n",
        "PAD_TOKEN_ID = CLASS - 1\n",
        "MASK_IGNORE_TOKEN_IDS = [0]\n",
        "POS_EMBED_USING = True\n",
        "\n",
        "model_name = 'panglao_pretrain_ours_1'\n",
        "ckpt_dir = './checkpoints/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-yZa70LXMlq",
        "outputId": "00bcb714-1e9e-4f1b-c911-6ec10b7a7b2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x79787910c810>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "torch.manual_seed(SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gowQVmRrXMlq"
      },
      "source": [
        "# Masking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wYyXZM4vXMlr"
      },
      "outputs": [],
      "source": [
        "# get the random prob matrix and True means smaller than prob threshold\n",
        "def prob_mask_like(t, prob):\n",
        "    return torch.zeros_like(t).float().uniform_(0, 1) < prob\n",
        "\n",
        "# get the mask matrix which cannot be masked\n",
        "def mask_with_tokens(t, token_ids):\n",
        "    init_no_mask = torch.full_like(t, False, dtype=torch.bool)\n",
        "    mask = reduce(lambda acc, el: acc | (t == el), token_ids, init_no_mask)\n",
        "    return mask\n",
        "\n",
        "def get_mask_subset_with_prob(mask, prob):\n",
        "    batch, seq_len, device = *mask.shape, mask.device\n",
        "    max_masked = math.ceil(prob * seq_len)      # num of mask of a single sequence in average\n",
        "    num_tokens = mask.sum(dim=-1, keepdim=True)     # num of pure tokens of each sequence except special tokens\n",
        "    mask_excess = torch.cat((torch.zeros(0), torch.arange(mask.size(-1)).repeat(mask.size(0)))).reshape(mask.size(0),mask.size(-1)).to(device)\n",
        "    mask_excess = (mask_excess >= (num_tokens * prob).ceil())        # only 15% of pure tokens can be masked\n",
        "    mask_excess = mask_excess[:, :max_masked]       # get difference between 15% of pure tokens and 15% of all tokens\n",
        "    rand = torch.rand((batch, seq_len), device=device).masked_fill(~mask, -1e9)     # rand (0-1) as prob, special token use -1e9\n",
        "    _, sampled_indices = rand.topk(max_masked, dim=-1)      # get index of topk prob to mask\n",
        "    sampled_indices = (sampled_indices + 1).masked_fill_(mask_excess, 0)        # delete difference of mask not pure\n",
        "    new_mask = torch.zeros((batch, seq_len + 1), device=device)     # get (batch, seq_len) shape zero matrix\n",
        "    new_mask.scatter_(-1, sampled_indices, 1)       # set masks in zero matrix as 1\n",
        "    return new_mask[:, 1:].bool()       # the final mask, True is mask\n",
        "\n",
        "def data_mask(data,\n",
        "    mask_prob = MASK_PROB,\n",
        "    replace_prob = REPLACE_PROB,\n",
        "    num_tokens = None,\n",
        "    random_token_prob = RANDOM_TOKEN_PROB,\n",
        "    mask_token_id = MASK_TOKEN_ID,\n",
        "    pad_token_id = PAD_TOKEN_ID,\n",
        "    mask_ignore_token_ids = MASK_IGNORE_TOKEN_IDS\n",
        "):\n",
        "    mask_ignore_token_ids = set([*mask_ignore_token_ids, pad_token_id])\n",
        "    # do not mask [pad] tokens, or any other tokens in the tokens designated to be excluded ([cls], [sep])\n",
        "    # also do not include these special tokens in the tokens chosen at random\n",
        "    no_mask = mask_with_tokens(data, mask_ignore_token_ids)   # ignore_token as True, will not be masked later\n",
        "    mask = get_mask_subset_with_prob(~no_mask, mask_prob)      # get the True/False mask matrix\n",
        "    # get mask indices\n",
        "    ## mask_indices = torch.nonzero(mask, as_tuple=True)   # get the index of mask(nonzero value of mask matrix)\n",
        "    # mask input with mask tokens with probability of `replace_prob` (keep tokens the same with probability 1 - replace_prob)\n",
        "    masked_input = data.clone().detach()\n",
        "    # if random token probability > 0 for mlm\n",
        "    if random_token_prob > 0:\n",
        "        assert num_tokens is not None, 'num_tokens keyword must be supplied when instantiating MLM if using random token replacement'\n",
        "        random_token_prob = prob_mask_like(data, random_token_prob)       # get the mask matrix of random token replace\n",
        "        random_tokens = torch.randint(0, num_tokens, data.shape, device=data.device)     # generate random token matrix with the same shape as in\n",
        "        random_no_mask = mask_with_tokens(random_tokens, mask_ignore_token_ids)        # not masked matrix for the random token matrix\n",
        "        random_token_prob &= ~random_no_mask        # get the pure mask matrix of random token replace\n",
        "        random_indices = torch.nonzero(random_token_prob, as_tuple=True)        # index of random token replace\n",
        "        masked_input[random_indices] = random_tokens[random_indices]        # replace some tokens by random token\n",
        "    # [mask] input\n",
        "    replace_prob = prob_mask_like(data, replace_prob)     # get the mask matrix of token being masked\n",
        "    masked_input = masked_input.masked_fill(mask * replace_prob, mask_token_id)        # get the data has been masked by mask_token\n",
        "    # mask out any tokens to padding tokens that were not originally going to be masked\n",
        "    labels = data.masked_fill(~mask, pad_token_id)        # the label of masked tokens\n",
        "    return masked_input, labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRs1LsQXXMls"
      },
      "source": [
        "# Dataset and Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DZBwDp-EXMls"
      },
      "outputs": [],
      "source": [
        "# total_samples = 1357593  # Replace with the actual total length of your dataset\n",
        "# train_ratio = 0.95\n",
        "\n",
        "# # Calculate the number of samples in each set\n",
        "# num_train_samples = int(total_samples * train_ratio)\n",
        "# num_valid_samples = total_samples - num_train_samples\n",
        "\n",
        "# # Generate indices for training and validation sets\n",
        "# train_indices = list(range(0, num_train_samples))\n",
        "# valid_indices = list(range(num_train_samples, total_samples))\n",
        "\n",
        "# print(\"Training indices:\", len(train_indices))\n",
        "# print(\"Validation indices:\", len(valid_indices))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cBmPZ4ypXMls"
      },
      "outputs": [],
      "source": [
        "# class SCDataset(Dataset):\n",
        "#     def __init__(self, file_path, indices):\n",
        "#         self.file_path = file_path\n",
        "#         self.data = sc.read_h5ad(data_path, backed='r')\n",
        "#         self.length = self.data.X.shape[0]\n",
        "#         self.indices = indices\n",
        "#         self.indices_len = len(self.indices)\n",
        "\n",
        "#     def __getitem__(self, index):\n",
        "#         rand_start = random.randint(0, self.indices_len-1)\n",
        "#         data = self.data.X[self.indices[rand_start]]\n",
        "#         # Convert sparse matrix row to dense if necessary\n",
        "#         if isinstance(data, scipy.sparse.csr_matrix):\n",
        "#             data = data.toarray().squeeze(0)\n",
        "#             # print(data)\n",
        "\n",
        "#         # Apply the same preprocessing as before\n",
        "#         data[data > (CLASS - 2)] = CLASS - 2\n",
        "#         data = torch.from_numpy(data).long()\n",
        "#         data = torch.cat((data, torch.tensor([0]))).to(device)\n",
        "#         return data\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return self.length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "igKC-308XMlt"
      },
      "outputs": [],
      "source": [
        "\n",
        "# train_dataset = SCDataset(data_path, train_indices)\n",
        "# val_dataset = SCDataset(data_path, valid_indices)\n",
        "\n",
        "# train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "# val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SCDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        super().__init__()\n",
        "        self.data = data\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        rand_start = random.randint(0, self.data.shape[0]-1)\n",
        "        full_seq = self.data[rand_start].toarray()[0]\n",
        "        full_seq[full_seq > (CLASS - 2)] = CLASS - 2\n",
        "        full_seq = torch.from_numpy(full_seq).long()\n",
        "        full_seq = torch.cat((full_seq, torch.tensor([0]))).to(device)\n",
        "        return full_seq\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data.shape[0]\n",
        "\n",
        "data = sc.read_h5ad('/content/drive/MyDrive/scFasterBERT/data/panglao_human.h5ad')\n",
        "data = data.X\n",
        "data_train, data_val = train_test_split(data, test_size=0.05,random_state=SEED)\n",
        "\n",
        "train_dataset = SCDataset(data_train)\n",
        "val_dataset = SCDataset(data_val)\n",
        "\n"
      ],
      "metadata": {
        "id": "2GBKtA0Dgup5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38e69046-9197-4909-b272-8b4538f7086a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/anndata/_core/anndata.py:1818: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
            "  utils.warn_names_duplicates(\"obs\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "id": "01qOE09-n3Gi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_qaL8bEXMlt"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V2xdhEylXMlt"
      },
      "outputs": [],
      "source": [
        "model = PerformerLM(\n",
        "    num_tokens = CLASS,\n",
        "    dim = 200,\n",
        "    depth = 6,\n",
        "    max_seq_len = SEQ_LEN,\n",
        "    heads = 10,\n",
        "    local_attn_heads = 0,\n",
        "    g2v_position_emb = POS_EMBED_USING\n",
        "    ).to(device)\n",
        "\n",
        "\n",
        "\n",
        "# optimizer\n",
        "optimizer = Adam(model.parameters(), lr=LEARNING_RATE)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ckpt = torch.load('/content/drive/MyDrive/scFasterBERT/panglao_pretrain.pth',map_location=torch.device('cpu'))\n",
        "model.load_state_dict(ckpt['model_state_dict'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88b_2cEA20yU",
        "outputId": "e5e8f3d1-79af-478c-bbfc-c7ea5d731deb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "quantized_model = nn.Sequential(\n",
        "    torch.quantization.QuantStub(),\n",
        "    model,\n",
        "    torch.quantization.DeQuantStub(),\n",
        ")"
      ],
      "metadata": {
        "id": "CasKoCAa4Ijw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GAQ8RY6p49aG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OLDLa74bXMlt"
      },
      "outputs": [],
      "source": [
        "loss_fn = nn.CrossEntropyLoss(ignore_index = PAD_TOKEN_ID, reduction='mean').to(device)\n",
        "softmax = nn.Softmax(dim=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HMeWW5JqXMlt"
      },
      "outputs": [],
      "source": [
        "for epoch in range(1, EPOCHS+1):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    cum_acc = 0.0\n",
        "    for index, data in tqdm(enumerate(train_loader)):\n",
        "        index += 1\n",
        "        data = data.to(device)\n",
        "        data, labels = data_mask(data)\n",
        "        if index % GRADIENT_ACCUMULATION != 0:\n",
        "            logits = model(data)\n",
        "            loss = loss_fn(logits.transpose(1, 2), labels) / GRADIENT_ACCUMULATION\n",
        "            loss.backward()\n",
        "        else:\n",
        "            logits = model(data)\n",
        "            loss = loss_fn(logits.transpose(1, 2), labels) / GRADIENT_ACCUMULATION\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), int(1e2))\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "        running_loss += loss.item()\n",
        "        final = softmax(logits)[..., 1:-1]\n",
        "        final = final.argmax(dim=-1) + 1\n",
        "        pred_num = (labels != PAD_TOKEN_ID).sum(dim=-1)\n",
        "        correct_num = ((labels != PAD_TOKEN_ID) * (final == labels)).sum(dim=-1)\n",
        "        cum_acc += torch.true_divide(correct_num, pred_num).mean().item()\n",
        "    epoch_loss = running_loss / index\n",
        "    epoch_acc = 100 * cum_acc / index\n",
        "    print(f'    ==  Epoch: {epoch} | Training Loss: {epoch_loss:.6f} | Accuracy: {epoch_acc:6.4f}%  ==')\n",
        "    Writer.add_scalar('Training loss', epoch_loss, epoch)\n",
        "    Writer.add_scalar('Training accuracy',epoch_acc, epoch)\n",
        "\n",
        "    if epoch % VALIDATE_EVERY == 0:\n",
        "        model.eval()\n",
        "        running_loss = 0.0\n",
        "        predictions = []\n",
        "        truths = []\n",
        "        with torch.no_grad():\n",
        "            for index, data in tqdm(enumerate(val_loader)):\n",
        "                index += 1\n",
        "                data = data.to(device)\n",
        "                data, labels = data_mask(data)\n",
        "                logits = model(data)\n",
        "                loss = loss_fn(logits.transpose(1, 2), labels)\n",
        "                running_loss += loss.item()\n",
        "                softmax = nn.Softmax(dim=-1)\n",
        "                final = softmax(logits)[..., 1:-1]\n",
        "                final = final.argmax(dim=-1) + 1\n",
        "                predictions.append(final)\n",
        "                truths.append(labels)\n",
        "        val_loss = running_loss / index\n",
        "        correct_num = ((torch.cat(truths, dim=0) != PAD_TOKEN_ID) * (torch.cat(predictions, dim=0) == torch.cat(truths, dim=0))).sum().item()\n",
        "        val_num = (torch.cat(truths, dim=0) != PAD_TOKEN_ID).sum().item()\n",
        "        val_acc = 100 * correct_num / val_num\n",
        "        print(f'    ==  Epoch: {epoch} | Validation Loss: {val_loss:.6f} | Accuracy: {val_acc:6.4f}%  ==')\n",
        "        Writer.add_scalar('Valid loss', val_loss, epoch)\n",
        "        Writer.add_scalar('Valid accuracy',val_acc, epoch)\n",
        "\n",
        "    # save_ckpt(i, model, optimizerepoch_loss, model_name, ckpt_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_9bfv1VTXMlu"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}