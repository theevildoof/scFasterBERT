{"cells":[{"cell_type":"code","source":["from psutil import virtual_memory\n","ram_gb = virtual_memory().total / 1e9\n","print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n","\n","if ram_gb < 20:\n","  print('Not using a high-RAM runtime')\n","else:\n","  print('You are using a high-RAM runtime!')"],"metadata":{"id":"Tg3dpsogXYSE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714634746213,"user_tz":-330,"elapsed":10,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}},"outputId":"a3d3f759-3502-4495-857a-8915d9ca982e"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Your runtime has 13.6 gigabytes of available RAM\n","\n","Not using a high-RAM runtime\n"]}]},{"cell_type":"code","source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)"],"metadata":{"id":"E_MdpTlxXYKc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714634746213,"user_tz":-330,"elapsed":8,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}},"outputId":"d91a17f7-4cd9-493b-f992-5d07bb2b53c8"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/bin/bash: line 1: nvidia-smi: command not found\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"metadata":{"id":"67tfpQ3-XUgj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714634771267,"user_tz":-330,"elapsed":25058,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}},"outputId":"feb9ba4e-0675-433e-fb77-be3233453dd8"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}]},{"cell_type":"code","source":["ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w6ydBP_ChTgV","executionInfo":{"status":"ok","timestamp":1714634771858,"user_tz":-330,"elapsed":594,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}},"outputId":"4b771a87-d69e-46be-9f5c-a2071dd11c5a"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[0m\u001b[01;34mdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"]}]},{"cell_type":"code","source":["import os\n","os.environ['PYTHONPATH'] += \"/content/drive/MyDrive/scFasterBERT/performer_pytorch\""],"metadata":{"id":"bd1l6AJ_iQe9","executionInfo":{"status":"ok","timestamp":1714634771858,"user_tz":-330,"elapsed":3,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["!pip install einops\n","!pip install local_attention\n","!pip install scanpy"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"70BzUhTSiloq","executionInfo":{"status":"ok","timestamp":1714634871254,"user_tz":-330,"elapsed":99399,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}},"outputId":"538ffbae-64dc-4767-cf7b-f58c33056e59"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting einops\n","  Downloading einops-0.8.0-py3-none-any.whl (43 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m672.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: einops\n","Successfully installed einops-0.8.0\n","Collecting local_attention\n","  Downloading local_attention-1.9.1-py3-none-any.whl (8.2 kB)\n","Requirement already satisfied: einops>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from local_attention) (0.8.0)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from local_attention) (2.2.1+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->local_attention) (3.13.4)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->local_attention) (4.11.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->local_attention) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->local_attention) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->local_attention) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->local_attention) (2023.6.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->local_attention)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->local_attention)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->local_attention)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->local_attention)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->local_attention)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->local_attention)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch->local_attention)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->local_attention)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->local_attention)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.19.3 (from torch->local_attention)\n","  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch->local_attention)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->local_attention) (2.2.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->local_attention)\n","  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->local_attention) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->local_attention) (1.3.0)\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, local_attention\n","Successfully installed local_attention-1.9.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105\n","Collecting scanpy\n","  Downloading scanpy-1.10.1-py3-none-any.whl (2.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting anndata>=0.8 (from scanpy)\n","  Downloading anndata-0.10.7-py3-none-any.whl (122 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.4/122.4 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: h5py>=3.1 in /usr/local/lib/python3.10/dist-packages (from scanpy) (3.9.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from scanpy) (1.4.0)\n","Collecting legacy-api-wrap>=1.4 (from scanpy)\n","  Downloading legacy_api_wrap-1.4-py3-none-any.whl (15 kB)\n","Requirement already satisfied: matplotlib>=3.6 in /usr/local/lib/python3.10/dist-packages (from scanpy) (3.7.1)\n","Requirement already satisfied: natsort in /usr/local/lib/python3.10/dist-packages (from scanpy) (8.4.0)\n","Requirement already satisfied: networkx>=2.7 in /usr/local/lib/python3.10/dist-packages (from scanpy) (3.3)\n","Requirement already satisfied: numba>=0.56 in /usr/local/lib/python3.10/dist-packages (from scanpy) (0.58.1)\n","Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.10/dist-packages (from scanpy) (1.25.2)\n","Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from scanpy) (24.0)\n","Requirement already satisfied: pandas>=1.5 in /usr/local/lib/python3.10/dist-packages (from scanpy) (2.0.3)\n","Requirement already satisfied: patsy in /usr/local/lib/python3.10/dist-packages (from scanpy) (0.5.6)\n","Collecting pynndescent>=0.5 (from scanpy)\n","  Downloading pynndescent-0.5.12-py3-none-any.whl (56 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scikit-learn>=0.24 in /usr/local/lib/python3.10/dist-packages (from scanpy) (1.2.2)\n","Requirement already satisfied: scipy>=1.8 in /usr/local/lib/python3.10/dist-packages (from scanpy) (1.11.4)\n","Requirement already satisfied: seaborn>=0.13 in /usr/local/lib/python3.10/dist-packages (from scanpy) (0.13.1)\n","Collecting session-info (from scanpy)\n","  Downloading session_info-1.0.0.tar.gz (24 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: statsmodels>=0.13 in /usr/local/lib/python3.10/dist-packages (from scanpy) (0.14.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from scanpy) (4.66.2)\n","Collecting umap-learn!=0.5.0,>=0.5 (from scanpy)\n","  Downloading umap_learn-0.5.6-py3-none-any.whl (85 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.7/85.7 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting array-api-compat!=1.5,>1.4 (from anndata>=0.8->scanpy)\n","  Downloading array_api_compat-1.6-py3-none-any.whl (36 kB)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anndata>=0.8->scanpy) (1.2.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->scanpy) (1.2.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->scanpy) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->scanpy) (4.51.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->scanpy) (1.4.5)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->scanpy) (9.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->scanpy) (3.1.2)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->scanpy) (2.8.2)\n","Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.56->scanpy) (0.41.1)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.5->scanpy) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.5->scanpy) (2024.1)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24->scanpy) (3.4.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy->scanpy) (1.16.0)\n","Collecting stdlib_list (from session-info->scanpy)\n","  Downloading stdlib_list-0.10.0-py3-none-any.whl (79 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: session-info\n","  Building wheel for session-info (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for session-info: filename=session_info-1.0.0-py3-none-any.whl size=8026 sha256=30046cbed1be7c14dd2ad790ea29036451d7dd6acd5adfaf64a1a7b39e358857\n","  Stored in directory: /root/.cache/pip/wheels/6a/aa/b9/eb5d4031476ec10802795b97ccf937b9bd998d68a9b268765a\n","Successfully built session-info\n","Installing collected packages: array-api-compat, stdlib_list, legacy-api-wrap, session-info, pynndescent, anndata, umap-learn, scanpy\n","Successfully installed anndata-0.10.7 array-api-compat-1.6 legacy-api-wrap-1.4 pynndescent-0.5.12 scanpy-1.10.1 session-info-1.0.0 stdlib_list-0.10.0 umap-learn-0.5.6\n"]}]},{"cell_type":"code","execution_count":7,"metadata":{"id":"WLddJJ5sXMln","executionInfo":{"status":"ok","timestamp":1714634888629,"user_tz":-330,"elapsed":17380,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}}},"outputs":[],"source":["import sys\n","sys.path.insert(1, '/content/drive/MyDrive/scFasterBERT/performer_pytorch')\n","sys.path.insert(2, '/content/drive/MyDrive/scFasterBERT/')\n","\n","import os\n","import gc\n","import argparse\n","import json\n","import random\n","import math\n","import random\n","from functools import reduce\n","import numpy as np\n","import pandas as pd\n","from scipy import sparse\n","from sklearn.model_selection import train_test_split\n","import torch\n","from torch import nn\n","from torch.optim import Adam\n","from torch.nn import functional as F\n","from torch.utils.data import DataLoader, Dataset\n","from performer_pytorch import PerformerLM\n","import scanpy as sc\n","import anndata as ad\n","from utils import *\n","import scipy.sparse\n","import h5py\n","from tqdm import tqdm\n","from torch.utils.tensorboard import SummaryWriter"]},{"cell_type":"code","source":["Writer = SummaryWriter('./runs/Distill_scBERT_pretrained')"],"metadata":{"id":"7FBmaSkOffL-","executionInfo":{"status":"ok","timestamp":1714634888629,"user_tz":-330,"elapsed":14,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","execution_count":9,"metadata":{"id":"Co1cwDfrXMlp","executionInfo":{"status":"ok","timestamp":1714634888629,"user_tz":-330,"elapsed":13,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}}},"outputs":[],"source":["data_path = '../data/panglao_human.h5ad'"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"4DGWuKE3XMlp","executionInfo":{"status":"ok","timestamp":1714634888629,"user_tz":-330,"elapsed":13,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}}},"outputs":[],"source":["SEED = 2021\n","EPOCHS = 100\n","BATCH_SIZE = 1\n","GRADIENT_ACCUMULATION = 60\n","LEARNING_RATE = 1e-4\n","SEQ_LEN = 16907\n","VALIDATE_EVERY = 1\n","CLASS = 7\n","MASK_PROB = 0.15\n","REPLACE_PROB = 0.9\n","RANDOM_TOKEN_PROB = 0.\n","MASK_TOKEN_ID = CLASS - 1\n","PAD_TOKEN_ID = CLASS - 1\n","MASK_IGNORE_TOKEN_IDS = [0]\n","POS_EMBED_USING = True\n","\n","model_name = 'panglao_pretrain_ours_1'\n","ckpt_dir = './checkpoints/'"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"K-yZa70LXMlq","outputId":"20704d4a-2e95-496e-bf92-aa60acc6581b","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714634889233,"user_tz":-330,"elapsed":617,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x791e1a368130>"]},"metadata":{},"execution_count":11}],"source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","torch.manual_seed(SEED)"]},{"cell_type":"code","source":["torch.cuda.empty_cache()"],"metadata":{"id":"w2KRxJgAAkRQ","executionInfo":{"status":"ok","timestamp":1714634889233,"user_tz":-330,"elapsed":4,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gowQVmRrXMlq"},"source":["# Masking"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"wYyXZM4vXMlr","executionInfo":{"status":"ok","timestamp":1714634889233,"user_tz":-330,"elapsed":4,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}}},"outputs":[],"source":["# get the random prob matrix and True means smaller than prob threshold\n","def prob_mask_like(t, prob):\n","    return torch.zeros_like(t).float().uniform_(0, 1) < prob\n","\n","# get the mask matrix which cannot be masked\n","def mask_with_tokens(t, token_ids):\n","    init_no_mask = torch.full_like(t, False, dtype=torch.bool)\n","    mask = reduce(lambda acc, el: acc | (t == el), token_ids, init_no_mask)\n","    return mask\n","\n","def get_mask_subset_with_prob(mask, prob):\n","    batch, seq_len, device = *mask.shape, mask.device\n","    max_masked = math.ceil(prob * seq_len)      # num of mask of a single sequence in average\n","    num_tokens = mask.sum(dim=-1, keepdim=True)     # num of pure tokens of each sequence except special tokens\n","    mask_excess = torch.cat((torch.zeros(0), torch.arange(mask.size(-1)).repeat(mask.size(0)))).reshape(mask.size(0),mask.size(-1)).to(device)\n","    mask_excess = (mask_excess >= (num_tokens * prob).ceil())        # only 15% of pure tokens can be masked\n","    mask_excess = mask_excess[:, :max_masked]       # get difference between 15% of pure tokens and 15% of all tokens\n","    rand = torch.rand((batch, seq_len), device=device).masked_fill(~mask, -1e9)     # rand (0-1) as prob, special token use -1e9\n","    _, sampled_indices = rand.topk(max_masked, dim=-1)      # get index of topk prob to mask\n","    sampled_indices = (sampled_indices + 1).masked_fill_(mask_excess, 0)        # delete difference of mask not pure\n","    new_mask = torch.zeros((batch, seq_len + 1), device=device)     # get (batch, seq_len) shape zero matrix\n","    new_mask.scatter_(-1, sampled_indices, 1)       # set masks in zero matrix as 1\n","    return new_mask[:, 1:].bool()       # the final mask, True is mask\n","\n","def data_mask(data,\n","    mask_prob = MASK_PROB,\n","    replace_prob = REPLACE_PROB,\n","    num_tokens = None,\n","    random_token_prob = RANDOM_TOKEN_PROB,\n","    mask_token_id = MASK_TOKEN_ID,\n","    pad_token_id = PAD_TOKEN_ID,\n","    mask_ignore_token_ids = MASK_IGNORE_TOKEN_IDS\n","):\n","    mask_ignore_token_ids = set([*mask_ignore_token_ids, pad_token_id])\n","    # do not mask [pad] tokens, or any other tokens in the tokens designated to be excluded ([cls], [sep])\n","    # also do not include these special tokens in the tokens chosen at random\n","    no_mask = mask_with_tokens(data, mask_ignore_token_ids)   # ignore_token as True, will not be masked later\n","    mask = get_mask_subset_with_prob(~no_mask, mask_prob)      # get the True/False mask matrix\n","    # get mask indices\n","    ## mask_indices = torch.nonzero(mask, as_tuple=True)   # get the index of mask(nonzero value of mask matrix)\n","    # mask input with mask tokens with probability of `replace_prob` (keep tokens the same with probability 1 - replace_prob)\n","    masked_input = data.clone().detach()\n","    # if random token probability > 0 for mlm\n","    if random_token_prob > 0:\n","        assert num_tokens is not None, 'num_tokens keyword must be supplied when instantiating MLM if using random token replacement'\n","        random_token_prob = prob_mask_like(data, random_token_prob)       # get the mask matrix of random token replace\n","        random_tokens = torch.randint(0, num_tokens, data.shape, device=data.device)     # generate random token matrix with the same shape as in\n","        random_no_mask = mask_with_tokens(random_tokens, mask_ignore_token_ids)        # not masked matrix for the random token matrix\n","        random_token_prob &= ~random_no_mask        # get the pure mask matrix of random token replace\n","        random_indices = torch.nonzero(random_token_prob, as_tuple=True)        # index of random token replace\n","        masked_input[random_indices] = random_tokens[random_indices]        # replace some tokens by random token\n","    # [mask] input\n","    replace_prob = prob_mask_like(data, replace_prob)     # get the mask matrix of token being masked\n","    masked_input = masked_input.masked_fill(mask * replace_prob, mask_token_id)        # get the data has been masked by mask_token\n","    # mask out any tokens to padding tokens that were not originally going to be masked\n","    labels = data.masked_fill(~mask, pad_token_id)        # the label of masked tokens\n","    return masked_input, labels"]},{"cell_type":"markdown","metadata":{"id":"vRs1LsQXXMls"},"source":["# Dataset and Dataloader"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DZBwDp-EXMls"},"outputs":[],"source":["# total_samples = 1357593  # Replace with the actual total length of your dataset\n","# train_ratio = 0.95\n","\n","# # Calculate the number of samples in each set\n","# num_train_samples = int(total_samples * train_ratio)\n","# num_valid_samples = total_samples - num_train_samples\n","\n","# # Generate indices for training and validation sets\n","# train_indices = list(range(0, num_train_samples))\n","# valid_indices = list(range(num_train_samples, total_samples))\n","\n","# print(\"Training indices:\", len(train_indices))\n","# print(\"Validation indices:\", len(valid_indices))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cBmPZ4ypXMls"},"outputs":[],"source":["# class SCDataset(Dataset):\n","#     def __init__(self, file_path, indices):\n","#         self.file_path = file_path\n","#         self.data = sc.read_h5ad(data_path, backed='r')\n","#         self.length = self.data.X.shape[0]\n","#         self.indices = indices\n","#         self.indices_len = len(self.indices)\n","\n","#     def __getitem__(self, index):\n","#         rand_start = random.randint(0, self.indices_len-1)\n","#         data = self.data.X[self.indices[rand_start]]\n","#         # Convert sparse matrix row to dense if necessary\n","#         if isinstance(data, scipy.sparse.csr_matrix):\n","#             data = data.toarray().squeeze(0)\n","#             # print(data)\n","\n","#         # Apply the same preprocessing as before\n","#         data[data > (CLASS - 2)] = CLASS - 2\n","#         data = torch.from_numpy(data).long()\n","#         data = torch.cat((data, torch.tensor([0]))).to(device)\n","#         return data\n","\n","#     def __len__(self):\n","#         return self.length"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"igKC-308XMlt"},"outputs":[],"source":["\n","# train_dataset = SCDataset(data_path, train_indices)\n","# val_dataset = SCDataset(data_path, valid_indices)\n","\n","# train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n","# val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)"]},{"cell_type":"markdown","source":["# For higher ram"],"metadata":{"id":"Atz4OMQOE-0r"}},{"cell_type":"code","source":["class SCDataset(Dataset):\n","    def __init__(self, data):\n","        super().__init__()\n","        self.data = data\n","\n","    def __getitem__(self, index):\n","        rand_start = random.randint(0, self.data.shape[0]-1)\n","        full_seq = self.data[rand_start].toarray()[0]\n","        full_seq[full_seq > (CLASS - 2)] = CLASS - 2\n","        full_seq = torch.from_numpy(full_seq).long()\n","        full_seq = torch.cat((full_seq, torch.tensor([0]))).to(device)\n","        return full_seq\n","\n","    def __len__(self):\n","        return self.data.shape[0]\n","\n","data = sc.read_h5ad('/content/drive/MyDrive/scFasterBERT/data/panglao_human.h5ad')\n","data = data.X\n","data_train, data_val = train_test_split(data, test_size=0.3,random_state=SEED)\n","\n","train_dataset = SCDataset(data_train)\n","val_dataset = SCDataset(data_val)\n","\n"],"metadata":{"id":"2GBKtA0Dgup5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714582572025,"user_tz":-330,"elapsed":18524,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}},"outputId":"408e909f-bfa0-4661-fa38-c715109f9799"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/anndata/_core/anndata.py:1818: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n","  utils.warn_names_duplicates(\"obs\")\n"]}]},{"cell_type":"code","source":["train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE)\n","val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)"],"metadata":{"id":"01qOE09-n3Gi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"k_qaL8bEXMlt"},"source":["# Model"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"V2xdhEylXMlt","outputId":"188def06-f92c-4fdb-9ee8-95df5c66e022","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714634892030,"user_tz":-330,"elapsed":2801,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["/content/drive/MyDrive/scFasterBERT/performer_pytorch/performer_pytorch.py:115: UserWarning: torch.qr is deprecated in favor of torch.linalg.qr and will be removed in a future PyTorch release.\n","The boolean parameter 'some' has been replaced with a string parameter 'mode'.\n","Q, R = torch.qr(A, some)\n","should be replaced with\n","Q, R = torch.linalg.qr(A, 'reduced' if some else 'complete') (Triggered internally at ../aten/src/ATen/native/BatchLinearAlgebra.cpp:2426.)\n","  q, r = torch.qr(unstructured_block.cpu(), some = True)\n"]}],"source":["teacher_model = PerformerLM(\n","    num_tokens = CLASS,\n","    dim = 200,\n","    depth = 6,\n","    max_seq_len = SEQ_LEN,\n","    heads = 10,\n","    local_attn_heads = 0,\n","    g2v_position_emb = POS_EMBED_USING\n",").to(device)\n","\n","# optimizer\n"]},{"cell_type":"code","source":["ckpt = torch.load('/content/drive/MyDrive/scFasterBERT/panglao_pretrain.pth',map_location=torch.device('cpu'))\n","teacher_model.load_state_dict(ckpt['model_state_dict'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NrIKDu89CHDO","executionInfo":{"status":"ok","timestamp":1714582572666,"user_tz":-330,"elapsed":650,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}},"outputId":"bc8c79d7-ac75-4ebb-afdc-65b623b1767b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OLDLa74bXMlt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714582572666,"user_tz":-330,"elapsed":8,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}},"outputId":"0c9d56cc-3be5-412b-866e-f030561f6949"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['token_emb.weight',\n"," 'pos_emb.emb.weight',\n"," 'performer.calls_since_last_redraw',\n"," 'performer.net.layers.0.0.norm.weight',\n"," 'performer.net.layers.0.0.norm.bias',\n"," 'performer.net.layers.0.0.fn.fast_attention.projection_matrix',\n"," 'performer.net.layers.0.0.fn.to_q.weight',\n"," 'performer.net.layers.0.0.fn.to_k.weight',\n"," 'performer.net.layers.0.0.fn.to_v.weight',\n"," 'performer.net.layers.0.0.fn.to_out.weight',\n"," 'performer.net.layers.0.0.fn.to_out.bias',\n"," 'performer.net.layers.0.1.norm.weight',\n"," 'performer.net.layers.0.1.norm.bias',\n"," 'performer.net.layers.0.1.fn.fn.w1.weight',\n"," 'performer.net.layers.0.1.fn.fn.w1.bias',\n"," 'performer.net.layers.0.1.fn.fn.w2.weight',\n"," 'performer.net.layers.0.1.fn.fn.w2.bias',\n"," 'performer.net.layers.1.0.norm.weight',\n"," 'performer.net.layers.1.0.norm.bias',\n"," 'performer.net.layers.1.0.fn.fast_attention.projection_matrix',\n"," 'performer.net.layers.1.0.fn.to_q.weight',\n"," 'performer.net.layers.1.0.fn.to_k.weight',\n"," 'performer.net.layers.1.0.fn.to_v.weight',\n"," 'performer.net.layers.1.0.fn.to_out.weight',\n"," 'performer.net.layers.1.0.fn.to_out.bias',\n"," 'performer.net.layers.1.1.norm.weight',\n"," 'performer.net.layers.1.1.norm.bias',\n"," 'performer.net.layers.1.1.fn.fn.w1.weight',\n"," 'performer.net.layers.1.1.fn.fn.w1.bias',\n"," 'performer.net.layers.1.1.fn.fn.w2.weight',\n"," 'performer.net.layers.1.1.fn.fn.w2.bias',\n"," 'performer.net.layers.2.0.norm.weight',\n"," 'performer.net.layers.2.0.norm.bias',\n"," 'performer.net.layers.2.0.fn.fast_attention.projection_matrix',\n"," 'performer.net.layers.2.0.fn.to_q.weight',\n"," 'performer.net.layers.2.0.fn.to_k.weight',\n"," 'performer.net.layers.2.0.fn.to_v.weight',\n"," 'performer.net.layers.2.0.fn.to_out.weight',\n"," 'performer.net.layers.2.0.fn.to_out.bias',\n"," 'performer.net.layers.2.1.norm.weight',\n"," 'performer.net.layers.2.1.norm.bias',\n"," 'performer.net.layers.2.1.fn.fn.w1.weight',\n"," 'performer.net.layers.2.1.fn.fn.w1.bias',\n"," 'performer.net.layers.2.1.fn.fn.w2.weight',\n"," 'performer.net.layers.2.1.fn.fn.w2.bias',\n"," 'performer.net.layers.3.0.norm.weight',\n"," 'performer.net.layers.3.0.norm.bias',\n"," 'performer.net.layers.3.0.fn.fast_attention.projection_matrix',\n"," 'performer.net.layers.3.0.fn.to_q.weight',\n"," 'performer.net.layers.3.0.fn.to_k.weight',\n"," 'performer.net.layers.3.0.fn.to_v.weight',\n"," 'performer.net.layers.3.0.fn.to_out.weight',\n"," 'performer.net.layers.3.0.fn.to_out.bias',\n"," 'performer.net.layers.3.1.norm.weight',\n"," 'performer.net.layers.3.1.norm.bias',\n"," 'performer.net.layers.3.1.fn.fn.w1.weight',\n"," 'performer.net.layers.3.1.fn.fn.w1.bias',\n"," 'performer.net.layers.3.1.fn.fn.w2.weight',\n"," 'performer.net.layers.3.1.fn.fn.w2.bias',\n"," 'performer.net.layers.4.0.norm.weight',\n"," 'performer.net.layers.4.0.norm.bias',\n"," 'performer.net.layers.4.0.fn.fast_attention.projection_matrix',\n"," 'performer.net.layers.4.0.fn.to_q.weight',\n"," 'performer.net.layers.4.0.fn.to_k.weight',\n"," 'performer.net.layers.4.0.fn.to_v.weight',\n"," 'performer.net.layers.4.0.fn.to_out.weight',\n"," 'performer.net.layers.4.0.fn.to_out.bias',\n"," 'performer.net.layers.4.1.norm.weight',\n"," 'performer.net.layers.4.1.norm.bias',\n"," 'performer.net.layers.4.1.fn.fn.w1.weight',\n"," 'performer.net.layers.4.1.fn.fn.w1.bias',\n"," 'performer.net.layers.4.1.fn.fn.w2.weight',\n"," 'performer.net.layers.4.1.fn.fn.w2.bias',\n"," 'performer.net.layers.5.0.norm.weight',\n"," 'performer.net.layers.5.0.norm.bias',\n"," 'performer.net.layers.5.0.fn.fast_attention.projection_matrix',\n"," 'performer.net.layers.5.0.fn.to_q.weight',\n"," 'performer.net.layers.5.0.fn.to_k.weight',\n"," 'performer.net.layers.5.0.fn.to_v.weight',\n"," 'performer.net.layers.5.0.fn.to_out.weight',\n"," 'performer.net.layers.5.0.fn.to_out.bias',\n"," 'performer.net.layers.5.1.norm.weight',\n"," 'performer.net.layers.5.1.norm.bias',\n"," 'performer.net.layers.5.1.fn.fn.w1.weight',\n"," 'performer.net.layers.5.1.fn.fn.w1.bias',\n"," 'performer.net.layers.5.1.fn.fn.w2.weight',\n"," 'performer.net.layers.5.1.fn.fn.w2.bias',\n"," 'norm.weight',\n"," 'norm.bias',\n"," 'to_out.weight',\n"," 'to_out.bias']"]},"metadata":{},"execution_count":21}],"source":["list(ckpt['model_state_dict'].keys())"]},{"cell_type":"code","source":["student_model = PerformerLM(\n","    num_tokens = CLASS,\n","    dim = 200,\n","    depth = 3,\n","    max_seq_len = SEQ_LEN,\n","    heads = 10,\n","    local_attn_heads = 0,\n","    g2v_position_emb = POS_EMBED_USING\n",").to(device)\n","\n","state_dict_student = student_model.state_dict()"],"metadata":{"id":"aOQ-F90DCJAn","executionInfo":{"status":"ok","timestamp":1714634892031,"user_tz":-330,"elapsed":3,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["list(state_dict_student)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gv1dVGf9CI63","executionInfo":{"status":"ok","timestamp":1714582572666,"user_tz":-330,"elapsed":7,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}},"outputId":"b9983d2c-de06-4946-b0c2-913d645880b7"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['token_emb.weight',\n"," 'pos_emb.emb.weight',\n"," 'performer.calls_since_last_redraw',\n"," 'performer.net.layers.0.0.norm.weight',\n"," 'performer.net.layers.0.0.norm.bias',\n"," 'performer.net.layers.0.0.fn.fast_attention.projection_matrix',\n"," 'performer.net.layers.0.0.fn.to_q.weight',\n"," 'performer.net.layers.0.0.fn.to_k.weight',\n"," 'performer.net.layers.0.0.fn.to_v.weight',\n"," 'performer.net.layers.0.0.fn.to_out.weight',\n"," 'performer.net.layers.0.0.fn.to_out.bias',\n"," 'performer.net.layers.0.1.norm.weight',\n"," 'performer.net.layers.0.1.norm.bias',\n"," 'performer.net.layers.0.1.fn.fn.w1.weight',\n"," 'performer.net.layers.0.1.fn.fn.w1.bias',\n"," 'performer.net.layers.0.1.fn.fn.w2.weight',\n"," 'performer.net.layers.0.1.fn.fn.w2.bias',\n"," 'performer.net.layers.1.0.norm.weight',\n"," 'performer.net.layers.1.0.norm.bias',\n"," 'performer.net.layers.1.0.fn.fast_attention.projection_matrix',\n"," 'performer.net.layers.1.0.fn.to_q.weight',\n"," 'performer.net.layers.1.0.fn.to_k.weight',\n"," 'performer.net.layers.1.0.fn.to_v.weight',\n"," 'performer.net.layers.1.0.fn.to_out.weight',\n"," 'performer.net.layers.1.0.fn.to_out.bias',\n"," 'performer.net.layers.1.1.norm.weight',\n"," 'performer.net.layers.1.1.norm.bias',\n"," 'performer.net.layers.1.1.fn.fn.w1.weight',\n"," 'performer.net.layers.1.1.fn.fn.w1.bias',\n"," 'performer.net.layers.1.1.fn.fn.w2.weight',\n"," 'performer.net.layers.1.1.fn.fn.w2.bias',\n"," 'performer.net.layers.2.0.norm.weight',\n"," 'performer.net.layers.2.0.norm.bias',\n"," 'performer.net.layers.2.0.fn.fast_attention.projection_matrix',\n"," 'performer.net.layers.2.0.fn.to_q.weight',\n"," 'performer.net.layers.2.0.fn.to_k.weight',\n"," 'performer.net.layers.2.0.fn.to_v.weight',\n"," 'performer.net.layers.2.0.fn.to_out.weight',\n"," 'performer.net.layers.2.0.fn.to_out.bias',\n"," 'performer.net.layers.2.1.norm.weight',\n"," 'performer.net.layers.2.1.norm.bias',\n"," 'performer.net.layers.2.1.fn.fn.w1.weight',\n"," 'performer.net.layers.2.1.fn.fn.w1.bias',\n"," 'performer.net.layers.2.1.fn.fn.w2.weight',\n"," 'performer.net.layers.2.1.fn.fn.w2.bias',\n"," 'norm.weight',\n"," 'norm.bias',\n"," 'to_out.weight',\n"," 'to_out.bias']"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["state_dict_student['token_emb.weight']=ckpt['model_state_dict']['token_emb.weight']\n","state_dict_student['pos_emb.emb.weight']=ckpt['model_state_dict']['pos_emb.emb.weight']\n","state_dict_student['performer.calls_since_last_redraw']=ckpt['model_state_dict']['performer.calls_since_last_redraw']\n","state_dict_student['performer.net.layers.0.0.norm.weight']=ckpt['model_state_dict']['performer.net.layers.0.0.norm.weight']\n","state_dict_student['performer.net.layers.0.0.norm.bias']=ckpt['model_state_dict']['performer.net.layers.0.0.norm.bias']\n","state_dict_student['performer.net.layers.0.0.fn.fast_attention.projection_matrix']=ckpt['model_state_dict']['performer.net.layers.0.0.fn.fast_attention.projection_matrix']\n","state_dict_student['performer.net.layers.0.0.fn.to_q.weight']=ckpt['model_state_dict']['performer.net.layers.0.0.fn.to_q.weight']\n","state_dict_student['performer.net.layers.0.0.fn.to_k.weight']=ckpt['model_state_dict']['performer.net.layers.0.0.fn.to_k.weight']\n","state_dict_student['performer.net.layers.0.0.fn.to_v.weight']=ckpt['model_state_dict']['performer.net.layers.0.0.fn.to_v.weight']\n","state_dict_student['performer.net.layers.0.0.fn.to_out.weight']=ckpt['model_state_dict']['performer.net.layers.0.0.fn.to_out.weight']\n","state_dict_student['performer.net.layers.0.0.fn.to_out.bias']=ckpt['model_state_dict']['performer.net.layers.0.0.fn.to_out.bias']\n","state_dict_student['performer.net.layers.0.1.norm.weight']=ckpt['model_state_dict']['performer.net.layers.0.1.norm.weight']\n","state_dict_student['performer.net.layers.0.1.norm.bias']=ckpt['model_state_dict']['performer.net.layers.0.1.norm.bias']\n","state_dict_student['performer.net.layers.0.1.fn.fn.w1.weight']=ckpt['model_state_dict']['performer.net.layers.0.1.fn.fn.w1.weight']\n","state_dict_student['performer.net.layers.0.1.fn.fn.w1.bias']=ckpt['model_state_dict']['performer.net.layers.0.1.fn.fn.w1.bias']\n","state_dict_student['performer.net.layers.0.1.fn.fn.w2.weight']=ckpt['model_state_dict']['performer.net.layers.0.1.fn.fn.w2.weight']\n","state_dict_student['performer.net.layers.0.1.fn.fn.w2.bias']=ckpt['model_state_dict']['performer.net.layers.0.1.fn.fn.w2.bias']\n","state_dict_student['performer.net.layers.1.0.norm.weight']=ckpt['model_state_dict']['performer.net.layers.2.0.norm.weight']\n","state_dict_student['performer.net.layers.1.0.norm.bias']=ckpt['model_state_dict']['performer.net.layers.2.0.norm.bias']\n","state_dict_student['performer.net.layers.1.0.fn.fast_attention.projection_matrix']=ckpt['model_state_dict']['performer.net.layers.2.0.fn.fast_attention.projection_matrix']\n","state_dict_student['performer.net.layers.1.0.fn.to_q.weight']=ckpt['model_state_dict']['performer.net.layers.2.0.fn.to_q.weight']\n","state_dict_student['performer.net.layers.1.0.fn.to_k.weight']=ckpt['model_state_dict']['performer.net.layers.2.0.fn.to_k.weight']\n","state_dict_student['performer.net.layers.1.0.fn.to_v.weight']=ckpt['model_state_dict']['performer.net.layers.2.0.fn.to_v.weight']\n","state_dict_student['performer.net.layers.1.0.fn.to_out.weight']=ckpt['model_state_dict']['performer.net.layers.2.0.fn.to_out.weight']\n","state_dict_student['performer.net.layers.1.0.fn.to_out.bias']=ckpt['model_state_dict']['performer.net.layers.2.0.fn.to_out.bias']\n","state_dict_student['performer.net.layers.1.1.norm.weight']=ckpt['model_state_dict']['performer.net.layers.2.1.norm.weight']\n","state_dict_student['performer.net.layers.1.1.norm.bias']=ckpt['model_state_dict']['performer.net.layers.2.1.norm.bias']\n","state_dict_student['performer.net.layers.1.1.fn.fn.w1.weight']=ckpt['model_state_dict']['performer.net.layers.2.1.fn.fn.w1.weight']\n","state_dict_student['performer.net.layers.1.1.fn.fn.w1.bias']=ckpt['model_state_dict']['performer.net.layers.2.1.fn.fn.w1.bias']\n","state_dict_student['performer.net.layers.1.1.fn.fn.w2.weight']=ckpt['model_state_dict']['performer.net.layers.2.1.fn.fn.w2.weight']\n","state_dict_student['performer.net.layers.1.1.fn.fn.w2.bias']=ckpt['model_state_dict']['performer.net.layers.2.1.fn.fn.w2.bias']\n","state_dict_student['performer.net.layers.2.0.norm.weight']=ckpt['model_state_dict']['performer.net.layers.4.0.norm.weight']\n","state_dict_student['performer.net.layers.2.0.norm.bias']=ckpt['model_state_dict']['performer.net.layers.4.0.norm.bias']\n","state_dict_student['performer.net.layers.2.0.fn.fast_attention.projection_matrix']=ckpt['model_state_dict']['performer.net.layers.4.0.fn.fast_attention.projection_matrix']\n","state_dict_student['performer.net.layers.2.0.fn.to_q.weight']=ckpt['model_state_dict']['performer.net.layers.4.0.fn.to_q.weight']\n","state_dict_student['performer.net.layers.2.0.fn.to_k.weight']=ckpt['model_state_dict']['performer.net.layers.4.0.fn.to_k.weight']\n","state_dict_student['performer.net.layers.2.0.fn.to_v.weight']=ckpt['model_state_dict']['performer.net.layers.4.0.fn.to_v.weight']\n","state_dict_student['performer.net.layers.2.0.fn.to_out.weight']=ckpt['model_state_dict']['performer.net.layers.4.0.fn.to_out.weight']\n","state_dict_student['performer.net.layers.2.0.fn.to_out.bias']=ckpt['model_state_dict']['performer.net.layers.4.0.fn.to_out.bias']\n","state_dict_student['performer.net.layers.2.1.norm.weight']=ckpt['model_state_dict']['performer.net.layers.4.1.norm.weight']\n","state_dict_student['performer.net.layers.2.1.norm.bias']=ckpt['model_state_dict']['performer.net.layers.4.1.norm.bias']\n","state_dict_student['performer.net.layers.2.1.fn.fn.w1.weight']=ckpt['model_state_dict']['performer.net.layers.4.1.fn.fn.w1.weight']\n","state_dict_student['performer.net.layers.2.1.fn.fn.w1.bias']=ckpt['model_state_dict']['performer.net.layers.4.1.fn.fn.w1.bias']\n","state_dict_student['performer.net.layers.2.1.fn.fn.w2.weight']=ckpt['model_state_dict']['performer.net.layers.4.1.fn.fn.w2.weight']\n","state_dict_student['performer.net.layers.2.1.fn.fn.w2.bias']=ckpt['model_state_dict']['performer.net.layers.4.1.fn.fn.w2.bias']\n","state_dict_student['norm.weight']=ckpt['model_state_dict']['norm.weight']\n","state_dict_student['norm.bias']=ckpt['model_state_dict']['norm.bias']\n","state_dict_student['to_out.weight']=ckpt['model_state_dict']['to_out.weight']\n","state_dict_student['to_out.bias']=ckpt['model_state_dict']['to_out.bias']\n","\n","\n"],"metadata":{"id":"053ct65aCMqp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pytorch_total_params = sum(p.numel() for p in teacher_model.parameters())\n","print(pytorch_total_params)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F4Yi-dpGMXLg","executionInfo":{"status":"ok","timestamp":1714634893967,"user_tz":-330,"elapsed":5,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}},"outputId":"e7b628be-77ab-4384-f4c3-b67a2c0d3ec9"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["8388607\n"]}]},{"cell_type":"code","source":["pytorch_total_params = sum(p.numel() for p in student_model.parameters())\n","print(pytorch_total_params)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"20qcu_e9MeU6","executionInfo":{"status":"ok","timestamp":1714634893967,"user_tz":-330,"elapsed":3,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}},"outputId":"4c63c6d6-89fc-47a1-95d9-c534ef93b2f6"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["5886607\n"]}]},{"cell_type":"code","source":["student_model.load_state_dict(state_dict_student)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FsWyRPvaCMoL","executionInfo":{"status":"ok","timestamp":1714582572666,"user_tz":-330,"elapsed":5,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}},"outputId":"63d2ee88-0927-489d-e781-c3bacf221c46"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["optimizer = Adam(student_model.parameters(), lr=LEARNING_RATE)\n","loss_fn = nn.CrossEntropyLoss(ignore_index = PAD_TOKEN_ID, reduction='mean').to(device)\n","softmax = nn.Softmax(dim=-1)"],"metadata":{"id":"hc6brXAGCOhm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!export 'PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:32'"],"metadata":{"id":"I_A99I79EOXk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["scaler = torch.cuda.amp.GradScaler()"],"metadata":{"id":"4lnXYaIV92vA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def distillation_loss(student_output, teacher_output, temperature):\n","    student_soft = F.log_softmax(student_output / temperature, dim=1)\n","    teacher_soft = F.softmax(teacher_output / temperature, dim=1)\n","    return F.kl_div(student_soft, teacher_soft, reduction='batchmean') * (temperature ** 2)"],"metadata":{"id":"_ojqXKjXF0UJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HMeWW5JqXMlt","outputId":"6d8dae96-78e8-417e-f021-79428654c995","colab":{"base_uri":"https://localhost:8080/","height":391},"executionInfo":{"status":"error","timestamp":1714582820576,"user_tz":-330,"elapsed":82003,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["  0%|          | 100/950315 [01:05<173:39:33,  1.52it/s]"]},{"output_type":"stream","name":"stdout","text":["0.004827586182509549\n"]},{"output_type":"stream","name":"stderr","text":["  0%|          | 124/950315 [01:21<173:35:47,  1.52it/s]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-35-5c921b7dc825>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m           \u001b[0mteacher_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mteacher_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m           \u001b[0mstudent_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstudent_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m           \u001b[0;31m# print(teacher_logits.shape, student_logits.transpose(1, 2).shape, labels.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m           \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudent_logits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdistillation_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudent_logits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mteacher_logits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mGRADIENT_ACCUMULATION\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/scFasterBERT/performer_pytorch/performer_pytorch.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, return_encodings, output_attentions, **kwargs)\u001b[0m\n\u001b[1;32m    627\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_emb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 629\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_pos_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_attentions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    630\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m             \u001b[0;31m# norm and to logits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/scFasterBERT/performer_pytorch/performer_pytorch.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, output_attentions, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_attentions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_check_redraw\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_redraw_projections\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_attentions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/scFasterBERT/performer_pytorch/performer_pytorch.py\u001b[0m in \u001b[0;36mcheck_redraw_projections\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    525\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 527\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_redraw_interval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalls_since_last_redraw\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_redraw_interval\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    528\u001b[0m             \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_module_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["EPOCHS = 1\n","VALIDATE_EVERY = 1000\n","PAD_TOKEN_ID = 0  # Assuming a placeholder value\n","\n","for i in range(1, EPOCHS+1):\n","    teacher_model.eval()\n","    student_model.train()\n","    running_loss = 0.0\n","    cum_acc = 0.0\n","    for index, data in enumerate(tqdm(train_loader)):\n","        index += 1\n","        data = data.to(device)\n","        data, labels = data_mask(data)\n","        with torch.cuda.amp.autocast(dtype=torch.float16):\n","          teacher_logits = teacher_model(data)\n","          student_logits = student_model(data)\n","          # print(teacher_logits.shape, student_logits.transpose(1, 2).shape, labels.shape)\n","          loss = loss_fn(student_logits.transpose(1, 2), labels) + distillation_loss(student_logits.transpose(1,2), teacher_logits.transpose(1, 2), 1) / GRADIENT_ACCUMULATION\n","          scaler.scale(loss).backward()\n","        if index % GRADIENT_ACCUMULATION != 0:\n","          torch.nn.utils.clip_grad_norm_(student_model.parameters(), int(1e2))\n","          scaler.step(optimizer)\n","          scaler.update()\n","          optimizer.zero_grad()\n","        running_loss += loss.item()\n","        final = softmax(student_logits)[..., 1:-1]\n","        final = final.argmax(dim=-1) + 1\n","        pred_num = (labels != PAD_TOKEN_ID).sum(dim=-1)\n","        correct_num = ((labels != PAD_TOKEN_ID) * (final == labels)).sum(dim=-1)\n","        cum_acc += torch.true_divide(correct_num, pred_num).mean().item()\n","        if(index % 100 == 0):\n","            print(cum_acc/index)\n","    epoch_loss = running_loss / index\n","    epoch_acc = 100 * cum_acc / index\n","\n","    print(f'    ==  Epoch: {i} | Training Loss: {epoch_loss:.6f} | Accuracy: {epoch_acc:6.4f}%  ==')\n","\n","    if i % VALIDATE_EVERY == 0:\n","        student_model.eval()\n","        running_loss = 0.0\n","        predictions = []\n","        truths = []\n","        with torch.no_grad():\n","            for index, data in enumerate(tqdm(val_loader)):\n","                index += 1\n","                data = data.to(device)\n","                data, labels = data_mask(data)\n","                teacher_logits = teacher_model(data)\n","                student_logits = student_model(data)\n","                loss = loss_fn(student_logits.transpose(1, 2), labels) + distillation_loss(student_logits.transpose(1,2), teacher_logits.transpose(1, 2), 1)\n","                running_loss += loss.item()\n","                softmax = nn.Softmax(dim=-1)\n","                final = softmax(student_logits)[..., 1:-1]\n","                final = final.argmax(dim=-1) + 1\n","                predictions.append(final)\n","                truths.append(labels)\n","        val_loss = running_loss / index\n","        correct_num = ((torch.cat(truths, dim=0) != PAD_TOKEN_ID) * (torch.cat(predictions, dim=0) == torch.cat(truths, dim=0))).sum().item()\n","        val_num = (torch.cat(truths, dim=0) != PAD_TOKEN_ID).sum().item()\n","        val_acc = 100 * correct_num / val_num\n","        print(f'    ==  Epoch: {i} | Validation Loss: {val_loss:.6f} | Accuracy: {val_acc:6.4f}%  ==')\n","\n"]},{"cell_type":"code","source":[],"metadata":{"id":"mIs2Ior1AKJY"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}