{"cells":[{"cell_type":"code","source":["from psutil import virtual_memory\n","ram_gb = virtual_memory().total / 1e9\n","print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n","\n","if ram_gb < 20:\n","  print('Not using a high-RAM runtime')\n","else:\n","  print('You are using a high-RAM runtime!')"],"metadata":{"id":"Tg3dpsogXYSE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715597975584,"user_tz":-330,"elapsed":11,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}},"outputId":"41842adb-7bec-4c32-e34c-983fd1688ada"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Your runtime has 54.8 gigabytes of available RAM\n","\n","You are using a high-RAM runtime!\n"]}]},{"cell_type":"code","source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)"],"metadata":{"id":"E_MdpTlxXYKc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715597975584,"user_tz":-330,"elapsed":10,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}},"outputId":"b53f3aa6-3deb-4b9b-8253-02473629f0d0"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mon May 13 10:59:32 2024       \n","+---------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n","|-----------------------------------------+----------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                      |               MIG M. |\n","|=========================================+======================+======================|\n","|   0  Tesla V100-SXM2-16GB           Off | 00000000:00:04.0 Off |                    0 |\n","| N/A   34C    P0              24W / 300W |      0MiB / 16384MiB |      0%      Default |\n","|                                         |                      |                  N/A |\n","+-----------------------------------------+----------------------+----------------------+\n","                                                                                         \n","+---------------------------------------------------------------------------------------+\n","| Processes:                                                                            |\n","|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n","|        ID   ID                                                             Usage      |\n","|=======================================================================================|\n","|  No running processes found                                                           |\n","+---------------------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"metadata":{"id":"67tfpQ3-XUgj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715597997228,"user_tz":-330,"elapsed":21648,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}},"outputId":"8fa71d01-2dc5-49a2-9d5e-71f4d88ce688"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}]},{"cell_type":"code","source":["ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w6ydBP_ChTgV","executionInfo":{"status":"ok","timestamp":1715597997228,"user_tz":-330,"elapsed":6,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}},"outputId":"c61ad41a-6a9c-48ef-d7a4-841c740565f0"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[0m\u001b[01;34mdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"]}]},{"cell_type":"code","source":["import os\n","os.environ['PYTHONPATH'] += \"/content/drive/MyDrive/scFasterBERT/performer_pytorch\""],"metadata":{"id":"bd1l6AJ_iQe9","executionInfo":{"status":"ok","timestamp":1715597997228,"user_tz":-330,"elapsed":3,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["!pip install einops\n","!pip install local_attention\n","!pip install scanpy"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"70BzUhTSiloq","executionInfo":{"status":"ok","timestamp":1715598070606,"user_tz":-330,"elapsed":73381,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}},"outputId":"15d46917-7316-4977-d305-986df732e081"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting einops\n","  Downloading einops-0.8.0-py3-none-any.whl (43 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m808.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: einops\n","Successfully installed einops-0.8.0\n","Collecting local_attention\n","  Downloading local_attention-1.9.1-py3-none-any.whl (8.2 kB)\n","Requirement already satisfied: einops>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from local_attention) (0.8.0)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from local_attention) (2.2.1+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->local_attention) (3.14.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->local_attention) (4.11.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->local_attention) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->local_attention) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->local_attention) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->local_attention) (2023.6.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->local_attention)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->local_attention)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->local_attention)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->local_attention)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->local_attention)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->local_attention)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch->local_attention)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->local_attention)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->local_attention)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.19.3 (from torch->local_attention)\n","  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch->local_attention)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->local_attention) (2.2.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->local_attention)\n","  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->local_attention) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->local_attention) (1.3.0)\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, local_attention\n","Successfully installed local_attention-1.9.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105\n","Collecting scanpy\n","  Downloading scanpy-1.10.1-py3-none-any.whl (2.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting anndata>=0.8 (from scanpy)\n","  Downloading anndata-0.10.7-py3-none-any.whl (122 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.4/122.4 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: h5py>=3.1 in /usr/local/lib/python3.10/dist-packages (from scanpy) (3.9.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from scanpy) (1.4.2)\n","Collecting legacy-api-wrap>=1.4 (from scanpy)\n","  Downloading legacy_api_wrap-1.4-py3-none-any.whl (15 kB)\n","Requirement already satisfied: matplotlib>=3.6 in /usr/local/lib/python3.10/dist-packages (from scanpy) (3.7.1)\n","Requirement already satisfied: natsort in /usr/local/lib/python3.10/dist-packages (from scanpy) (8.4.0)\n","Requirement already satisfied: networkx>=2.7 in /usr/local/lib/python3.10/dist-packages (from scanpy) (3.3)\n","Requirement already satisfied: numba>=0.56 in /usr/local/lib/python3.10/dist-packages (from scanpy) (0.58.1)\n","Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.10/dist-packages (from scanpy) (1.25.2)\n","Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from scanpy) (24.0)\n","Requirement already satisfied: pandas>=1.5 in /usr/local/lib/python3.10/dist-packages (from scanpy) (2.0.3)\n","Requirement already satisfied: patsy in /usr/local/lib/python3.10/dist-packages (from scanpy) (0.5.6)\n","Collecting pynndescent>=0.5 (from scanpy)\n","  Downloading pynndescent-0.5.12-py3-none-any.whl (56 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scikit-learn>=0.24 in /usr/local/lib/python3.10/dist-packages (from scanpy) (1.2.2)\n","Requirement already satisfied: scipy>=1.8 in /usr/local/lib/python3.10/dist-packages (from scanpy) (1.11.4)\n","Requirement already satisfied: seaborn>=0.13 in /usr/local/lib/python3.10/dist-packages (from scanpy) (0.13.1)\n","Collecting session-info (from scanpy)\n","  Downloading session_info-1.0.0.tar.gz (24 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: statsmodels>=0.13 in /usr/local/lib/python3.10/dist-packages (from scanpy) (0.14.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from scanpy) (4.66.4)\n","Collecting umap-learn!=0.5.0,>=0.5 (from scanpy)\n","  Downloading umap_learn-0.5.6-py3-none-any.whl (85 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.7/85.7 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting array-api-compat!=1.5,>1.4 (from anndata>=0.8->scanpy)\n","  Downloading array_api_compat-1.6-py3-none-any.whl (36 kB)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anndata>=0.8->scanpy) (1.2.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->scanpy) (1.2.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->scanpy) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->scanpy) (4.51.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->scanpy) (1.4.5)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->scanpy) (9.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->scanpy) (3.1.2)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->scanpy) (2.8.2)\n","Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.56->scanpy) (0.41.1)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.5->scanpy) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.5->scanpy) (2024.1)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24->scanpy) (3.5.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy->scanpy) (1.16.0)\n","Collecting stdlib_list (from session-info->scanpy)\n","  Downloading stdlib_list-0.10.0-py3-none-any.whl (79 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: session-info\n","  Building wheel for session-info (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for session-info: filename=session_info-1.0.0-py3-none-any.whl size=8026 sha256=a8dff816dba1f42a288da868338c3bc0a0ca29d6767462f055fb7182d17d825f\n","  Stored in directory: /root/.cache/pip/wheels/6a/aa/b9/eb5d4031476ec10802795b97ccf937b9bd998d68a9b268765a\n","Successfully built session-info\n","Installing collected packages: array-api-compat, stdlib_list, legacy-api-wrap, session-info, pynndescent, anndata, umap-learn, scanpy\n","Successfully installed anndata-0.10.7 array-api-compat-1.6 legacy-api-wrap-1.4 pynndescent-0.5.12 scanpy-1.10.1 session-info-1.0.0 stdlib_list-0.10.0 umap-learn-0.5.6\n"]}]},{"cell_type":"code","execution_count":8,"metadata":{"id":"WLddJJ5sXMln","executionInfo":{"status":"ok","timestamp":1715598081257,"user_tz":-330,"elapsed":10655,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}}},"outputs":[],"source":["import sys\n","sys.path.insert(1, '/content/drive/MyDrive/scFasterBERT/performer_pytorch')\n","sys.path.insert(2, '/content/drive/MyDrive/scFasterBERT/')\n","import os\n","import gc\n","import argparse\n","import json\n","import random\n","import math\n","import random\n","from functools import reduce\n","import numpy as np\n","import pandas as pd\n","from scipy import sparse\n","from sklearn.model_selection import train_test_split\n","import torch\n","from torch import nn\n","from torch.optim import Adam\n","from torch.nn import functional as F\n","from torch.utils.data import DataLoader, Dataset\n","from performer_pytorch import PerformerLM_quant, PerformerLM\n","import scanpy as sc\n","import anndata as ad\n","from utils import *\n","import scipy.sparse\n","import h5py\n","from tqdm import tqdm\n","from torch.utils.tensorboard import SummaryWriter\n","from torch.quantization import get_default_qconfig, prepare, convert, float_qparams_weight_only_qconfig"]},{"cell_type":"code","source":["Writer = SummaryWriter('./runs/scBERT_ours_pretrained')"],"metadata":{"id":"7FBmaSkOffL-","executionInfo":{"status":"ok","timestamp":1715598081257,"user_tz":-330,"elapsed":12,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","execution_count":10,"metadata":{"id":"Co1cwDfrXMlp","executionInfo":{"status":"ok","timestamp":1715598081257,"user_tz":-330,"elapsed":11,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}}},"outputs":[],"source":["data_path = '../data/panglao_human.h5ad'"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"4DGWuKE3XMlp","executionInfo":{"status":"ok","timestamp":1715598081257,"user_tz":-330,"elapsed":10,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}}},"outputs":[],"source":["SEED = 2021\n","EPOCHS = 100\n","BATCH_SIZE = 1\n","GRADIENT_ACCUMULATION = 60\n","LEARNING_RATE = 1e-4\n","SEQ_LEN = 16907\n","VALIDATE_EVERY = 1\n","CLASS = 7\n","MASK_PROB = 0.15\n","REPLACE_PROB = 0.9\n","RANDOM_TOKEN_PROB = 0.\n","MASK_TOKEN_ID = CLASS - 1\n","PAD_TOKEN_ID = CLASS - 1\n","MASK_IGNORE_TOKEN_IDS = [0]\n","POS_EMBED_USING = True\n","\n","model_name = 'panglao_pretrain_ours_1'\n","ckpt_dir = './checkpoints/'"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"K-yZa70LXMlq","outputId":"c3ee80ff-9918-4d24-da3e-39266df57d3a","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715598082352,"user_tz":-330,"elapsed":6,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7ec1e73007f0>"]},"metadata":{},"execution_count":12}],"source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","torch.manual_seed(SEED)"]},{"cell_type":"markdown","metadata":{"id":"gowQVmRrXMlq"},"source":["# Masking"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"wYyXZM4vXMlr","executionInfo":{"status":"ok","timestamp":1715598082352,"user_tz":-330,"elapsed":5,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}}},"outputs":[],"source":["# get the random prob matrix and True means smaller than prob threshold\n","def prob_mask_like(t, prob):\n","    return torch.zeros_like(t).float().uniform_(0, 1) < prob\n","\n","# get the mask matrix which cannot be masked\n","def mask_with_tokens(t, token_ids):\n","    init_no_mask = torch.full_like(t, False, dtype=torch.bool)\n","    mask = reduce(lambda acc, el: acc | (t == el), token_ids, init_no_mask)\n","    return mask\n","\n","def get_mask_subset_with_prob(mask, prob):\n","    batch, seq_len, device = *mask.shape, mask.device\n","    max_masked = math.ceil(prob * seq_len)      # num of mask of a single sequence in average\n","    num_tokens = mask.sum(dim=-1, keepdim=True)     # num of pure tokens of each sequence except special tokens\n","    mask_excess = torch.cat((torch.zeros(0), torch.arange(mask.size(-1)).repeat(mask.size(0)))).reshape(mask.size(0),mask.size(-1)).to(device)\n","    mask_excess = (mask_excess >= (num_tokens * prob).ceil())        # only 15% of pure tokens can be masked\n","    mask_excess = mask_excess[:, :max_masked]       # get difference between 15% of pure tokens and 15% of all tokens\n","    rand = torch.rand((batch, seq_len), device=device).masked_fill(~mask, -1e9)     # rand (0-1) as prob, special token use -1e9\n","    _, sampled_indices = rand.topk(max_masked, dim=-1)      # get index of topk prob to mask\n","    sampled_indices = (sampled_indices + 1).masked_fill_(mask_excess, 0)        # delete difference of mask not pure\n","    new_mask = torch.zeros((batch, seq_len + 1), device=device)     # get (batch, seq_len) shape zero matrix\n","    new_mask.scatter_(-1, sampled_indices, 1)       # set masks in zero matrix as 1\n","    return new_mask[:, 1:].bool()       # the final mask, True is mask\n","\n","def data_mask(data,\n","    mask_prob = MASK_PROB,\n","    replace_prob = REPLACE_PROB,\n","    num_tokens = None,\n","    random_token_prob = RANDOM_TOKEN_PROB,\n","    mask_token_id = MASK_TOKEN_ID,\n","    pad_token_id = PAD_TOKEN_ID,\n","    mask_ignore_token_ids = MASK_IGNORE_TOKEN_IDS\n","):\n","    mask_ignore_token_ids = set([*mask_ignore_token_ids, pad_token_id])\n","    # do not mask [pad] tokens, or any other tokens in the tokens designated to be excluded ([cls], [sep])\n","    # also do not include these special tokens in the tokens chosen at random\n","    no_mask = mask_with_tokens(data, mask_ignore_token_ids)   # ignore_token as True, will not be masked later\n","    mask = get_mask_subset_with_prob(~no_mask, mask_prob)      # get the True/False mask matrix\n","    # get mask indices\n","    ## mask_indices = torch.nonzero(mask, as_tuple=True)   # get the index of mask(nonzero value of mask matrix)\n","    # mask input with mask tokens with probability of `replace_prob` (keep tokens the same with probability 1 - replace_prob)\n","    masked_input = data.clone().detach()\n","    # if random token probability > 0 for mlm\n","    if random_token_prob > 0:\n","        assert num_tokens is not None, 'num_tokens keyword must be supplied when instantiating MLM if using random token replacement'\n","        random_token_prob = prob_mask_like(data, random_token_prob)       # get the mask matrix of random token replace\n","        random_tokens = torch.randint(0, num_tokens, data.shape, device=data.device)     # generate random token matrix with the same shape as in\n","        random_no_mask = mask_with_tokens(random_tokens, mask_ignore_token_ids)        # not masked matrix for the random token matrix\n","        random_token_prob &= ~random_no_mask        # get the pure mask matrix of random token replace\n","        random_indices = torch.nonzero(random_token_prob, as_tuple=True)        # index of random token replace\n","        masked_input[random_indices] = random_tokens[random_indices]        # replace some tokens by random token\n","    # [mask] input\n","    replace_prob = prob_mask_like(data, replace_prob)     # get the mask matrix of token being masked\n","    masked_input = masked_input.masked_fill(mask * replace_prob, mask_token_id)        # get the data has been masked by mask_token\n","    # mask out any tokens to padding tokens that were not originally going to be masked\n","    labels = data.masked_fill(~mask, pad_token_id)        # the label of masked tokens\n","    return masked_input, labels"]},{"cell_type":"markdown","metadata":{"id":"vRs1LsQXXMls"},"source":["# Dataset and Dataloader"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"DZBwDp-EXMls","executionInfo":{"status":"ok","timestamp":1715598082352,"user_tz":-330,"elapsed":5,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}}},"outputs":[],"source":["\n","# total_samples = 1357593  # Replace with the actual total length of your dataset\n","# train_ratio = 0.95\n","\n","# # Calculate the number of samples in each set\n","# num_train_samples = int(total_samples * train_ratio)\n","# num_valid_samples = total_samples - num_train_samples\n","\n","# # Generate indices for training and validation sets\n","# train_indices = list(range(0, num_train_samples))\n","# valid_indices = list(range(num_train_samples, total_samples))\n","\n","# print(\"Training indices:\", len(train_indices))\n","# print(\"Validation indices:\", len(valid_indices))"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"cBmPZ4ypXMls","executionInfo":{"status":"ok","timestamp":1715598082352,"user_tz":-330,"elapsed":4,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}}},"outputs":[],"source":["# class SCDataset(Dataset):\n","#     def __init__(self, file_path, indices):\n","#         self.file_path = file_path\n","#         self.data = sc.read_h5ad(data_path, backed='r')\n","#         self.length = self.data.X.shape[0]\n","#         self.indices = indices\n","#         self.indices_len = len(self.indices)\n","\n","#     def __getitem__(self, index):\n","#         rand_start = random.randint(0, self.indices_len-1)\n","#         data = self.data.X[self.indices[rand_start]]\n","#         # Convert sparse matrix row to dense if necessary\n","#         if isinstance(data, scipy.sparse.csr_matrix):\n","#             data = data.toarray().squeeze(0)\n","#             # print(data)\n","\n","#         # Apply the same preprocessing as before\n","#         data[data > (CLASS - 2)] = CLASS - 2\n","#         data = torch.from_numpy(data).long()\n","#         data = torch.cat((data, torch.tensor([0]))).to(device)\n","#         return data\n","\n","#     def __len__(self):\n","#         return self.length"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"igKC-308XMlt","executionInfo":{"status":"ok","timestamp":1715598082352,"user_tz":-330,"elapsed":4,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}}},"outputs":[],"source":["\n","# train_dataset = SCDataset(data_path, train_indices)\n","# val_dataset = SCDataset(data_path, valid_indices)\n","\n","# train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n","# val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)"]},{"cell_type":"code","source":["class SCDataset(Dataset):\n","    def __init__(self, data):\n","        super().__init__()\n","        self.data = data\n","\n","    def __getitem__(self, index):\n","        rand_start = random.randint(0, self.data.shape[0]-1)\n","        full_seq = self.data[rand_start].toarray()[0]\n","        full_seq[full_seq > (CLASS - 2)] = CLASS - 2\n","        full_seq = torch.from_numpy(full_seq).long()\n","        full_seq = torch.cat((full_seq, torch.tensor([0]))).to(device)\n","        return full_seq\n","\n","    def __len__(self):\n","        return self.data.shape[0]\n","\n","data = sc.read_h5ad('/content/drive/MyDrive/scFasterBERT/data/panglao_human.h5ad')\n","data = data.X\n","\n","\n"],"metadata":{"id":"2GBKtA0Dgup5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715598225349,"user_tz":-330,"elapsed":143001,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}},"outputId":"00df8924-7958-4acb-c665-6ef146d06ed5"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/anndata/_core/anndata.py:1818: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n","  utils.warn_names_duplicates(\"obs\")\n"]}]},{"cell_type":"code","source":["data_train, data_val = train_test_split(data, test_size=0.00001,random_state=SEED)\n","\n","train_dataset = SCDataset(data_train)\n","val_dataset = SCDataset(data_val)"],"metadata":{"id":"owfCgA7flELk","executionInfo":{"status":"ok","timestamp":1715598236598,"user_tz":-330,"elapsed":11252,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE)\n","val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)"],"metadata":{"id":"01qOE09-n3Gi","executionInfo":{"status":"ok","timestamp":1715598236598,"user_tz":-330,"elapsed":26,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["len(val_loader)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"05TPiuulMxfW","executionInfo":{"status":"ok","timestamp":1715598236598,"user_tz":-330,"elapsed":23,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}},"outputId":"71baa7ea-8749-41b4-929e-bf71f3098a5a"},"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["14"]},"metadata":{},"execution_count":20}]},{"cell_type":"markdown","metadata":{"id":"k_qaL8bEXMlt"},"source":["# Model"]},{"cell_type":"code","execution_count":32,"metadata":{"id":"V2xdhEylXMlt","executionInfo":{"status":"ok","timestamp":1715598407807,"user_tz":-330,"elapsed":550,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}}},"outputs":[],"source":["model = PerformerLM_quant(\n","    num_tokens = CLASS,\n","    dim = 200,\n","    depth = 6,\n","    max_seq_len = SEQ_LEN,\n","    heads = 10,\n","    local_attn_heads = 0,\n","    g2v_position_emb = POS_EMBED_USING\n","    ).to(device)\n","\n","\n","\n","# optimizer\n","optimizer = Adam(model.parameters(), lr=LEARNING_RATE)"]},{"cell_type":"code","source":["ckpt = torch.load('/content/drive/MyDrive/scFasterBERT/panglao_pretrain.pth',map_location=torch.device('cpu'))\n","model.load_state_dict(ckpt['model_state_dict'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"88b_2cEA20yU","executionInfo":{"status":"ok","timestamp":1715598407807,"user_tz":-330,"elapsed":2,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}},"outputId":"6983a613-673b-4713-cefb-aaf7869b9b2a"},"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":33}]},{"cell_type":"code","source":["model.eval()\n","model.qconfig = get_default_qconfig('fbgemm')\n","model.token_emb.qconfig = float_qparams_weight_only_qconfig\n","model.pos_emb.qconfig = float_qparams_weight_only_qconfig\n","model.layer_pos_emb.qconfig = float_qparams_weight_only_qconfig\n","model = torch.quantization.prepare(model)\n","model\n"],"metadata":{"id":"GAQ8RY6p49aG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715598411615,"user_tz":-330,"elapsed":710,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}},"outputId":"8577d436-b6c9-43c6-b830-41e39bff2d25"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/ao/quantization/observer.py:220: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n","  warnings.warn(\n"]},{"output_type":"execute_result","data":{"text/plain":["PerformerLM_quant(\n","  (quant): QuantStub(\n","    (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n","  )\n","  (dequant): DeQuantStub()\n","  (token_emb): Embedding(\n","    7, 200\n","    (activation_post_process): PlaceholderObserver(dtype=torch.float32, is_dynamic=False)\n","  )\n","  (pos_emb): Gene2VecPositionalEmbedding(\n","    (emb): Embedding(\n","      16907, 200\n","      (activation_post_process): PlaceholderObserver(dtype=torch.float32, is_dynamic=False)\n","    )\n","  )\n","  (layer_pos_emb): Always()\n","  (dropout): Dropout(p=0.0, inplace=False)\n","  (performer): Performer(\n","    (net): SequentialSequence(\n","      (layers): ModuleList(\n","        (0-5): 6 x ModuleList(\n","          (0): PreLayerNorm(\n","            (norm): LayerNorm(\n","              (200,), eps=1e-05, elementwise_affine=True\n","              (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n","            )\n","            (fn): SelfAttention(\n","              (fast_attention): FastAttention(\n","                (kernel_fn): ReLU()\n","              )\n","              (to_q): Linear(\n","                in_features=200, out_features=640, bias=False\n","                (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n","              )\n","              (to_k): Linear(\n","                in_features=200, out_features=640, bias=False\n","                (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n","              )\n","              (to_v): Linear(\n","                in_features=200, out_features=640, bias=False\n","                (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n","              )\n","              (to_out): Linear(\n","                in_features=640, out_features=200, bias=True\n","                (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n","              )\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (1): PreLayerNorm(\n","            (norm): LayerNorm(\n","              (200,), eps=1e-05, elementwise_affine=True\n","              (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n","            )\n","            (fn): Chunk(\n","              (fn): FeedForward(\n","                (w1): Linear(\n","                  in_features=200, out_features=800, bias=True\n","                  (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n","                )\n","                (act): GELU(approximate='none')\n","                (dropout): Dropout(p=0.0, inplace=False)\n","                (w2): Linear(\n","                  in_features=800, out_features=200, bias=True\n","                  (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n","                )\n","              )\n","            )\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (norm): LayerNorm(\n","    (200,), eps=1e-05, elementwise_affine=True\n","    (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n","  )\n","  (to_out): Linear(\n","    in_features=200, out_features=7, bias=True\n","    (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n","  )\n",")"]},"metadata":{},"execution_count":34}]},{"cell_type":"code","execution_count":35,"metadata":{"id":"OLDLa74bXMlt","executionInfo":{"status":"ok","timestamp":1715598414954,"user_tz":-330,"elapsed":343,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}}},"outputs":[],"source":["loss_fn = nn.CrossEntropyLoss(ignore_index = PAD_TOKEN_ID, reduction='mean').to(device)\n","softmax = nn.Softmax(dim=-1)"]},{"cell_type":"code","execution_count":36,"metadata":{"id":"HMeWW5JqXMlt","executionInfo":{"status":"ok","timestamp":1715598415273,"user_tz":-330,"elapsed":3,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}}},"outputs":[],"source":["def test(model):\n","    model.eval()\n","    running_loss = 0.0\n","    predictions = []\n","    truths = []\n","    with torch.no_grad():\n","        for index, data in enumerate(tqdm(val_loader)):\n","            index += 1\n","            data = data.to(device)\n","            data, labels = data_mask(data)\n","            logits = model(data)\n","            loss = loss_fn(logits.transpose(1, 2), labels)\n","            running_loss += loss.item()\n","            softmax = nn.Softmax(dim=-1)\n","            final = softmax(logits)[..., 1:-1]\n","            final = final.argmax(dim=-1) + 1\n","            predictions.append(final)\n","            truths.append(labels)\n","    val_loss = running_loss / index\n","    correct_num = ((torch.cat(truths, dim=0) != PAD_TOKEN_ID) * (torch.cat(predictions, dim=0) == torch.cat(truths, dim=0))).sum().item()\n","    val_num = (torch.cat(truths, dim=0) != PAD_TOKEN_ID).sum().item()\n","    val_acc = 100 * correct_num / val_num\n","    print(f'Validation Loss: {val_loss:.6f} | Accuracy: {val_acc:6.4f}%  ==')\n","    Writer.add_scalar('Valid loss', val_loss)\n","    Writer.add_scalar('Valid accuracy',val_acc)\n","    # torch.save(model.state_dict(), '.')"]},{"cell_type":"code","execution_count":37,"metadata":{"id":"_9bfv1VTXMlu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715598416990,"user_tz":-330,"elapsed":1719,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}},"outputId":"42bedd8e-0b44-41d7-d809-e844e9eb223d"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 14/14 [00:01<00:00,  8.29it/s]"]},{"output_type":"stream","name":"stdout","text":["Validation Loss: 0.493375 | Accuracy: 78.9097%  ==\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["test(model)"]},{"cell_type":"code","source":["model"],"metadata":{"id":"6iiYCGtBOkTI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715598418362,"user_tz":-330,"elapsed":2,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}},"outputId":"95f2cb7d-fc8c-4082-faea-c142a5dc3bc9"},"execution_count":38,"outputs":[{"output_type":"execute_result","data":{"text/plain":["PerformerLM_quant(\n","  (quant): QuantStub(\n","    (activation_post_process): HistogramObserver(min_val=-5.110640525817871, max_val=5.724368095397949)\n","  )\n","  (dequant): DeQuantStub()\n","  (token_emb): Embedding(\n","    7, 200\n","    (activation_post_process): PlaceholderObserver(dtype=torch.float32, is_dynamic=False)\n","  )\n","  (pos_emb): Gene2VecPositionalEmbedding(\n","    (emb): Embedding(\n","      16907, 200\n","      (activation_post_process): PlaceholderObserver(dtype=torch.float32, is_dynamic=False)\n","    )\n","  )\n","  (layer_pos_emb): Always()\n","  (dropout): Dropout(p=0.0, inplace=False)\n","  (performer): Performer(\n","    (net): SequentialSequence(\n","      (layers): ModuleList(\n","        (0): ModuleList(\n","          (0): PreLayerNorm(\n","            (norm): LayerNorm(\n","              (200,), eps=1e-05, elementwise_affine=True\n","              (activation_post_process): HistogramObserver(min_val=-3.778261423110962, max_val=3.9024288654327393)\n","            )\n","            (fn): SelfAttention(\n","              (fast_attention): FastAttention(\n","                (kernel_fn): ReLU()\n","              )\n","              (to_q): Linear(\n","                in_features=200, out_features=640, bias=False\n","                (activation_post_process): HistogramObserver(min_val=-2.69214129447937, max_val=2.6585679054260254)\n","              )\n","              (to_k): Linear(\n","                in_features=200, out_features=640, bias=False\n","                (activation_post_process): HistogramObserver(min_val=-2.494612216949463, max_val=2.505307197570801)\n","              )\n","              (to_v): Linear(\n","                in_features=200, out_features=640, bias=False\n","                (activation_post_process): HistogramObserver(min_val=-2.432809352874756, max_val=2.428619384765625)\n","              )\n","              (to_out): Linear(\n","                in_features=640, out_features=200, bias=True\n","                (activation_post_process): HistogramObserver(min_val=-1.1456509828567505, max_val=0.9336699843406677)\n","              )\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (1): PreLayerNorm(\n","            (norm): LayerNorm(\n","              (200,), eps=1e-05, elementwise_affine=True\n","              (activation_post_process): HistogramObserver(min_val=-3.7175452709198, max_val=4.05757999420166)\n","            )\n","            (fn): Chunk(\n","              (fn): FeedForward(\n","                (w1): Linear(\n","                  in_features=200, out_features=800, bias=True\n","                  (activation_post_process): HistogramObserver(min_val=-2.758389949798584, max_val=2.693600654602051)\n","                )\n","                (act): GELU(approximate='none')\n","                (dropout): Dropout(p=0.0, inplace=False)\n","                (w2): Linear(\n","                  in_features=800, out_features=200, bias=True\n","                  (activation_post_process): HistogramObserver(min_val=-1.1064807176589966, max_val=1.2398561239242554)\n","                )\n","              )\n","            )\n","          )\n","        )\n","        (1): ModuleList(\n","          (0): PreLayerNorm(\n","            (norm): LayerNorm(\n","              (200,), eps=1e-05, elementwise_affine=True\n","              (activation_post_process): HistogramObserver(min_val=-3.652278423309326, max_val=4.228809356689453)\n","            )\n","            (fn): SelfAttention(\n","              (fast_attention): FastAttention(\n","                (kernel_fn): ReLU()\n","              )\n","              (to_q): Linear(\n","                in_features=200, out_features=640, bias=False\n","                (activation_post_process): HistogramObserver(min_val=-3.1982715129852295, max_val=3.135711431503296)\n","              )\n","              (to_k): Linear(\n","                in_features=200, out_features=640, bias=False\n","                (activation_post_process): HistogramObserver(min_val=-2.744265079498291, max_val=2.627977132797241)\n","              )\n","              (to_v): Linear(\n","                in_features=200, out_features=640, bias=False\n","                (activation_post_process): HistogramObserver(min_val=-2.626105785369873, max_val=2.6195716857910156)\n","              )\n","              (to_out): Linear(\n","                in_features=640, out_features=200, bias=True\n","                (activation_post_process): HistogramObserver(min_val=-1.0244542360305786, max_val=1.1803200244903564)\n","              )\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (1): PreLayerNorm(\n","            (norm): LayerNorm(\n","              (200,), eps=1e-05, elementwise_affine=True\n","              (activation_post_process): HistogramObserver(min_val=-3.891057252883911, max_val=3.9539244174957275)\n","            )\n","            (fn): Chunk(\n","              (fn): FeedForward(\n","                (w1): Linear(\n","                  in_features=200, out_features=800, bias=True\n","                  (activation_post_process): HistogramObserver(min_val=-2.765228271484375, max_val=2.9841489791870117)\n","                )\n","                (act): GELU(approximate='none')\n","                (dropout): Dropout(p=0.0, inplace=False)\n","                (w2): Linear(\n","                  in_features=800, out_features=200, bias=True\n","                  (activation_post_process): HistogramObserver(min_val=-1.0461808443069458, max_val=1.037045955657959)\n","                )\n","              )\n","            )\n","          )\n","        )\n","        (2): ModuleList(\n","          (0): PreLayerNorm(\n","            (norm): LayerNorm(\n","              (200,), eps=1e-05, elementwise_affine=True\n","              (activation_post_process): HistogramObserver(min_val=-3.731564521789551, max_val=3.787799596786499)\n","            )\n","            (fn): SelfAttention(\n","              (fast_attention): FastAttention(\n","                (kernel_fn): ReLU()\n","              )\n","              (to_q): Linear(\n","                in_features=200, out_features=640, bias=False\n","                (activation_post_process): HistogramObserver(min_val=-2.889131784439087, max_val=2.8416385650634766)\n","              )\n","              (to_k): Linear(\n","                in_features=200, out_features=640, bias=False\n","                (activation_post_process): HistogramObserver(min_val=-2.525418281555176, max_val=2.421161651611328)\n","              )\n","              (to_v): Linear(\n","                in_features=200, out_features=640, bias=False\n","                (activation_post_process): HistogramObserver(min_val=-2.4232749938964844, max_val=2.6414389610290527)\n","              )\n","              (to_out): Linear(\n","                in_features=640, out_features=200, bias=True\n","                (activation_post_process): HistogramObserver(min_val=-0.7787982225418091, max_val=0.7910595536231995)\n","              )\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (1): PreLayerNorm(\n","            (norm): LayerNorm(\n","              (200,), eps=1e-05, elementwise_affine=True\n","              (activation_post_process): HistogramObserver(min_val=-4.329277515411377, max_val=4.708266735076904)\n","            )\n","            (fn): Chunk(\n","              (fn): FeedForward(\n","                (w1): Linear(\n","                  in_features=200, out_features=800, bias=True\n","                  (activation_post_process): HistogramObserver(min_val=-2.7698965072631836, max_val=2.8729677200317383)\n","                )\n","                (act): GELU(approximate='none')\n","                (dropout): Dropout(p=0.0, inplace=False)\n","                (w2): Linear(\n","                  in_features=800, out_features=200, bias=True\n","                  (activation_post_process): HistogramObserver(min_val=-1.0909630060195923, max_val=1.096139907836914)\n","                )\n","              )\n","            )\n","          )\n","        )\n","        (3): ModuleList(\n","          (0): PreLayerNorm(\n","            (norm): LayerNorm(\n","              (200,), eps=1e-05, elementwise_affine=True\n","              (activation_post_process): HistogramObserver(min_val=-4.518128871917725, max_val=4.452439308166504)\n","            )\n","            (fn): SelfAttention(\n","              (fast_attention): FastAttention(\n","                (kernel_fn): ReLU()\n","              )\n","              (to_q): Linear(\n","                in_features=200, out_features=640, bias=False\n","                (activation_post_process): HistogramObserver(min_val=-3.089341163635254, max_val=3.0748298168182373)\n","              )\n","              (to_k): Linear(\n","                in_features=200, out_features=640, bias=False\n","                (activation_post_process): HistogramObserver(min_val=-2.6356687545776367, max_val=2.575673818588257)\n","              )\n","              (to_v): Linear(\n","                in_features=200, out_features=640, bias=False\n","                (activation_post_process): HistogramObserver(min_val=-2.994370698928833, max_val=2.9251198768615723)\n","              )\n","              (to_out): Linear(\n","                in_features=640, out_features=200, bias=True\n","                (activation_post_process): HistogramObserver(min_val=-0.7118064761161804, max_val=0.7845442891120911)\n","              )\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (1): PreLayerNorm(\n","            (norm): LayerNorm(\n","              (200,), eps=1e-05, elementwise_affine=True\n","              (activation_post_process): HistogramObserver(min_val=-4.192989826202393, max_val=4.40410041809082)\n","            )\n","            (fn): Chunk(\n","              (fn): FeedForward(\n","                (w1): Linear(\n","                  in_features=200, out_features=800, bias=True\n","                  (activation_post_process): HistogramObserver(min_val=-2.8862993717193604, max_val=2.785637855529785)\n","                )\n","                (act): GELU(approximate='none')\n","                (dropout): Dropout(p=0.0, inplace=False)\n","                (w2): Linear(\n","                  in_features=800, out_features=200, bias=True\n","                  (activation_post_process): HistogramObserver(min_val=-1.0514905452728271, max_val=1.0995151996612549)\n","                )\n","              )\n","            )\n","          )\n","        )\n","        (4): ModuleList(\n","          (0): PreLayerNorm(\n","            (norm): LayerNorm(\n","              (200,), eps=1e-05, elementwise_affine=True\n","              (activation_post_process): HistogramObserver(min_val=-5.378165245056152, max_val=4.431543827056885)\n","            )\n","            (fn): SelfAttention(\n","              (fast_attention): FastAttention(\n","                (kernel_fn): ReLU()\n","              )\n","              (to_q): Linear(\n","                in_features=200, out_features=640, bias=False\n","                (activation_post_process): HistogramObserver(min_val=-3.168015718460083, max_val=3.2348546981811523)\n","              )\n","              (to_k): Linear(\n","                in_features=200, out_features=640, bias=False\n","                (activation_post_process): HistogramObserver(min_val=-2.801513910293579, max_val=2.449878454208374)\n","              )\n","              (to_v): Linear(\n","                in_features=200, out_features=640, bias=False\n","                (activation_post_process): HistogramObserver(min_val=-2.742253065109253, max_val=2.5584473609924316)\n","              )\n","              (to_out): Linear(\n","                in_features=640, out_features=200, bias=True\n","                (activation_post_process): HistogramObserver(min_val=-0.7112011909484863, max_val=0.9172477126121521)\n","              )\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (1): PreLayerNorm(\n","            (norm): LayerNorm(\n","              (200,), eps=1e-05, elementwise_affine=True\n","              (activation_post_process): HistogramObserver(min_val=-5.07258415222168, max_val=4.3310227394104)\n","            )\n","            (fn): Chunk(\n","              (fn): FeedForward(\n","                (w1): Linear(\n","                  in_features=200, out_features=800, bias=True\n","                  (activation_post_process): HistogramObserver(min_val=-3.154526948928833, max_val=2.929048776626587)\n","                )\n","                (act): GELU(approximate='none')\n","                (dropout): Dropout(p=0.0, inplace=False)\n","                (w2): Linear(\n","                  in_features=800, out_features=200, bias=True\n","                  (activation_post_process): HistogramObserver(min_val=-1.2081398963928223, max_val=1.2931679487228394)\n","                )\n","              )\n","            )\n","          )\n","        )\n","        (5): ModuleList(\n","          (0): PreLayerNorm(\n","            (norm): LayerNorm(\n","              (200,), eps=1e-05, elementwise_affine=True\n","              (activation_post_process): HistogramObserver(min_val=-5.015596389770508, max_val=4.416195869445801)\n","            )\n","            (fn): SelfAttention(\n","              (fast_attention): FastAttention(\n","                (kernel_fn): ReLU()\n","              )\n","              (to_q): Linear(\n","                in_features=200, out_features=640, bias=False\n","                (activation_post_process): HistogramObserver(min_val=-2.9048097133636475, max_val=3.0401384830474854)\n","              )\n","              (to_k): Linear(\n","                in_features=200, out_features=640, bias=False\n","                (activation_post_process): HistogramObserver(min_val=-2.4627773761749268, max_val=2.594742774963379)\n","              )\n","              (to_v): Linear(\n","                in_features=200, out_features=640, bias=False\n","                (activation_post_process): HistogramObserver(min_val=-2.6405727863311768, max_val=2.528587579727173)\n","              )\n","              (to_out): Linear(\n","                in_features=640, out_features=200, bias=True\n","                (activation_post_process): HistogramObserver(min_val=-0.8577980399131775, max_val=0.8347498178482056)\n","              )\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (1): PreLayerNorm(\n","            (norm): LayerNorm(\n","              (200,), eps=1e-05, elementwise_affine=True\n","              (activation_post_process): HistogramObserver(min_val=-4.668730735778809, max_val=4.100922584533691)\n","            )\n","            (fn): Chunk(\n","              (fn): FeedForward(\n","                (w1): Linear(\n","                  in_features=200, out_features=800, bias=True\n","                  (activation_post_process): HistogramObserver(min_val=-3.172147274017334, max_val=4.409560680389404)\n","                )\n","                (act): GELU(approximate='none')\n","                (dropout): Dropout(p=0.0, inplace=False)\n","                (w2): Linear(\n","                  in_features=800, out_features=200, bias=True\n","                  (activation_post_process): HistogramObserver(min_val=-1.4936782121658325, max_val=1.779229760169983)\n","                )\n","              )\n","            )\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (norm): LayerNorm(\n","    (200,), eps=1e-05, elementwise_affine=True\n","    (activation_post_process): HistogramObserver(min_val=-4.746884822845459, max_val=3.986906051635742)\n","  )\n","  (to_out): Linear(\n","    in_features=200, out_features=7, bias=True\n","    (activation_post_process): HistogramObserver(min_val=-4.794501781463623, max_val=7.638988971710205)\n","  )\n",")"]},"metadata":{},"execution_count":38}]},{"cell_type":"code","source":["model = model.to('cpu')\n","quant_model = torch.ao.quantization.convert(model, inplace = False)"],"metadata":{"id":"W34C_HyTOmI0","executionInfo":{"status":"ok","timestamp":1715598431055,"user_tz":-330,"elapsed":1092,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}}},"execution_count":39,"outputs":[]},{"cell_type":"code","source":["quant_model"],"metadata":{"id":"SUOxiNBJ_qzz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715598431055,"user_tz":-330,"elapsed":2,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}},"outputId":"3754d073-f1df-49c6-998a-f805e3fdd818"},"execution_count":40,"outputs":[{"output_type":"execute_result","data":{"text/plain":["PerformerLM_quant(\n","  (quant): Quantize(scale=tensor([0.0549]), zero_point=tensor([66]), dtype=torch.quint8)\n","  (dequant): DeQuantize()\n","  (token_emb): QuantizedEmbedding(num_embeddings=7, embedding_dim=200, dtype=torch.quint8, qscheme=torch.per_channel_affine_float_qparams)\n","  (pos_emb): Gene2VecPositionalEmbedding(\n","    (emb): QuantizedEmbedding(num_embeddings=16907, embedding_dim=200, dtype=torch.quint8, qscheme=torch.per_channel_affine_float_qparams)\n","  )\n","  (layer_pos_emb): Always()\n","  (dropout): QuantizedDropout(p=0.0, inplace=False)\n","  (performer): Performer(\n","    (net): SequentialSequence(\n","      (layers): ModuleList(\n","        (0): ModuleList(\n","          (0): PreLayerNorm(\n","            (norm): QuantizedLayerNorm((200,), eps=1e-05, elementwise_affine=True)\n","            (fn): SelfAttention(\n","              (fast_attention): FastAttention(\n","                (kernel_fn): ReLU()\n","              )\n","              (to_q): QuantizedLinear(in_features=200, out_features=640, scale=0.03684454783797264, zero_point=67, qscheme=torch.per_channel_affine)\n","              (to_k): QuantizedLinear(in_features=200, out_features=640, scale=0.03202611953020096, zero_point=58, qscheme=torch.per_channel_affine)\n","              (to_v): QuantizedLinear(in_features=200, out_features=640, scale=0.03199882432818413, zero_point=67, qscheme=torch.per_channel_affine)\n","              (to_out): QuantizedLinear(in_features=640, out_features=200, scale=0.015669094398617744, zero_point=70, qscheme=torch.per_channel_affine)\n","              (dropout): QuantizedDropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (1): PreLayerNorm(\n","            (norm): QuantizedLayerNorm((200,), eps=1e-05, elementwise_affine=True)\n","            (fn): Chunk(\n","              (fn): FeedForward(\n","                (w1): QuantizedLinear(in_features=200, out_features=800, scale=0.03383178636431694, zero_point=65, qscheme=torch.per_channel_affine)\n","                (act): GELU(approximate='none')\n","                (dropout): QuantizedDropout(p=0.0, inplace=False)\n","                (w2): QuantizedLinear(in_features=800, out_features=200, scale=0.01543500181287527, zero_point=65, qscheme=torch.per_channel_affine)\n","              )\n","            )\n","          )\n","        )\n","        (1): ModuleList(\n","          (0): PreLayerNorm(\n","            (norm): QuantizedLayerNorm((200,), eps=1e-05, elementwise_affine=True)\n","            (fn): SelfAttention(\n","              (fast_attention): FastAttention(\n","                (kernel_fn): ReLU()\n","              )\n","              (to_q): QuantizedLinear(in_features=200, out_features=640, scale=0.0369914211332798, zero_point=63, qscheme=torch.per_channel_affine)\n","              (to_k): QuantizedLinear(in_features=200, out_features=640, scale=0.03153994679450989, zero_point=64, qscheme=torch.per_channel_affine)\n","              (to_v): QuantizedLinear(in_features=200, out_features=640, scale=0.03291456028819084, zero_point=64, qscheme=torch.per_channel_affine)\n","              (to_out): QuantizedLinear(in_features=640, out_features=200, scale=0.01663990318775177, zero_point=60, qscheme=torch.per_channel_affine)\n","              (dropout): QuantizedDropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (1): PreLayerNorm(\n","            (norm): QuantizedLayerNorm((200,), eps=1e-05, elementwise_affine=True)\n","            (fn): Chunk(\n","              (fn): FeedForward(\n","                (w1): QuantizedLinear(in_features=200, out_features=800, scale=0.03753400221467018, zero_point=57, qscheme=torch.per_channel_affine)\n","                (act): GELU(approximate='none')\n","                (dropout): QuantizedDropout(p=0.0, inplace=False)\n","                (w2): QuantizedLinear(in_features=800, out_features=200, scale=0.013792277313768864, zero_point=64, qscheme=torch.per_channel_affine)\n","              )\n","            )\n","          )\n","        )\n","        (2): ModuleList(\n","          (0): PreLayerNorm(\n","            (norm): QuantizedLayerNorm((200,), eps=1e-05, elementwise_affine=True)\n","            (fn): SelfAttention(\n","              (fast_attention): FastAttention(\n","                (kernel_fn): ReLU()\n","              )\n","              (to_q): QuantizedLinear(in_features=200, out_features=640, scale=0.03201436623930931, zero_point=64, qscheme=torch.per_channel_affine)\n","              (to_k): QuantizedLinear(in_features=200, out_features=640, scale=0.02848939038813114, zero_point=64, qscheme=torch.per_channel_affine)\n","              (to_v): QuantizedLinear(in_features=200, out_features=640, scale=0.03090282715857029, zero_point=65, qscheme=torch.per_channel_affine)\n","              (to_out): QuantizedLinear(in_features=640, out_features=200, scale=0.012053264304995537, zero_point=63, qscheme=torch.per_channel_affine)\n","              (dropout): QuantizedDropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (1): PreLayerNorm(\n","            (norm): QuantizedLayerNorm((200,), eps=1e-05, elementwise_affine=True)\n","            (fn): Chunk(\n","              (fn): FeedForward(\n","                (w1): QuantizedLinear(in_features=200, out_features=800, scale=0.03495115041732788, zero_point=68, qscheme=torch.per_channel_affine)\n","                (act): GELU(approximate='none')\n","                (dropout): QuantizedDropout(p=0.0, inplace=False)\n","                (w2): QuantizedLinear(in_features=800, out_features=200, scale=0.014740677550435066, zero_point=62, qscheme=torch.per_channel_affine)\n","              )\n","            )\n","          )\n","        )\n","        (3): ModuleList(\n","          (0): PreLayerNorm(\n","            (norm): QuantizedLayerNorm((200,), eps=1e-05, elementwise_affine=True)\n","            (fn): SelfAttention(\n","              (fast_attention): FastAttention(\n","                (kernel_fn): ReLU()\n","              )\n","              (to_q): QuantizedLinear(in_features=200, out_features=640, scale=0.03680547699332237, zero_point=62, qscheme=torch.per_channel_affine)\n","              (to_k): QuantizedLinear(in_features=200, out_features=640, scale=0.0325588695704937, zero_point=68, qscheme=torch.per_channel_affine)\n","              (to_v): QuantizedLinear(in_features=200, out_features=640, scale=0.03129344433546066, zero_point=64, qscheme=torch.per_channel_affine)\n","              (to_out): QuantizedLinear(in_features=640, out_features=200, scale=0.011557919904589653, zero_point=60, qscheme=torch.per_channel_affine)\n","              (dropout): QuantizedDropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (1): PreLayerNorm(\n","            (norm): QuantizedLayerNorm((200,), eps=1e-05, elementwise_affine=True)\n","            (fn): Chunk(\n","              (fn): FeedForward(\n","                (w1): QuantizedLinear(in_features=200, out_features=800, scale=0.03367014601826668, zero_point=60, qscheme=torch.per_channel_affine)\n","                (act): GELU(approximate='none')\n","                (dropout): QuantizedDropout(p=0.0, inplace=False)\n","                (w2): QuantizedLinear(in_features=800, out_features=200, scale=0.014025996439158916, zero_point=62, qscheme=torch.per_channel_affine)\n","              )\n","            )\n","          )\n","        )\n","        (4): ModuleList(\n","          (0): PreLayerNorm(\n","            (norm): QuantizedLayerNorm((200,), eps=1e-05, elementwise_affine=True)\n","            (fn): SelfAttention(\n","              (fast_attention): FastAttention(\n","                (kernel_fn): ReLU()\n","              )\n","              (to_q): QuantizedLinear(in_features=200, out_features=640, scale=0.03335648775100708, zero_point=60, qscheme=torch.per_channel_affine)\n","              (to_k): QuantizedLinear(in_features=200, out_features=640, scale=0.032223574817180634, zero_point=63, qscheme=torch.per_channel_affine)\n","              (to_v): QuantizedLinear(in_features=200, out_features=640, scale=0.03136448934674263, zero_point=66, qscheme=torch.per_channel_affine)\n","              (to_out): QuantizedLinear(in_features=640, out_features=200, scale=0.012309035286307335, zero_point=55, qscheme=torch.per_channel_affine)\n","              (dropout): QuantizedDropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (1): PreLayerNorm(\n","            (norm): QuantizedLayerNorm((200,), eps=1e-05, elementwise_affine=True)\n","            (fn): Chunk(\n","              (fn): FeedForward(\n","                (w1): QuantizedLinear(in_features=200, out_features=800, scale=0.03377477452158928, zero_point=63, qscheme=torch.per_channel_affine)\n","                (act): GELU(approximate='none')\n","                (dropout): QuantizedDropout(p=0.0, inplace=False)\n","                (w2): QuantizedLinear(in_features=800, out_features=200, scale=0.01625250093638897, zero_point=64, qscheme=torch.per_channel_affine)\n","              )\n","            )\n","          )\n","        )\n","        (5): ModuleList(\n","          (0): PreLayerNorm(\n","            (norm): QuantizedLayerNorm((200,), eps=1e-05, elementwise_affine=True)\n","            (fn): SelfAttention(\n","              (fast_attention): FastAttention(\n","                (kernel_fn): ReLU()\n","              )\n","              (to_q): QuantizedLinear(in_features=200, out_features=640, scale=0.031245172023773193, zero_point=67, qscheme=torch.per_channel_affine)\n","              (to_k): QuantizedLinear(in_features=200, out_features=640, scale=0.03159783035516739, zero_point=62, qscheme=torch.per_channel_affine)\n","              (to_v): QuantizedLinear(in_features=200, out_features=640, scale=0.03263318911194801, zero_point=67, qscheme=torch.per_channel_affine)\n","              (to_out): QuantizedLinear(in_features=640, out_features=200, scale=0.012800049968063831, zero_point=64, qscheme=torch.per_channel_affine)\n","              (dropout): QuantizedDropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (1): PreLayerNorm(\n","            (norm): QuantizedLayerNorm((200,), eps=1e-05, elementwise_affine=True)\n","            (fn): Chunk(\n","              (fn): FeedForward(\n","                (w1): QuantizedLinear(in_features=200, out_features=800, scale=0.037923697382211685, zero_point=62, qscheme=torch.per_channel_affine)\n","                (act): GELU(approximate='none')\n","                (dropout): QuantizedDropout(p=0.0, inplace=False)\n","                (w2): QuantizedLinear(in_features=800, out_features=200, scale=0.0182711873203516, zero_point=62, qscheme=torch.per_channel_affine)\n","              )\n","            )\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (norm): QuantizedLayerNorm((200,), eps=1e-05, elementwise_affine=True)\n","  (to_out): QuantizedLinear(in_features=200, out_features=7, scale=0.09235630184412003, zero_point=47, qscheme=torch.per_channel_affine)\n",")"]},"metadata":{},"execution_count":40}]},{"cell_type":"code","source":["t = next(iter(val_loader))"],"metadata":{"id":"KGi5uugUocnO","executionInfo":{"status":"ok","timestamp":1715598496319,"user_tz":-330,"elapsed":320,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}}},"execution_count":47,"outputs":[]},{"cell_type":"code","source":["t[0].to('cpu')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NcUTKHVJoxU7","executionInfo":{"status":"ok","timestamp":1715598483625,"user_tz":-330,"elapsed":2,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}},"outputId":"ef180aef-b7fc-4e00-c8d9-9403c4b35ffd"},"execution_count":45,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0, 0, 0,  ..., 0, 0, 0])"]},"metadata":{},"execution_count":45}]},{"cell_type":"code","source":["model_result = model(t.to('cpu'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aCwf_CWLo2YJ","executionInfo":{"status":"ok","timestamp":1715598519043,"user_tz":-330,"elapsed":6902,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}},"outputId":"3123a258-31a7-4af9-bd41-ae9089ae44b4"},"execution_count":49,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[-0.2310,  1.2989,  0.0341,  ..., -0.4952,  0.6045, -0.8916],\n","         [-0.1635,  1.1905,  0.0030,  ..., -0.3954,  0.9010, -0.8225],\n","         [-0.4919,  1.0702,  0.1793,  ..., -0.3885,  0.7581, -1.0574],\n","         ...,\n","         [-0.2972,  0.9968,  0.0241,  ..., -0.3113,  0.6009, -0.7958],\n","         [-0.3710,  1.0941,  0.1565,  ..., -0.3415,  0.6977, -0.7443],\n","         [-0.2857,  1.1152,  0.1111,  ..., -0.3227,  0.7436, -0.8916]]],\n","       grad_fn=<ViewBackward0>)"]},"metadata":{},"execution_count":49}]},{"cell_type":"code","source":["quant_model.to('cpu')\n","result = quant_model(t.to('cpu'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":304},"id":"t3ujDsAwpAqq","executionInfo":{"status":"error","timestamp":1715598720929,"user_tz":-330,"elapsed":398,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}},"outputId":"1a12f1e1-4c05-4f5b-eabb-b7af9bed9870"},"execution_count":55,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"empty_strided not supported on quantized tensors yet see https://github.com/pytorch/pytorch/issues/74540","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-55-eb21451a6545>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mquant_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquant_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/scFasterBERT/performer_pytorch/performer_pytorch.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, return_encodings, output_attentions, **kwargs)\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_pos_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_attentions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m             \u001b[0;31m# norm and to logits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/scFasterBERT/performer_pytorch/performer_pytorch.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, output_attentions, **kwargs)\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_check_redraw\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_redraw_projections\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_attentions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mPerformerLM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/scFasterBERT/performer_pytorch/reversible.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, output_attentions, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m                 \u001b[0mattn_weights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_attentions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mf_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mf_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mg_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutput_attentions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/scFasterBERT/performer_pytorch/performer_pytorch.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, **kwargs)\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mChunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/scFasterBERT/performer_pytorch/performer_pytorch.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, pos_emb, context, mask, context_mask, output_attentions, **kwargs)\u001b[0m\n\u001b[1;32m    393\u001b[0m                 \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfast_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_attentions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfast_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m             \u001b[0mattn_outs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/scFasterBERT/performer_pytorch/performer_pytorch.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, q, k, v, output_attentions)\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m             \u001b[0mcreate_kernel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msoftmax_kernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprojection_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprojection_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m             \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_kernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_query\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m             \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_kernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_query\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/scFasterBERT/performer_pytorch/performer_pytorch.py\u001b[0m in \u001b[0;36msoftmax_kernel\u001b[0;34m(data, projection_matrix, is_query, normalize_data, eps, device)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0mprojection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprojection_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'j d -> b h j d'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m     \u001b[0mprojection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprojection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0mdata_dash\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'...id,...jd->...ij'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata_normalizer\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprojection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: empty_strided not supported on quantized tensors yet see https://github.com/pytorch/pytorch/issues/74540"]}]},{"cell_type":"code","source":["model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WLZszZpVO0Pf","executionInfo":{"status":"ok","timestamp":1715598436866,"user_tz":-330,"elapsed":528,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}},"outputId":"6c3eec9e-8d05-4255-8037-f215eeb94b0a"},"execution_count":41,"outputs":[{"output_type":"execute_result","data":{"text/plain":["PerformerLM_quant(\n","  (quant): QuantStub(\n","    (activation_post_process): HistogramObserver(min_val=-5.110640525817871, max_val=5.724368095397949)\n","  )\n","  (dequant): DeQuantStub()\n","  (token_emb): Embedding(\n","    7, 200\n","    (activation_post_process): PlaceholderObserver(dtype=torch.float32, is_dynamic=False)\n","  )\n","  (pos_emb): Gene2VecPositionalEmbedding(\n","    (emb): Embedding(\n","      16907, 200\n","      (activation_post_process): PlaceholderObserver(dtype=torch.float32, is_dynamic=False)\n","    )\n","  )\n","  (layer_pos_emb): Always()\n","  (dropout): Dropout(p=0.0, inplace=False)\n","  (performer): Performer(\n","    (net): SequentialSequence(\n","      (layers): ModuleList(\n","        (0): ModuleList(\n","          (0): PreLayerNorm(\n","            (norm): LayerNorm(\n","              (200,), eps=1e-05, elementwise_affine=True\n","              (activation_post_process): HistogramObserver(min_val=-3.778261423110962, max_val=3.9024288654327393)\n","            )\n","            (fn): SelfAttention(\n","              (fast_attention): FastAttention(\n","                (kernel_fn): ReLU()\n","              )\n","              (to_q): Linear(\n","                in_features=200, out_features=640, bias=False\n","                (activation_post_process): HistogramObserver(min_val=-2.69214129447937, max_val=2.6585679054260254)\n","              )\n","              (to_k): Linear(\n","                in_features=200, out_features=640, bias=False\n","                (activation_post_process): HistogramObserver(min_val=-2.494612216949463, max_val=2.505307197570801)\n","              )\n","              (to_v): Linear(\n","                in_features=200, out_features=640, bias=False\n","                (activation_post_process): HistogramObserver(min_val=-2.432809352874756, max_val=2.428619384765625)\n","              )\n","              (to_out): Linear(\n","                in_features=640, out_features=200, bias=True\n","                (activation_post_process): HistogramObserver(min_val=-1.1456509828567505, max_val=0.9336699843406677)\n","              )\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (1): PreLayerNorm(\n","            (norm): LayerNorm(\n","              (200,), eps=1e-05, elementwise_affine=True\n","              (activation_post_process): HistogramObserver(min_val=-3.7175452709198, max_val=4.05757999420166)\n","            )\n","            (fn): Chunk(\n","              (fn): FeedForward(\n","                (w1): Linear(\n","                  in_features=200, out_features=800, bias=True\n","                  (activation_post_process): HistogramObserver(min_val=-2.758389949798584, max_val=2.693600654602051)\n","                )\n","                (act): GELU(approximate='none')\n","                (dropout): Dropout(p=0.0, inplace=False)\n","                (w2): Linear(\n","                  in_features=800, out_features=200, bias=True\n","                  (activation_post_process): HistogramObserver(min_val=-1.1064807176589966, max_val=1.2398561239242554)\n","                )\n","              )\n","            )\n","          )\n","        )\n","        (1): ModuleList(\n","          (0): PreLayerNorm(\n","            (norm): LayerNorm(\n","              (200,), eps=1e-05, elementwise_affine=True\n","              (activation_post_process): HistogramObserver(min_val=-3.652278423309326, max_val=4.228809356689453)\n","            )\n","            (fn): SelfAttention(\n","              (fast_attention): FastAttention(\n","                (kernel_fn): ReLU()\n","              )\n","              (to_q): Linear(\n","                in_features=200, out_features=640, bias=False\n","                (activation_post_process): HistogramObserver(min_val=-3.1982715129852295, max_val=3.135711431503296)\n","              )\n","              (to_k): Linear(\n","                in_features=200, out_features=640, bias=False\n","                (activation_post_process): HistogramObserver(min_val=-2.744265079498291, max_val=2.627977132797241)\n","              )\n","              (to_v): Linear(\n","                in_features=200, out_features=640, bias=False\n","                (activation_post_process): HistogramObserver(min_val=-2.626105785369873, max_val=2.6195716857910156)\n","              )\n","              (to_out): Linear(\n","                in_features=640, out_features=200, bias=True\n","                (activation_post_process): HistogramObserver(min_val=-1.0244542360305786, max_val=1.1803200244903564)\n","              )\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (1): PreLayerNorm(\n","            (norm): LayerNorm(\n","              (200,), eps=1e-05, elementwise_affine=True\n","              (activation_post_process): HistogramObserver(min_val=-3.891057252883911, max_val=3.9539244174957275)\n","            )\n","            (fn): Chunk(\n","              (fn): FeedForward(\n","                (w1): Linear(\n","                  in_features=200, out_features=800, bias=True\n","                  (activation_post_process): HistogramObserver(min_val=-2.765228271484375, max_val=2.9841489791870117)\n","                )\n","                (act): GELU(approximate='none')\n","                (dropout): Dropout(p=0.0, inplace=False)\n","                (w2): Linear(\n","                  in_features=800, out_features=200, bias=True\n","                  (activation_post_process): HistogramObserver(min_val=-1.0461808443069458, max_val=1.037045955657959)\n","                )\n","              )\n","            )\n","          )\n","        )\n","        (2): ModuleList(\n","          (0): PreLayerNorm(\n","            (norm): LayerNorm(\n","              (200,), eps=1e-05, elementwise_affine=True\n","              (activation_post_process): HistogramObserver(min_val=-3.731564521789551, max_val=3.787799596786499)\n","            )\n","            (fn): SelfAttention(\n","              (fast_attention): FastAttention(\n","                (kernel_fn): ReLU()\n","              )\n","              (to_q): Linear(\n","                in_features=200, out_features=640, bias=False\n","                (activation_post_process): HistogramObserver(min_val=-2.889131784439087, max_val=2.8416385650634766)\n","              )\n","              (to_k): Linear(\n","                in_features=200, out_features=640, bias=False\n","                (activation_post_process): HistogramObserver(min_val=-2.525418281555176, max_val=2.421161651611328)\n","              )\n","              (to_v): Linear(\n","                in_features=200, out_features=640, bias=False\n","                (activation_post_process): HistogramObserver(min_val=-2.4232749938964844, max_val=2.6414389610290527)\n","              )\n","              (to_out): Linear(\n","                in_features=640, out_features=200, bias=True\n","                (activation_post_process): HistogramObserver(min_val=-0.7787982225418091, max_val=0.7910595536231995)\n","              )\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (1): PreLayerNorm(\n","            (norm): LayerNorm(\n","              (200,), eps=1e-05, elementwise_affine=True\n","              (activation_post_process): HistogramObserver(min_val=-4.329277515411377, max_val=4.708266735076904)\n","            )\n","            (fn): Chunk(\n","              (fn): FeedForward(\n","                (w1): Linear(\n","                  in_features=200, out_features=800, bias=True\n","                  (activation_post_process): HistogramObserver(min_val=-2.7698965072631836, max_val=2.8729677200317383)\n","                )\n","                (act): GELU(approximate='none')\n","                (dropout): Dropout(p=0.0, inplace=False)\n","                (w2): Linear(\n","                  in_features=800, out_features=200, bias=True\n","                  (activation_post_process): HistogramObserver(min_val=-1.0909630060195923, max_val=1.096139907836914)\n","                )\n","              )\n","            )\n","          )\n","        )\n","        (3): ModuleList(\n","          (0): PreLayerNorm(\n","            (norm): LayerNorm(\n","              (200,), eps=1e-05, elementwise_affine=True\n","              (activation_post_process): HistogramObserver(min_val=-4.518128871917725, max_val=4.452439308166504)\n","            )\n","            (fn): SelfAttention(\n","              (fast_attention): FastAttention(\n","                (kernel_fn): ReLU()\n","              )\n","              (to_q): Linear(\n","                in_features=200, out_features=640, bias=False\n","                (activation_post_process): HistogramObserver(min_val=-3.089341163635254, max_val=3.0748298168182373)\n","              )\n","              (to_k): Linear(\n","                in_features=200, out_features=640, bias=False\n","                (activation_post_process): HistogramObserver(min_val=-2.6356687545776367, max_val=2.575673818588257)\n","              )\n","              (to_v): Linear(\n","                in_features=200, out_features=640, bias=False\n","                (activation_post_process): HistogramObserver(min_val=-2.994370698928833, max_val=2.9251198768615723)\n","              )\n","              (to_out): Linear(\n","                in_features=640, out_features=200, bias=True\n","                (activation_post_process): HistogramObserver(min_val=-0.7118064761161804, max_val=0.7845442891120911)\n","              )\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (1): PreLayerNorm(\n","            (norm): LayerNorm(\n","              (200,), eps=1e-05, elementwise_affine=True\n","              (activation_post_process): HistogramObserver(min_val=-4.192989826202393, max_val=4.40410041809082)\n","            )\n","            (fn): Chunk(\n","              (fn): FeedForward(\n","                (w1): Linear(\n","                  in_features=200, out_features=800, bias=True\n","                  (activation_post_process): HistogramObserver(min_val=-2.8862993717193604, max_val=2.785637855529785)\n","                )\n","                (act): GELU(approximate='none')\n","                (dropout): Dropout(p=0.0, inplace=False)\n","                (w2): Linear(\n","                  in_features=800, out_features=200, bias=True\n","                  (activation_post_process): HistogramObserver(min_val=-1.0514905452728271, max_val=1.0995151996612549)\n","                )\n","              )\n","            )\n","          )\n","        )\n","        (4): ModuleList(\n","          (0): PreLayerNorm(\n","            (norm): LayerNorm(\n","              (200,), eps=1e-05, elementwise_affine=True\n","              (activation_post_process): HistogramObserver(min_val=-5.378165245056152, max_val=4.431543827056885)\n","            )\n","            (fn): SelfAttention(\n","              (fast_attention): FastAttention(\n","                (kernel_fn): ReLU()\n","              )\n","              (to_q): Linear(\n","                in_features=200, out_features=640, bias=False\n","                (activation_post_process): HistogramObserver(min_val=-3.168015718460083, max_val=3.2348546981811523)\n","              )\n","              (to_k): Linear(\n","                in_features=200, out_features=640, bias=False\n","                (activation_post_process): HistogramObserver(min_val=-2.801513910293579, max_val=2.449878454208374)\n","              )\n","              (to_v): Linear(\n","                in_features=200, out_features=640, bias=False\n","                (activation_post_process): HistogramObserver(min_val=-2.742253065109253, max_val=2.5584473609924316)\n","              )\n","              (to_out): Linear(\n","                in_features=640, out_features=200, bias=True\n","                (activation_post_process): HistogramObserver(min_val=-0.7112011909484863, max_val=0.9172477126121521)\n","              )\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (1): PreLayerNorm(\n","            (norm): LayerNorm(\n","              (200,), eps=1e-05, elementwise_affine=True\n","              (activation_post_process): HistogramObserver(min_val=-5.07258415222168, max_val=4.3310227394104)\n","            )\n","            (fn): Chunk(\n","              (fn): FeedForward(\n","                (w1): Linear(\n","                  in_features=200, out_features=800, bias=True\n","                  (activation_post_process): HistogramObserver(min_val=-3.154526948928833, max_val=2.929048776626587)\n","                )\n","                (act): GELU(approximate='none')\n","                (dropout): Dropout(p=0.0, inplace=False)\n","                (w2): Linear(\n","                  in_features=800, out_features=200, bias=True\n","                  (activation_post_process): HistogramObserver(min_val=-1.2081398963928223, max_val=1.2931679487228394)\n","                )\n","              )\n","            )\n","          )\n","        )\n","        (5): ModuleList(\n","          (0): PreLayerNorm(\n","            (norm): LayerNorm(\n","              (200,), eps=1e-05, elementwise_affine=True\n","              (activation_post_process): HistogramObserver(min_val=-5.015596389770508, max_val=4.416195869445801)\n","            )\n","            (fn): SelfAttention(\n","              (fast_attention): FastAttention(\n","                (kernel_fn): ReLU()\n","              )\n","              (to_q): Linear(\n","                in_features=200, out_features=640, bias=False\n","                (activation_post_process): HistogramObserver(min_val=-2.9048097133636475, max_val=3.0401384830474854)\n","              )\n","              (to_k): Linear(\n","                in_features=200, out_features=640, bias=False\n","                (activation_post_process): HistogramObserver(min_val=-2.4627773761749268, max_val=2.594742774963379)\n","              )\n","              (to_v): Linear(\n","                in_features=200, out_features=640, bias=False\n","                (activation_post_process): HistogramObserver(min_val=-2.6405727863311768, max_val=2.528587579727173)\n","              )\n","              (to_out): Linear(\n","                in_features=640, out_features=200, bias=True\n","                (activation_post_process): HistogramObserver(min_val=-0.8577980399131775, max_val=0.8347498178482056)\n","              )\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (1): PreLayerNorm(\n","            (norm): LayerNorm(\n","              (200,), eps=1e-05, elementwise_affine=True\n","              (activation_post_process): HistogramObserver(min_val=-4.668730735778809, max_val=4.100922584533691)\n","            )\n","            (fn): Chunk(\n","              (fn): FeedForward(\n","                (w1): Linear(\n","                  in_features=200, out_features=800, bias=True\n","                  (activation_post_process): HistogramObserver(min_val=-3.172147274017334, max_val=4.409560680389404)\n","                )\n","                (act): GELU(approximate='none')\n","                (dropout): Dropout(p=0.0, inplace=False)\n","                (w2): Linear(\n","                  in_features=800, out_features=200, bias=True\n","                  (activation_post_process): HistogramObserver(min_val=-1.4936782121658325, max_val=1.779229760169983)\n","                )\n","              )\n","            )\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (norm): LayerNorm(\n","    (200,), eps=1e-05, elementwise_affine=True\n","    (activation_post_process): HistogramObserver(min_val=-4.746884822845459, max_val=3.986906051635742)\n","  )\n","  (to_out): Linear(\n","    in_features=200, out_features=7, bias=True\n","    (activation_post_process): HistogramObserver(min_val=-4.794501781463623, max_val=7.638988971710205)\n","  )\n",")"]},"metadata":{},"execution_count":41}]},{"cell_type":"code","source":["def print_size_of_model(model):\n","    torch.save(model.state_dict(), \"temp_delme.p\")\n","    print('Size (KB):', os.path.getsize(\"temp_delme.p\")/1e3)\n","    os.remove('temp_delme.p')\n"],"metadata":{"id":"dKs50c_cO6hF","executionInfo":{"status":"ok","timestamp":1715598249507,"user_tz":-330,"elapsed":3,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["print_size_of_model(quant_model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4HAcdRYGrkBy","executionInfo":{"status":"ok","timestamp":1715597643962,"user_tz":-330,"elapsed":2,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}},"outputId":"0562c45c-1db2-40cf-fbea-dc68bf4f2514"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["Size (KB): 9361.357\n"]}]},{"cell_type":"code","source":["torch.save(quant_model.state_dict(), \"Q-scbert.pth\")"],"metadata":{"id":"3jsixdd-PR7m","executionInfo":{"status":"ok","timestamp":1715597656242,"user_tz":-330,"elapsed":431,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["loaded_model = PerformerLM_quant(\n","    num_tokens = CLASS,\n","    dim = 200,\n","    depth = 6,\n","    max_seq_len = SEQ_LEN,\n","    heads = 10,\n","    local_attn_heads = 0,\n","    g2v_position_emb = POS_EMBED_USING\n","    )"],"metadata":{"id":"INJbDtqJ8dDt","executionInfo":{"status":"ok","timestamp":1715597661383,"user_tz":-330,"elapsed":2,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["y[0].view(1,1,-1).shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dU2Vi-ElEHMd","executionInfo":{"status":"ok","timestamp":1714499521678,"user_tz":-330,"elapsed":4,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}},"outputId":"849a04f9-f416-4037-9062-48bd8835ed12"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 1, 16907])"]},"metadata":{},"execution_count":163}]},{"cell_type":"code","source":["loaded_dict_enc = torch.load('Q-scbert.pth', map_location='cpu')"],"metadata":{"id":"xC-uXCyWGYTR","executionInfo":{"status":"ok","timestamp":1715597700445,"user_tz":-330,"elapsed":684,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","source":["loaded_model.load_state_dict(loaded_dict_enc, strict = False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-_Wn2KeTCPZx","executionInfo":{"status":"ok","timestamp":1715597704916,"user_tz":-330,"elapsed":2,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}},"outputId":"f279ce54-05f9-4722-a378-0f67d2bfba82"},"execution_count":37,"outputs":[{"output_type":"execute_result","data":{"text/plain":["_IncompatibleKeys(missing_keys=['token_emb.weight', 'pos_emb.emb.weight', 'performer.net.layers.0.0.fn.to_q.weight', 'performer.net.layers.0.0.fn.to_k.weight', 'performer.net.layers.0.0.fn.to_v.weight', 'performer.net.layers.0.0.fn.to_out.weight', 'performer.net.layers.0.0.fn.to_out.bias', 'performer.net.layers.0.1.fn.fn.w1.weight', 'performer.net.layers.0.1.fn.fn.w1.bias', 'performer.net.layers.0.1.fn.fn.w2.weight', 'performer.net.layers.0.1.fn.fn.w2.bias', 'performer.net.layers.1.0.fn.to_q.weight', 'performer.net.layers.1.0.fn.to_k.weight', 'performer.net.layers.1.0.fn.to_v.weight', 'performer.net.layers.1.0.fn.to_out.weight', 'performer.net.layers.1.0.fn.to_out.bias', 'performer.net.layers.1.1.fn.fn.w1.weight', 'performer.net.layers.1.1.fn.fn.w1.bias', 'performer.net.layers.1.1.fn.fn.w2.weight', 'performer.net.layers.1.1.fn.fn.w2.bias', 'performer.net.layers.2.0.fn.to_q.weight', 'performer.net.layers.2.0.fn.to_k.weight', 'performer.net.layers.2.0.fn.to_v.weight', 'performer.net.layers.2.0.fn.to_out.weight', 'performer.net.layers.2.0.fn.to_out.bias', 'performer.net.layers.2.1.fn.fn.w1.weight', 'performer.net.layers.2.1.fn.fn.w1.bias', 'performer.net.layers.2.1.fn.fn.w2.weight', 'performer.net.layers.2.1.fn.fn.w2.bias', 'performer.net.layers.3.0.fn.to_q.weight', 'performer.net.layers.3.0.fn.to_k.weight', 'performer.net.layers.3.0.fn.to_v.weight', 'performer.net.layers.3.0.fn.to_out.weight', 'performer.net.layers.3.0.fn.to_out.bias', 'performer.net.layers.3.1.fn.fn.w1.weight', 'performer.net.layers.3.1.fn.fn.w1.bias', 'performer.net.layers.3.1.fn.fn.w2.weight', 'performer.net.layers.3.1.fn.fn.w2.bias', 'performer.net.layers.4.0.fn.to_q.weight', 'performer.net.layers.4.0.fn.to_k.weight', 'performer.net.layers.4.0.fn.to_v.weight', 'performer.net.layers.4.0.fn.to_out.weight', 'performer.net.layers.4.0.fn.to_out.bias', 'performer.net.layers.4.1.fn.fn.w1.weight', 'performer.net.layers.4.1.fn.fn.w1.bias', 'performer.net.layers.4.1.fn.fn.w2.weight', 'performer.net.layers.4.1.fn.fn.w2.bias', 'performer.net.layers.5.0.fn.to_q.weight', 'performer.net.layers.5.0.fn.to_k.weight', 'performer.net.layers.5.0.fn.to_v.weight', 'performer.net.layers.5.0.fn.to_out.weight', 'performer.net.layers.5.0.fn.to_out.bias', 'performer.net.layers.5.1.fn.fn.w1.weight', 'performer.net.layers.5.1.fn.fn.w1.bias', 'performer.net.layers.5.1.fn.fn.w2.weight', 'performer.net.layers.5.1.fn.fn.w2.bias', 'to_out.weight', 'to_out.bias'], unexpected_keys=['quant.scale', 'quant.zero_point', 'token_emb._packed_params.dtype', 'token_emb._packed_params._packed_weight', 'pos_emb.emb._packed_params.dtype', 'pos_emb.emb._packed_params._packed_weight', 'performer.net.layers.0.0.norm.scale', 'performer.net.layers.0.0.norm.zero_point', 'performer.net.layers.0.0.fn.to_q.scale', 'performer.net.layers.0.0.fn.to_q.zero_point', 'performer.net.layers.0.0.fn.to_q._packed_params.dtype', 'performer.net.layers.0.0.fn.to_q._packed_params._packed_params', 'performer.net.layers.0.0.fn.to_k.scale', 'performer.net.layers.0.0.fn.to_k.zero_point', 'performer.net.layers.0.0.fn.to_k._packed_params.dtype', 'performer.net.layers.0.0.fn.to_k._packed_params._packed_params', 'performer.net.layers.0.0.fn.to_v.scale', 'performer.net.layers.0.0.fn.to_v.zero_point', 'performer.net.layers.0.0.fn.to_v._packed_params.dtype', 'performer.net.layers.0.0.fn.to_v._packed_params._packed_params', 'performer.net.layers.0.0.fn.to_out.scale', 'performer.net.layers.0.0.fn.to_out.zero_point', 'performer.net.layers.0.0.fn.to_out._packed_params.dtype', 'performer.net.layers.0.0.fn.to_out._packed_params._packed_params', 'performer.net.layers.0.1.norm.scale', 'performer.net.layers.0.1.norm.zero_point', 'performer.net.layers.0.1.fn.fn.w1.scale', 'performer.net.layers.0.1.fn.fn.w1.zero_point', 'performer.net.layers.0.1.fn.fn.w1._packed_params.dtype', 'performer.net.layers.0.1.fn.fn.w1._packed_params._packed_params', 'performer.net.layers.0.1.fn.fn.w2.scale', 'performer.net.layers.0.1.fn.fn.w2.zero_point', 'performer.net.layers.0.1.fn.fn.w2._packed_params.dtype', 'performer.net.layers.0.1.fn.fn.w2._packed_params._packed_params', 'performer.net.layers.1.0.norm.scale', 'performer.net.layers.1.0.norm.zero_point', 'performer.net.layers.1.0.fn.to_q.scale', 'performer.net.layers.1.0.fn.to_q.zero_point', 'performer.net.layers.1.0.fn.to_q._packed_params.dtype', 'performer.net.layers.1.0.fn.to_q._packed_params._packed_params', 'performer.net.layers.1.0.fn.to_k.scale', 'performer.net.layers.1.0.fn.to_k.zero_point', 'performer.net.layers.1.0.fn.to_k._packed_params.dtype', 'performer.net.layers.1.0.fn.to_k._packed_params._packed_params', 'performer.net.layers.1.0.fn.to_v.scale', 'performer.net.layers.1.0.fn.to_v.zero_point', 'performer.net.layers.1.0.fn.to_v._packed_params.dtype', 'performer.net.layers.1.0.fn.to_v._packed_params._packed_params', 'performer.net.layers.1.0.fn.to_out.scale', 'performer.net.layers.1.0.fn.to_out.zero_point', 'performer.net.layers.1.0.fn.to_out._packed_params.dtype', 'performer.net.layers.1.0.fn.to_out._packed_params._packed_params', 'performer.net.layers.1.1.norm.scale', 'performer.net.layers.1.1.norm.zero_point', 'performer.net.layers.1.1.fn.fn.w1.scale', 'performer.net.layers.1.1.fn.fn.w1.zero_point', 'performer.net.layers.1.1.fn.fn.w1._packed_params.dtype', 'performer.net.layers.1.1.fn.fn.w1._packed_params._packed_params', 'performer.net.layers.1.1.fn.fn.w2.scale', 'performer.net.layers.1.1.fn.fn.w2.zero_point', 'performer.net.layers.1.1.fn.fn.w2._packed_params.dtype', 'performer.net.layers.1.1.fn.fn.w2._packed_params._packed_params', 'performer.net.layers.2.0.norm.scale', 'performer.net.layers.2.0.norm.zero_point', 'performer.net.layers.2.0.fn.to_q.scale', 'performer.net.layers.2.0.fn.to_q.zero_point', 'performer.net.layers.2.0.fn.to_q._packed_params.dtype', 'performer.net.layers.2.0.fn.to_q._packed_params._packed_params', 'performer.net.layers.2.0.fn.to_k.scale', 'performer.net.layers.2.0.fn.to_k.zero_point', 'performer.net.layers.2.0.fn.to_k._packed_params.dtype', 'performer.net.layers.2.0.fn.to_k._packed_params._packed_params', 'performer.net.layers.2.0.fn.to_v.scale', 'performer.net.layers.2.0.fn.to_v.zero_point', 'performer.net.layers.2.0.fn.to_v._packed_params.dtype', 'performer.net.layers.2.0.fn.to_v._packed_params._packed_params', 'performer.net.layers.2.0.fn.to_out.scale', 'performer.net.layers.2.0.fn.to_out.zero_point', 'performer.net.layers.2.0.fn.to_out._packed_params.dtype', 'performer.net.layers.2.0.fn.to_out._packed_params._packed_params', 'performer.net.layers.2.1.norm.scale', 'performer.net.layers.2.1.norm.zero_point', 'performer.net.layers.2.1.fn.fn.w1.scale', 'performer.net.layers.2.1.fn.fn.w1.zero_point', 'performer.net.layers.2.1.fn.fn.w1._packed_params.dtype', 'performer.net.layers.2.1.fn.fn.w1._packed_params._packed_params', 'performer.net.layers.2.1.fn.fn.w2.scale', 'performer.net.layers.2.1.fn.fn.w2.zero_point', 'performer.net.layers.2.1.fn.fn.w2._packed_params.dtype', 'performer.net.layers.2.1.fn.fn.w2._packed_params._packed_params', 'performer.net.layers.3.0.norm.scale', 'performer.net.layers.3.0.norm.zero_point', 'performer.net.layers.3.0.fn.to_q.scale', 'performer.net.layers.3.0.fn.to_q.zero_point', 'performer.net.layers.3.0.fn.to_q._packed_params.dtype', 'performer.net.layers.3.0.fn.to_q._packed_params._packed_params', 'performer.net.layers.3.0.fn.to_k.scale', 'performer.net.layers.3.0.fn.to_k.zero_point', 'performer.net.layers.3.0.fn.to_k._packed_params.dtype', 'performer.net.layers.3.0.fn.to_k._packed_params._packed_params', 'performer.net.layers.3.0.fn.to_v.scale', 'performer.net.layers.3.0.fn.to_v.zero_point', 'performer.net.layers.3.0.fn.to_v._packed_params.dtype', 'performer.net.layers.3.0.fn.to_v._packed_params._packed_params', 'performer.net.layers.3.0.fn.to_out.scale', 'performer.net.layers.3.0.fn.to_out.zero_point', 'performer.net.layers.3.0.fn.to_out._packed_params.dtype', 'performer.net.layers.3.0.fn.to_out._packed_params._packed_params', 'performer.net.layers.3.1.norm.scale', 'performer.net.layers.3.1.norm.zero_point', 'performer.net.layers.3.1.fn.fn.w1.scale', 'performer.net.layers.3.1.fn.fn.w1.zero_point', 'performer.net.layers.3.1.fn.fn.w1._packed_params.dtype', 'performer.net.layers.3.1.fn.fn.w1._packed_params._packed_params', 'performer.net.layers.3.1.fn.fn.w2.scale', 'performer.net.layers.3.1.fn.fn.w2.zero_point', 'performer.net.layers.3.1.fn.fn.w2._packed_params.dtype', 'performer.net.layers.3.1.fn.fn.w2._packed_params._packed_params', 'performer.net.layers.4.0.norm.scale', 'performer.net.layers.4.0.norm.zero_point', 'performer.net.layers.4.0.fn.to_q.scale', 'performer.net.layers.4.0.fn.to_q.zero_point', 'performer.net.layers.4.0.fn.to_q._packed_params.dtype', 'performer.net.layers.4.0.fn.to_q._packed_params._packed_params', 'performer.net.layers.4.0.fn.to_k.scale', 'performer.net.layers.4.0.fn.to_k.zero_point', 'performer.net.layers.4.0.fn.to_k._packed_params.dtype', 'performer.net.layers.4.0.fn.to_k._packed_params._packed_params', 'performer.net.layers.4.0.fn.to_v.scale', 'performer.net.layers.4.0.fn.to_v.zero_point', 'performer.net.layers.4.0.fn.to_v._packed_params.dtype', 'performer.net.layers.4.0.fn.to_v._packed_params._packed_params', 'performer.net.layers.4.0.fn.to_out.scale', 'performer.net.layers.4.0.fn.to_out.zero_point', 'performer.net.layers.4.0.fn.to_out._packed_params.dtype', 'performer.net.layers.4.0.fn.to_out._packed_params._packed_params', 'performer.net.layers.4.1.norm.scale', 'performer.net.layers.4.1.norm.zero_point', 'performer.net.layers.4.1.fn.fn.w1.scale', 'performer.net.layers.4.1.fn.fn.w1.zero_point', 'performer.net.layers.4.1.fn.fn.w1._packed_params.dtype', 'performer.net.layers.4.1.fn.fn.w1._packed_params._packed_params', 'performer.net.layers.4.1.fn.fn.w2.scale', 'performer.net.layers.4.1.fn.fn.w2.zero_point', 'performer.net.layers.4.1.fn.fn.w2._packed_params.dtype', 'performer.net.layers.4.1.fn.fn.w2._packed_params._packed_params', 'performer.net.layers.5.0.norm.scale', 'performer.net.layers.5.0.norm.zero_point', 'performer.net.layers.5.0.fn.to_q.scale', 'performer.net.layers.5.0.fn.to_q.zero_point', 'performer.net.layers.5.0.fn.to_q._packed_params.dtype', 'performer.net.layers.5.0.fn.to_q._packed_params._packed_params', 'performer.net.layers.5.0.fn.to_k.scale', 'performer.net.layers.5.0.fn.to_k.zero_point', 'performer.net.layers.5.0.fn.to_k._packed_params.dtype', 'performer.net.layers.5.0.fn.to_k._packed_params._packed_params', 'performer.net.layers.5.0.fn.to_v.scale', 'performer.net.layers.5.0.fn.to_v.zero_point', 'performer.net.layers.5.0.fn.to_v._packed_params.dtype', 'performer.net.layers.5.0.fn.to_v._packed_params._packed_params', 'performer.net.layers.5.0.fn.to_out.scale', 'performer.net.layers.5.0.fn.to_out.zero_point', 'performer.net.layers.5.0.fn.to_out._packed_params.dtype', 'performer.net.layers.5.0.fn.to_out._packed_params._packed_params', 'performer.net.layers.5.1.norm.scale', 'performer.net.layers.5.1.norm.zero_point', 'performer.net.layers.5.1.fn.fn.w1.scale', 'performer.net.layers.5.1.fn.fn.w1.zero_point', 'performer.net.layers.5.1.fn.fn.w1._packed_params.dtype', 'performer.net.layers.5.1.fn.fn.w1._packed_params._packed_params', 'performer.net.layers.5.1.fn.fn.w2.scale', 'performer.net.layers.5.1.fn.fn.w2.zero_point', 'performer.net.layers.5.1.fn.fn.w2._packed_params.dtype', 'performer.net.layers.5.1.fn.fn.w2._packed_params._packed_params', 'norm.scale', 'norm.zero_point', 'to_out.scale', 'to_out.zero_point', 'to_out._packed_params.dtype', 'to_out._packed_params._packed_params'])"]},"metadata":{},"execution_count":37}]},{"cell_type":"code","source":[],"metadata":{"id":"7iAw00OKIMs6"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"colab":{"provenance":[],"machine_shape":"hm","gpuType":"V100"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}