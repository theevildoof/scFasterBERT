{"cells":[{"cell_type":"code","source":["from psutil import virtual_memory\n","ram_gb = virtual_memory().total / 1e9\n","print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n","\n","if ram_gb < 20:\n","  print('Not using a high-RAM runtime')\n","else:\n","  print('You are using a high-RAM runtime!')"],"metadata":{"id":"Tg3dpsogXYSE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713719247410,"user_tz":-330,"elapsed":7,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}},"outputId":"aad493e1-37d5-495b-a7ae-8a51d0f424ec"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Your runtime has 67.4 gigabytes of available RAM\n","\n","You are using a high-RAM runtime!\n"]}]},{"cell_type":"code","source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)"],"metadata":{"id":"E_MdpTlxXYKc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713719247410,"user_tz":-330,"elapsed":6,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}},"outputId":"147110a9-da99-45ad-b024-9222e7604b65"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Sun Apr 21 17:07:26 2024       \n","+---------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n","|-----------------------------------------+----------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                      |               MIG M. |\n","|=========================================+======================+======================|\n","|   0  NVIDIA L4                      Off | 00000000:00:03.0 Off |                    0 |\n","| N/A   55C    P0              22W /  72W |      1MiB / 23034MiB |      0%      Default |\n","|                                         |                      |                  N/A |\n","+-----------------------------------------+----------------------+----------------------+\n","                                                                                         \n","+---------------------------------------------------------------------------------------+\n","| Processes:                                                                            |\n","|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n","|        ID   ID                                                             Usage      |\n","|=======================================================================================|\n","|  No running processes found                                                           |\n","+---------------------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"metadata":{"id":"67tfpQ3-XUgj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713719250751,"user_tz":-330,"elapsed":3344,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}},"outputId":"81ab6417-6d56-44a2-e0d0-6fb32fbc577c"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"]}]},{"cell_type":"code","source":["ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w6ydBP_ChTgV","executionInfo":{"status":"ok","timestamp":1713719250752,"user_tz":-330,"elapsed":6,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}},"outputId":"3070d8fa-2978-4505-b9ad-05a4308ca3ca"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[0m\u001b[01;34mdrive\u001b[0m/  \u001b[01;34mruns\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"]}]},{"cell_type":"code","source":["import os\n","os.environ['PYTHONPATH'] += \"/content/drive/MyDrive/scFasterBERT/performer_pytorch\""],"metadata":{"id":"bd1l6AJ_iQe9","executionInfo":{"status":"ok","timestamp":1713719250752,"user_tz":-330,"elapsed":4,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["!pip install einops\n","!pip install local_attention\n","!pip install scanpy"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"70BzUhTSiloq","executionInfo":{"status":"ok","timestamp":1713719266055,"user_tz":-330,"elapsed":15307,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}},"outputId":"ea062415-ab03-4504-9bc4-425f8554f425"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (0.7.0)\n","Requirement already satisfied: local_attention in /usr/local/lib/python3.10/dist-packages (1.9.1)\n","Requirement already satisfied: einops>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from local_attention) (0.7.0)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from local_attention) (2.2.1+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->local_attention) (3.13.4)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->local_attention) (4.11.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->local_attention) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->local_attention) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->local_attention) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->local_attention) (2023.6.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->local_attention) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->local_attention) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->local_attention) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->local_attention) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->local_attention) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->local_attention) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->local_attention) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->local_attention) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->local_attention) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch->local_attention) (2.19.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->local_attention) (12.1.105)\n","Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->local_attention) (2.2.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->local_attention) (12.4.127)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->local_attention) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->local_attention) (1.3.0)\n","Requirement already satisfied: scanpy in /usr/local/lib/python3.10/dist-packages (1.10.1)\n","Requirement already satisfied: anndata>=0.8 in /usr/local/lib/python3.10/dist-packages (from scanpy) (0.10.7)\n","Requirement already satisfied: h5py>=3.1 in /usr/local/lib/python3.10/dist-packages (from scanpy) (3.9.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from scanpy) (1.4.0)\n","Requirement already satisfied: legacy-api-wrap>=1.4 in /usr/local/lib/python3.10/dist-packages (from scanpy) (1.4)\n","Requirement already satisfied: matplotlib>=3.6 in /usr/local/lib/python3.10/dist-packages (from scanpy) (3.7.1)\n","Requirement already satisfied: natsort in /usr/local/lib/python3.10/dist-packages (from scanpy) (8.4.0)\n","Requirement already satisfied: networkx>=2.7 in /usr/local/lib/python3.10/dist-packages (from scanpy) (3.3)\n","Requirement already satisfied: numba>=0.56 in /usr/local/lib/python3.10/dist-packages (from scanpy) (0.58.1)\n","Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.10/dist-packages (from scanpy) (1.25.2)\n","Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from scanpy) (24.0)\n","Requirement already satisfied: pandas>=1.5 in /usr/local/lib/python3.10/dist-packages (from scanpy) (2.0.3)\n","Requirement already satisfied: patsy in /usr/local/lib/python3.10/dist-packages (from scanpy) (0.5.6)\n","Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.10/dist-packages (from scanpy) (0.5.12)\n","Requirement already satisfied: scikit-learn>=0.24 in /usr/local/lib/python3.10/dist-packages (from scanpy) (1.2.2)\n","Requirement already satisfied: scipy>=1.8 in /usr/local/lib/python3.10/dist-packages (from scanpy) (1.11.4)\n","Requirement already satisfied: seaborn>=0.13 in /usr/local/lib/python3.10/dist-packages (from scanpy) (0.13.1)\n","Requirement already satisfied: session-info in /usr/local/lib/python3.10/dist-packages (from scanpy) (1.0.0)\n","Requirement already satisfied: statsmodels>=0.13 in /usr/local/lib/python3.10/dist-packages (from scanpy) (0.14.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from scanpy) (4.66.2)\n","Requirement already satisfied: umap-learn!=0.5.0,>=0.5 in /usr/local/lib/python3.10/dist-packages (from scanpy) (0.5.6)\n","Requirement already satisfied: array-api-compat!=1.5,>1.4 in /usr/local/lib/python3.10/dist-packages (from anndata>=0.8->scanpy) (1.6)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anndata>=0.8->scanpy) (1.2.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->scanpy) (1.2.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->scanpy) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->scanpy) (4.51.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->scanpy) (1.4.5)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->scanpy) (9.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->scanpy) (3.1.2)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->scanpy) (2.8.2)\n","Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.56->scanpy) (0.41.1)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.5->scanpy) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.5->scanpy) (2024.1)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24->scanpy) (3.4.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy->scanpy) (1.16.0)\n","Requirement already satisfied: stdlib-list in /usr/local/lib/python3.10/dist-packages (from session-info->scanpy) (0.10.0)\n"]}]},{"cell_type":"code","execution_count":7,"metadata":{"id":"WLddJJ5sXMln","executionInfo":{"status":"ok","timestamp":1713719273609,"user_tz":-330,"elapsed":7558,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}}},"outputs":[],"source":["import sys\n","sys.path.insert(1, '/content/drive/MyDrive/scFasterBERT/performer_pytorch')\n","sys.path.insert(2, '/content/drive/MyDrive/scFasterBERT/')\n","\n","import os\n","import gc\n","import argparse\n","import json\n","import random\n","import math\n","import random\n","from functools import reduce\n","import numpy as np\n","import pandas as pd\n","from scipy import sparse\n","from sklearn.model_selection import train_test_split\n","import torch\n","from torch import nn\n","from torch.optim import Adam\n","from torch.nn import functional as F\n","from torch.utils.data import DataLoader, Dataset\n","from performer_pytorch import PerformerLM\n","import scanpy as sc\n","import anndata as ad\n","from utils import *\n","import scipy.sparse\n","import h5py\n","from tqdm import tqdm\n","from torch.utils.tensorboard import SummaryWriter"]},{"cell_type":"code","source":["Writer = SummaryWriter('./runs/scBERT_ours_pretrained')"],"metadata":{"id":"7FBmaSkOffL-","executionInfo":{"status":"ok","timestamp":1713719273609,"user_tz":-330,"elapsed":7,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","execution_count":9,"metadata":{"id":"Co1cwDfrXMlp","executionInfo":{"status":"ok","timestamp":1713719273609,"user_tz":-330,"elapsed":6,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}}},"outputs":[],"source":["data_path = '../data/panglao_human.h5ad'"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"4DGWuKE3XMlp","executionInfo":{"status":"ok","timestamp":1713719273609,"user_tz":-330,"elapsed":6,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}}},"outputs":[],"source":["SEED = 2021\n","EPOCHS = 100\n","BATCH_SIZE = 3\n","GRADIENT_ACCUMULATION = 60\n","LEARNING_RATE = 1e-4\n","SEQ_LEN = 16907\n","VALIDATE_EVERY = 1\n","CLASS = 7\n","MASK_PROB = 0.15\n","REPLACE_PROB = 0.9\n","RANDOM_TOKEN_PROB = 0.\n","MASK_TOKEN_ID = CLASS - 1\n","PAD_TOKEN_ID = CLASS - 1\n","MASK_IGNORE_TOKEN_IDS = [0]\n","POS_EMBED_USING = True\n","\n","model_name = 'panglao_pretrain_ours_1'\n","ckpt_dir = './checkpoints/'"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"K-yZa70LXMlq","outputId":"5f726677-d77e-432d-a52a-910359d1b745","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713719273609,"user_tz":-330,"elapsed":6,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7bd110e81a50>"]},"metadata":{},"execution_count":11}],"source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","torch.manual_seed(SEED)"]},{"cell_type":"markdown","metadata":{"id":"gowQVmRrXMlq"},"source":["# Masking"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"wYyXZM4vXMlr","executionInfo":{"status":"ok","timestamp":1713719273609,"user_tz":-330,"elapsed":5,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}}},"outputs":[],"source":["# get the random prob matrix and True means smaller than prob threshold\n","def prob_mask_like(t, prob):\n","    return torch.zeros_like(t).float().uniform_(0, 1) < prob\n","\n","# get the mask matrix which cannot be masked\n","def mask_with_tokens(t, token_ids):\n","    init_no_mask = torch.full_like(t, False, dtype=torch.bool)\n","    mask = reduce(lambda acc, el: acc | (t == el), token_ids, init_no_mask)\n","    return mask\n","\n","def get_mask_subset_with_prob(mask, prob):\n","    batch, seq_len, device = *mask.shape, mask.device\n","    max_masked = math.ceil(prob * seq_len)      # num of mask of a single sequence in average\n","    num_tokens = mask.sum(dim=-1, keepdim=True)     # num of pure tokens of each sequence except special tokens\n","    mask_excess = torch.cat((torch.zeros(0), torch.arange(mask.size(-1)).repeat(mask.size(0)))).reshape(mask.size(0),mask.size(-1)).to(device)\n","    mask_excess = (mask_excess >= (num_tokens * prob).ceil())        # only 15% of pure tokens can be masked\n","    mask_excess = mask_excess[:, :max_masked]       # get difference between 15% of pure tokens and 15% of all tokens\n","    rand = torch.rand((batch, seq_len), device=device).masked_fill(~mask, -1e9)     # rand (0-1) as prob, special token use -1e9\n","    _, sampled_indices = rand.topk(max_masked, dim=-1)      # get index of topk prob to mask\n","    sampled_indices = (sampled_indices + 1).masked_fill_(mask_excess, 0)        # delete difference of mask not pure\n","    new_mask = torch.zeros((batch, seq_len + 1), device=device)     # get (batch, seq_len) shape zero matrix\n","    new_mask.scatter_(-1, sampled_indices, 1)       # set masks in zero matrix as 1\n","    return new_mask[:, 1:].bool()       # the final mask, True is mask\n","\n","def data_mask(data,\n","    mask_prob = MASK_PROB,\n","    replace_prob = REPLACE_PROB,\n","    num_tokens = None,\n","    random_token_prob = RANDOM_TOKEN_PROB,\n","    mask_token_id = MASK_TOKEN_ID,\n","    pad_token_id = PAD_TOKEN_ID,\n","    mask_ignore_token_ids = MASK_IGNORE_TOKEN_IDS\n","):\n","    mask_ignore_token_ids = set([*mask_ignore_token_ids, pad_token_id])\n","    # do not mask [pad] tokens, or any other tokens in the tokens designated to be excluded ([cls], [sep])\n","    # also do not include these special tokens in the tokens chosen at random\n","    no_mask = mask_with_tokens(data, mask_ignore_token_ids)   # ignore_token as True, will not be masked later\n","    mask = get_mask_subset_with_prob(~no_mask, mask_prob)      # get the True/False mask matrix\n","    # get mask indices\n","    ## mask_indices = torch.nonzero(mask, as_tuple=True)   # get the index of mask(nonzero value of mask matrix)\n","    # mask input with mask tokens with probability of `replace_prob` (keep tokens the same with probability 1 - replace_prob)\n","    masked_input = data.clone().detach()\n","    # if random token probability > 0 for mlm\n","    if random_token_prob > 0:\n","        assert num_tokens is not None, 'num_tokens keyword must be supplied when instantiating MLM if using random token replacement'\n","        random_token_prob = prob_mask_like(data, random_token_prob)       # get the mask matrix of random token replace\n","        random_tokens = torch.randint(0, num_tokens, data.shape, device=data.device)     # generate random token matrix with the same shape as in\n","        random_no_mask = mask_with_tokens(random_tokens, mask_ignore_token_ids)        # not masked matrix for the random token matrix\n","        random_token_prob &= ~random_no_mask        # get the pure mask matrix of random token replace\n","        random_indices = torch.nonzero(random_token_prob, as_tuple=True)        # index of random token replace\n","        masked_input[random_indices] = random_tokens[random_indices]        # replace some tokens by random token\n","    # [mask] input\n","    replace_prob = prob_mask_like(data, replace_prob)     # get the mask matrix of token being masked\n","    masked_input = masked_input.masked_fill(mask * replace_prob, mask_token_id)        # get the data has been masked by mask_token\n","    # mask out any tokens to padding tokens that were not originally going to be masked\n","    labels = data.masked_fill(~mask, pad_token_id)        # the label of masked tokens\n","    return masked_input, labels"]},{"cell_type":"markdown","metadata":{"id":"vRs1LsQXXMls"},"source":["# Dataset and Dataloader"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"DZBwDp-EXMls","executionInfo":{"status":"ok","timestamp":1713719273610,"user_tz":-330,"elapsed":6,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}}},"outputs":[],"source":["# total_samples = 1357593  # Replace with the actual total length of your dataset\n","# train_ratio = 0.95\n","\n","# # Calculate the number of samples in each set\n","# num_train_samples = int(total_samples * train_ratio)\n","# num_valid_samples = total_samples - num_train_samples\n","\n","# # Generate indices for training and validation sets\n","# train_indices = list(range(0, num_train_samples))\n","# valid_indices = list(range(num_train_samples, total_samples))\n","\n","# print(\"Training indices:\", len(train_indices))\n","# print(\"Validation indices:\", len(valid_indices))"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"cBmPZ4ypXMls","executionInfo":{"status":"ok","timestamp":1713719273610,"user_tz":-330,"elapsed":5,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}}},"outputs":[],"source":["# class SCDataset(Dataset):\n","#     def __init__(self, file_path, indices):\n","#         self.file_path = file_path\n","#         self.data = sc.read_h5ad(data_path, backed='r')\n","#         self.length = self.data.X.shape[0]\n","#         self.indices = indices\n","#         self.indices_len = len(self.indices)\n","\n","#     def __getitem__(self, index):\n","#         rand_start = random.randint(0, self.indices_len-1)\n","#         data = self.data.X[self.indices[rand_start]]\n","#         # Convert sparse matrix row to dense if necessary\n","#         if isinstance(data, scipy.sparse.csr_matrix):\n","#             data = data.toarray().squeeze(0)\n","#             # print(data)\n","\n","#         # Apply the same preprocessing as before\n","#         data[data > (CLASS - 2)] = CLASS - 2\n","#         data = torch.from_numpy(data).long()\n","#         data = torch.cat((data, torch.tensor([0]))).to(device)\n","#         return data\n","\n","#     def __len__(self):\n","#         return self.length"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"igKC-308XMlt","executionInfo":{"status":"ok","timestamp":1713719273610,"user_tz":-330,"elapsed":5,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}}},"outputs":[],"source":["\n","# train_dataset = SCDataset(data_path, train_indices)\n","# val_dataset = SCDataset(data_path, valid_indices)\n","\n","# train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n","# val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)"]},{"cell_type":"code","source":["class SCDataset(Dataset):\n","    def __init__(self, data):\n","        super().__init__()\n","        self.data = data\n","\n","    def __getitem__(self, index):\n","        rand_start = random.randint(0, self.data.shape[0]-1)\n","        full_seq = self.data[rand_start].toarray()[0]\n","        full_seq[full_seq > (CLASS - 2)] = CLASS - 2\n","        full_seq = torch.from_numpy(full_seq).long()\n","        full_seq = torch.cat((full_seq, torch.tensor([0]))).to(device)\n","        return full_seq\n","\n","    def __len__(self):\n","        return self.data.shape[0]\n","\n","data = sc.read_h5ad('/content/drive/MyDrive/scFasterBERT/data/panglao_human.h5ad')\n","data = data.X\n","data_train, data_val = train_test_split(data, test_size=0.05,random_state=SEED)\n","\n","train_dataset = SCDataset(data_train)\n","val_dataset = SCDataset(data_val)\n","\n"],"metadata":{"id":"2GBKtA0Dgup5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713719293360,"user_tz":-330,"elapsed":18302,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}},"outputId":"700b0132-5e25-4b78-ab6e-f9b36934f572"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/anndata/_core/anndata.py:1818: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n","  utils.warn_names_duplicates(\"obs\")\n"]}]},{"cell_type":"code","source":["train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE)\n","val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)"],"metadata":{"id":"01qOE09-n3Gi","executionInfo":{"status":"ok","timestamp":1713719293361,"user_tz":-330,"elapsed":11,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}}},"execution_count":17,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"k_qaL8bEXMlt"},"source":["# Model"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"V2xdhEylXMlt","outputId":"8d1effbd-262f-417a-81ba-e6630cab7975","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713719294655,"user_tz":-330,"elapsed":1305,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["/content/drive/MyDrive/scFasterBERT/performer_pytorch/performer_pytorch.py:115: UserWarning: torch.qr is deprecated in favor of torch.linalg.qr and will be removed in a future PyTorch release.\n","The boolean parameter 'some' has been replaced with a string parameter 'mode'.\n","Q, R = torch.qr(A, some)\n","should be replaced with\n","Q, R = torch.linalg.qr(A, 'reduced' if some else 'complete') (Triggered internally at ../aten/src/ATen/native/BatchLinearAlgebra.cpp:2426.)\n","  q, r = torch.qr(unstructured_block.cpu(), some = True)\n"]}],"source":["model = PerformerLM(\n","    num_tokens = CLASS,\n","    dim = 200,\n","    depth = 6,\n","    max_seq_len = SEQ_LEN,\n","    heads = 10,\n","    local_attn_heads = 0,\n","    g2v_position_emb = POS_EMBED_USING\n",")\n","\n","\n","model.to(device)\n","\n","# optimizer\n","optimizer = Adam(model.parameters(), lr=LEARNING_RATE)"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"OLDLa74bXMlt","executionInfo":{"status":"ok","timestamp":1713719294656,"user_tz":-330,"elapsed":7,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}}},"outputs":[],"source":["loss_fn = nn.CrossEntropyLoss(ignore_index = PAD_TOKEN_ID, reduction='mean').to(device)\n","softmax = nn.Softmax(dim=-1)"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"HMeWW5JqXMlt","outputId":"e9cb7762-2650-4852-a7c6-379fffbae8fe","colab":{"base_uri":"https://localhost:8080/","height":228},"executionInfo":{"status":"error","timestamp":1713719511116,"user_tz":-330,"elapsed":216466,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["385it [03:36,  1.78it/s]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-9c85e8e5b769>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mfinal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mfinal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["for epoch in range(1, EPOCHS+1):\n","    model.train()\n","    running_loss = 0.0\n","    cum_acc = 0.0\n","    for index, data in tqdm(enumerate(train_loader)):\n","        index += 1\n","        data = data.to(device)\n","        data, labels = data_mask(data)\n","        if index % GRADIENT_ACCUMULATION != 0:\n","            logits = model(data)\n","            loss = loss_fn(logits.transpose(1, 2), labels) / GRADIENT_ACCUMULATION\n","            loss.backward()\n","        else:\n","            logits = model(data)\n","            loss = loss_fn(logits.transpose(1, 2), labels) / GRADIENT_ACCUMULATION\n","            loss.backward()\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), int(1e2))\n","            optimizer.step()\n","            optimizer.zero_grad()\n","        running_loss += loss.item()\n","        final = softmax(logits)[..., 1:-1]\n","        final = final.argmax(dim=-1) + 1\n","        pred_num = (labels != PAD_TOKEN_ID).sum(dim=-1)\n","        correct_num = ((labels != PAD_TOKEN_ID) * (final == labels)).sum(dim=-1)\n","        cum_acc += torch.true_divide(correct_num, pred_num).mean().item()\n","    epoch_loss = running_loss / index\n","    epoch_acc = 100 * cum_acc / index\n","    print(f'    ==  Epoch: {epoch} | Training Loss: {epoch_loss:.6f} | Accuracy: {epoch_acc:6.4f}%  ==')\n","    Writer.add_scalar('Training loss', epoch_loss, epoch)\n","    Writer.add_scalar('Training accuracy',epoch_acc, epoch)\n","\n","    if epoch % VALIDATE_EVERY == 0:\n","        model.eval()\n","        running_loss = 0.0\n","        predictions = []\n","        truths = []\n","        with torch.no_grad():\n","            for index, data in tqdm(enumerate(val_loader)):\n","                index += 1\n","                data = data.to(device)\n","                data, labels = data_mask(data)\n","                logits = model(data)\n","                loss = loss_fn(logits.transpose(1, 2), labels)\n","                running_loss += loss.item()\n","                softmax = nn.Softmax(dim=-1)\n","                final = softmax(logits)[..., 1:-1]\n","                final = final.argmax(dim=-1) + 1\n","                predictions.append(final)\n","                truths.append(labels)\n","        val_loss = running_loss / index\n","        correct_num = ((torch.cat(truths, dim=0) != PAD_TOKEN_ID) * (torch.cat(predictions, dim=0) == torch.cat(truths, dim=0))).sum().item()\n","        val_num = (torch.cat(truths, dim=0) != PAD_TOKEN_ID).sum().item()\n","        val_acc = 100 * correct_num / val_num\n","        print(f'    ==  Epoch: {epoch} | Validation Loss: {val_loss:.6f} | Accuracy: {val_acc:6.4f}%  ==')\n","        Writer.add_scalar('Valid loss', val_loss, epoch)\n","        Writer.add_scalar('Valid accuracy',val_acc, epoch)\n","\n","    # save_ckpt(i, model, optimizerepoch_loss, model_name, ckpt_dir)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_9bfv1VTXMlu","executionInfo":{"status":"aborted","timestamp":1713719511116,"user_tz":-330,"elapsed":10,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}}},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}