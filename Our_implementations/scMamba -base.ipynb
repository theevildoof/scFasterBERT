{"cells":[{"cell_type":"code","source":["from psutil import virtual_memory\n","ram_gb = virtual_memory().total / 1e9\n","print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n","\n","if ram_gb < 20:\n","  print('Not using a high-RAM runtime')\n","else:\n","  print('You are using a high-RAM runtime!')"],"metadata":{"id":"Tg3dpsogXYSE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714485642524,"user_tz":-330,"elapsed":9,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}},"outputId":"e555d884-0dd9-464d-ad77-13de8432eb95"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Your runtime has 13.6 gigabytes of available RAM\n","\n","Not using a high-RAM runtime\n"]}]},{"cell_type":"code","source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)"],"metadata":{"id":"E_MdpTlxXYKc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714485642525,"user_tz":-330,"elapsed":8,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}},"outputId":"315deb95-a767-4840-a62e-e7ce5805c6c8"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/bin/bash: line 1: nvidia-smi: command not found\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"metadata":{"id":"67tfpQ3-XUgj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714485670081,"user_tz":-330,"elapsed":27562,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}},"outputId":"90b374a6-984b-4f39-ae10-4e6f848e3c5e"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}]},{"cell_type":"code","source":["!pip install mamba-ssm\n","!pip install causal-conv1d>=1.2.0\n","!pip install local_attention\n","!pip install scanpy\n","!pip install einops"],"metadata":{"id":"bd1l6AJ_iQe9","executionInfo":{"status":"ok","timestamp":1714486171923,"user_tz":-330,"elapsed":39704,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"0193b8ab-a2b9-4958-daa6-d9730123e125"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: mamba-ssm in /usr/local/lib/python3.10/dist-packages (1.2.0.post1)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from mamba-ssm) (2.2.1+cu121)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mamba-ssm) (24.0)\n","Requirement already satisfied: ninja in /usr/local/lib/python3.10/dist-packages (from mamba-ssm) (1.11.1.1)\n","Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from mamba-ssm) (0.8.0)\n","Requirement already satisfied: triton in /usr/local/lib/python3.10/dist-packages (from mamba-ssm) (2.2.0)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from mamba-ssm) (4.40.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (3.13.4)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (4.11.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (2023.6.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (2.19.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (12.1.105)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->mamba-ssm) (12.4.127)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm) (0.20.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm) (1.25.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm) (2023.12.25)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm) (2.31.0)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm) (0.19.1)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm) (0.4.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm) (4.66.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->mamba-ssm) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->mamba-ssm) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->mamba-ssm) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->mamba-ssm) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->mamba-ssm) (2024.2.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->mamba-ssm) (1.3.0)\n","Requirement already satisfied: local_attention in /usr/local/lib/python3.10/dist-packages (1.9.1)\n","Requirement already satisfied: einops>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from local_attention) (0.8.0)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from local_attention) (2.2.1+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->local_attention) (3.13.4)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->local_attention) (4.11.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->local_attention) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->local_attention) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->local_attention) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->local_attention) (2023.6.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->local_attention) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->local_attention) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->local_attention) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->local_attention) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->local_attention) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->local_attention) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->local_attention) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->local_attention) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->local_attention) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch->local_attention) (2.19.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->local_attention) (12.1.105)\n","Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->local_attention) (2.2.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->local_attention) (12.4.127)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->local_attention) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->local_attention) (1.3.0)\n","Collecting scanpy\n","  Downloading scanpy-1.10.1-py3-none-any.whl (2.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting anndata>=0.8 (from scanpy)\n","  Downloading anndata-0.10.7-py3-none-any.whl (122 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.4/122.4 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: h5py>=3.1 in /usr/local/lib/python3.10/dist-packages (from scanpy) (3.9.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from scanpy) (1.4.0)\n","Collecting legacy-api-wrap>=1.4 (from scanpy)\n","  Downloading legacy_api_wrap-1.4-py3-none-any.whl (15 kB)\n","Requirement already satisfied: matplotlib>=3.6 in /usr/local/lib/python3.10/dist-packages (from scanpy) (3.7.1)\n","Requirement already satisfied: natsort in /usr/local/lib/python3.10/dist-packages (from scanpy) (8.4.0)\n","Requirement already satisfied: networkx>=2.7 in /usr/local/lib/python3.10/dist-packages (from scanpy) (3.3)\n","Requirement already satisfied: numba>=0.56 in /usr/local/lib/python3.10/dist-packages (from scanpy) (0.58.1)\n","Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.10/dist-packages (from scanpy) (1.25.2)\n","Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from scanpy) (24.0)\n","Requirement already satisfied: pandas>=1.5 in /usr/local/lib/python3.10/dist-packages (from scanpy) (2.0.3)\n","Requirement already satisfied: patsy in /usr/local/lib/python3.10/dist-packages (from scanpy) (0.5.6)\n","Collecting pynndescent>=0.5 (from scanpy)\n","  Downloading pynndescent-0.5.12-py3-none-any.whl (56 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scikit-learn>=0.24 in /usr/local/lib/python3.10/dist-packages (from scanpy) (1.2.2)\n","Requirement already satisfied: scipy>=1.8 in /usr/local/lib/python3.10/dist-packages (from scanpy) (1.11.4)\n","Requirement already satisfied: seaborn>=0.13 in /usr/local/lib/python3.10/dist-packages (from scanpy) (0.13.1)\n","Collecting session-info (from scanpy)\n","  Downloading session_info-1.0.0.tar.gz (24 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: statsmodels>=0.13 in /usr/local/lib/python3.10/dist-packages (from scanpy) (0.14.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from scanpy) (4.66.2)\n","Collecting umap-learn!=0.5.0,>=0.5 (from scanpy)\n","  Downloading umap_learn-0.5.6-py3-none-any.whl (85 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.7/85.7 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting array-api-compat!=1.5,>1.4 (from anndata>=0.8->scanpy)\n","  Downloading array_api_compat-1.6-py3-none-any.whl (36 kB)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anndata>=0.8->scanpy) (1.2.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->scanpy) (1.2.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->scanpy) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->scanpy) (4.51.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->scanpy) (1.4.5)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->scanpy) (9.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->scanpy) (3.1.2)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->scanpy) (2.8.2)\n","Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.56->scanpy) (0.41.1)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.5->scanpy) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.5->scanpy) (2024.1)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24->scanpy) (3.4.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy->scanpy) (1.16.0)\n","Collecting stdlib_list (from session-info->scanpy)\n","  Downloading stdlib_list-0.10.0-py3-none-any.whl (79 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: session-info\n","  Building wheel for session-info (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for session-info: filename=session_info-1.0.0-py3-none-any.whl size=8026 sha256=bd0d41b15f3ea1b675f078ab440db548506e0960a064e184ec1175cb68fd809f\n","  Stored in directory: /root/.cache/pip/wheels/6a/aa/b9/eb5d4031476ec10802795b97ccf937b9bd998d68a9b268765a\n","Successfully built session-info\n","Installing collected packages: array-api-compat, stdlib_list, legacy-api-wrap, session-info, pynndescent, anndata, umap-learn, scanpy\n","Successfully installed anndata-0.10.7 array-api-compat-1.6 legacy-api-wrap-1.4 pynndescent-0.5.12 scanpy-1.10.1 session-info-1.0.0 stdlib_list-0.10.0 umap-learn-0.5.6\n","Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (0.8.0)\n"]}]},{"cell_type":"code","source":["from mamba_ssm import Mamba\n"],"metadata":{"id":"X98kO0rLFRyZ","executionInfo":{"status":"ok","timestamp":1714485883335,"user_tz":-330,"elapsed":3,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","execution_count":16,"metadata":{"id":"WLddJJ5sXMln","executionInfo":{"status":"ok","timestamp":1714486923362,"user_tz":-330,"elapsed":12475,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}}},"outputs":[],"source":["import sys\n","sys.path.insert(1, '/content/drive/MyDrive/scFasterBERT/performer_pytorch')\n","sys.path.insert(2, '/content/drive/MyDrive/scFasterBERT/')\n","import os\n","import gc\n","import argparse\n","import json\n","import random\n","import math\n","import random\n","from functools import reduce\n","import numpy as np\n","import pandas as pd\n","from scipy import sparse\n","from sklearn.model_selection import train_test_split\n","import torch\n","from torch import nn\n","from torch.optim import Adam\n","from torch.nn import functional as F\n","from torch.utils.data import DataLoader, Dataset\n","from performer_pytorch import PerformerLM\n","\n","import scanpy as sc\n","import anndata as ad\n","from utils import *\n","import scipy.sparse\n","import h5py\n","from tqdm import tqdm\n","from torch.utils.tensorboard import SummaryWriter"]},{"cell_type":"code","source":["Writer = SummaryWriter('./runs/scMamba_pretrained')"],"metadata":{"id":"7FBmaSkOffL-","executionInfo":{"status":"ok","timestamp":1714486923363,"user_tz":-330,"elapsed":4,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","execution_count":18,"metadata":{"id":"Co1cwDfrXMlp","executionInfo":{"status":"ok","timestamp":1714486923363,"user_tz":-330,"elapsed":3,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}}},"outputs":[],"source":["data_path = '../data/panglao_human.h5ad'"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"4DGWuKE3XMlp","executionInfo":{"status":"ok","timestamp":1714486923363,"user_tz":-330,"elapsed":3,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}}},"outputs":[],"source":["SEED = 2021\n","EPOCHS = 10\n","BATCH_SIZE = 3\n","GRADIENT_ACCUMULATION = 60\n","LEARNING_RATE = 1e-4\n","SEQ_LEN = 16907\n","VALIDATE_EVERY = 1\n","CLASS = 7\n","MASK_PROB = 0.15\n","REPLACE_PROB = 0.9\n","RANDOM_TOKEN_PROB = 0.\n","MASK_TOKEN_ID = CLASS - 1\n","PAD_TOKEN_ID = CLASS - 1\n","MASK_IGNORE_TOKEN_IDS = [0]\n","POS_EMBED_USING = True\n","\n","model_name = 'panglao_pretrain_ours_1'\n","ckpt_dir = './checkpoints/'"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"K-yZa70LXMlq","outputId":"a52eea8a-2cd7-4338-94f6-b3ce98287657","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714486925121,"user_tz":-330,"elapsed":4,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7da5b448b330>"]},"metadata":{},"execution_count":20}],"source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","torch.manual_seed(SEED)"]},{"cell_type":"markdown","metadata":{"id":"gowQVmRrXMlq"},"source":["# Masking"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"wYyXZM4vXMlr","executionInfo":{"status":"ok","timestamp":1714486926382,"user_tz":-330,"elapsed":4,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}}},"outputs":[],"source":["# get the random prob matrix and True means smaller than prob threshold\n","def prob_mask_like(t, prob):\n","    return torch.zeros_like(t).float().uniform_(0, 1) < prob\n","\n","# get the mask matrix which cannot be masked\n","def mask_with_tokens(t, token_ids):\n","    init_no_mask = torch.full_like(t, False, dtype=torch.bool)\n","    mask = reduce(lambda acc, el: acc | (t == el), token_ids, init_no_mask)\n","    return mask\n","\n","def get_mask_subset_with_prob(mask, prob):\n","    batch, seq_len, device = *mask.shape, mask.device\n","    max_masked = math.ceil(prob * seq_len)      # num of mask of a single sequence in average\n","    num_tokens = mask.sum(dim=-1, keepdim=True)     # num of pure tokens of each sequence except special tokens\n","    mask_excess = torch.cat((torch.zeros(0), torch.arange(mask.size(-1)).repeat(mask.size(0)))).reshape(mask.size(0),mask.size(-1)).to(device)\n","    mask_excess = (mask_excess >= (num_tokens * prob).ceil())        # only 15% of pure tokens can be masked\n","    mask_excess = mask_excess[:, :max_masked]       # get difference between 15% of pure tokens and 15% of all tokens\n","    rand = torch.rand((batch, seq_len), device=device).masked_fill(~mask, -1e9)     # rand (0-1) as prob, special token use -1e9\n","    _, sampled_indices = rand.topk(max_masked, dim=-1)      # get index of topk prob to mask\n","    sampled_indices = (sampled_indices + 1).masked_fill_(mask_excess, 0)        # delete difference of mask not pure\n","    new_mask = torch.zeros((batch, seq_len + 1), device=device)     # get (batch, seq_len) shape zero matrix\n","    new_mask.scatter_(-1, sampled_indices, 1)       # set masks in zero matrix as 1\n","    return new_mask[:, 1:].bool()       # the final mask, True is mask\n","\n","def data_mask(data,\n","    mask_prob = MASK_PROB,\n","    replace_prob = REPLACE_PROB,\n","    num_tokens = None,\n","    random_token_prob = RANDOM_TOKEN_PROB,\n","    mask_token_id = MASK_TOKEN_ID,\n","    pad_token_id = PAD_TOKEN_ID,\n","    mask_ignore_token_ids = MASK_IGNORE_TOKEN_IDS\n","):\n","    mask_ignore_token_ids = set([*mask_ignore_token_ids, pad_token_id])\n","    # do not mask [pad] tokens, or any other tokens in the tokens designated to be excluded ([cls], [sep])\n","    # also do not include these special tokens in the tokens chosen at random\n","    no_mask = mask_with_tokens(data, mask_ignore_token_ids)   # ignore_token as True, will not be masked later\n","    mask = get_mask_subset_with_prob(~no_mask, mask_prob)      # get the True/False mask matrix\n","    # get mask indices\n","    ## mask_indices = torch.nonzero(mask, as_tuple=True)   # get the index of mask(nonzero value of mask matrix)\n","    # mask input with mask tokens with probability of `replace_prob` (keep tokens the same with probability 1 - replace_prob)\n","    masked_input = data.clone().detach()\n","    # if random token probability > 0 for mlm\n","    if random_token_prob > 0:\n","        assert num_tokens is not None, 'num_tokens keyword must be supplied when instantiating MLM if using random token replacement'\n","        random_token_prob = prob_mask_like(data, random_token_prob)       # get the mask matrix of random token replace\n","        random_tokens = torch.randint(0, num_tokens, data.shape, device=data.device)     # generate random token matrix with the same shape as in\n","        random_no_mask = mask_with_tokens(random_tokens, mask_ignore_token_ids)        # not masked matrix for the random token matrix\n","        random_token_prob &= ~random_no_mask        # get the pure mask matrix of random token replace\n","        random_indices = torch.nonzero(random_token_prob, as_tuple=True)        # index of random token replace\n","        masked_input[random_indices] = random_tokens[random_indices]        # replace some tokens by random token\n","    # [mask] input\n","    replace_prob = prob_mask_like(data, replace_prob)     # get the mask matrix of token being masked\n","    masked_input = masked_input.masked_fill(mask * replace_prob, mask_token_id)        # get the data has been masked by mask_token\n","    # mask out any tokens to padding tokens that were not originally going to be masked\n","    labels = data.masked_fill(~mask, pad_token_id)        # the label of masked tokens\n","    return masked_input, labels"]},{"cell_type":"markdown","metadata":{"id":"vRs1LsQXXMls"},"source":["# Dataset and Dataloader"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"DZBwDp-EXMls","executionInfo":{"status":"ok","timestamp":1714486927913,"user_tz":-330,"elapsed":2,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}}},"outputs":[],"source":["# total_samples = 1357593  # Replace with the actual total length of your dataset\n","# train_ratio = 0.95\n","\n","# # Calculate the number of samples in each set\n","# num_train_samples = int(total_samples * train_ratio)\n","# num_valid_samples = total_samples - num_train_samples\n","\n","# # Generate indices for training and validation sets\n","# train_indices = list(range(0, num_train_samples))\n","# valid_indices = list(range(num_train_samples, total_samples))\n","\n","# print(\"Training indices:\", len(train_indices))\n","# print(\"Validation indices:\", len(valid_indices))"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"cBmPZ4ypXMls","executionInfo":{"status":"ok","timestamp":1714486929753,"user_tz":-330,"elapsed":346,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}}},"outputs":[],"source":["# class SCDataset(Dataset):\n","#     def __init__(self, file_path, indices):\n","#         self.file_path = file_path\n","#         self.data = sc.read_h5ad(data_path, backed='r')\n","#         self.length = self.data.X.shape[0]\n","#         self.indices = indices\n","#         self.indices_len = len(self.indices)\n","\n","#     def __getitem__(self, index):\n","#         rand_start = random.randint(0, self.indices_len-1)\n","#         data = self.data.X[self.indices[rand_start]]\n","#         # Convert sparse matrix row to dense if necessary\n","#         if isinstance(data, scipy.sparse.csr_matrix):\n","#             data = data.toarray().squeeze(0)\n","#             # print(data)\n","\n","#         # Apply the same preprocessing as before\n","#         data[data > (CLASS - 2)] = CLASS - 2\n","#         data = torch.from_numpy(data).long()\n","#         data = torch.cat((data, torch.tensor([0]))).to(device)\n","#         return data\n","\n","#     def __len__(self):\n","#         return self.length"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"igKC-308XMlt","executionInfo":{"status":"ok","timestamp":1714486931173,"user_tz":-330,"elapsed":2,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}}},"outputs":[],"source":["\n","# train_dataset = SCDataset(data_path, train_indices)\n","# val_dataset = SCDataset(data_path, valid_indices)\n","\n","# train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n","# val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)"]},{"cell_type":"code","source":["class SCDataset(Dataset):\n","    def __init__(self, data):\n","        super().__init__()\n","        self.data = data\n","\n","    def __getitem__(self, index):\n","        rand_start = random.randint(0, self.data.shape[0]-1)\n","        full_seq = self.data[rand_start].toarray()[0]\n","        full_seq[full_seq > (CLASS - 2)] = CLASS - 2\n","        full_seq = torch.from_numpy(full_seq).long()\n","        full_seq = torch.cat((full_seq, torch.tensor([0]))).to(device)\n","        return full_seq\n","\n","    def __len__(self):\n","        return self.data.shape[0]\n","\n","data = sc.read_h5ad('/content/drive/MyDrive/scFasterBERT/data/panglao_human.h5ad')\n","data = data.X\n","data_train, data_val = train_test_split(data, test_size=0.05,random_state=SEED)\n","\n","train_dataset = SCDataset(data_train)\n","val_dataset = SCDataset(data_val)\n","\n"],"metadata":{"id":"2GBKtA0Dgup5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE)\n","val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)"],"metadata":{"id":"01qOE09-n3Gi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"k_qaL8bEXMlt"},"source":["# Model"]},{"cell_type":"code","source":["class scMamba(nn.Module):\n","  def __init__(self, ):\n","    super().__init__():\n","\n","\n","\n","  def forward(self, ):\n",""],"metadata":{"id":"wm7e4z3TCo4g"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V2xdhEylXMlt","outputId":"8d1effbd-262f-417a-81ba-e6630cab7975","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713719294655,"user_tz":-330,"elapsed":1305,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["/content/drive/MyDrive/scFasterBERT/performer_pytorch/performer_pytorch.py:115: UserWarning: torch.qr is deprecated in favor of torch.linalg.qr and will be removed in a future PyTorch release.\n","The boolean parameter 'some' has been replaced with a string parameter 'mode'.\n","Q, R = torch.qr(A, some)\n","should be replaced with\n","Q, R = torch.linalg.qr(A, 'reduced' if some else 'complete') (Triggered internally at ../aten/src/ATen/native/BatchLinearAlgebra.cpp:2426.)\n","  q, r = torch.qr(unstructured_block.cpu(), some = True)\n"]}],"source":["model = scmamba()\n","\n","model.to(device)\n","\n","# optimizer\n","optimizer = Adam(model.parameters(), lr=LEARNING_RATE)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OLDLa74bXMlt"},"outputs":[],"source":["loss_fn = nn.CrossEntropyLoss(ignore_index = PAD_TOKEN_ID, reduction='mean').to(device)\n","softmax = nn.Softmax(dim=-1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HMeWW5JqXMlt","outputId":"e9cb7762-2650-4852-a7c6-379fffbae8fe","colab":{"base_uri":"https://localhost:8080/","height":228},"executionInfo":{"status":"error","timestamp":1713719511116,"user_tz":-330,"elapsed":216466,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["385it [03:36,  1.78it/s]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-9c85e8e5b769>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mfinal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mfinal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["for epoch in range(1, EPOCHS+1):\n","    model.train()\n","    running_loss = 0.0\n","    cum_acc = 0.0\n","    for index, data in tqdm(enumerate(train_loader)):\n","        index += 1\n","        data = data.to(device)\n","        data, labels = data_mask(data)\n","        if index % GRADIENT_ACCUMULATION != 0:\n","            logits = model(data)\n","            loss = loss_fn(logits.transpose(1, 2), labels) / GRADIENT_ACCUMULATION\n","            loss.backward()\n","        else:\n","            logits = model(data)\n","            loss = loss_fn(logits.transpose(1, 2), labels) / GRADIENT_ACCUMULATION\n","            loss.backward()\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), int(1e2))\n","            optimizer.step()\n","            optimizer.zero_grad()\n","        running_loss += loss.item()\n","        final = softmax(logits)[..., 1:-1]\n","        final = final.argmax(dim=-1) + 1\n","        pred_num = (labels != PAD_TOKEN_ID).sum(dim=-1)\n","        correct_num = ((labels != PAD_TOKEN_ID) * (final == labels)).sum(dim=-1)\n","        cum_acc += torch.true_divide(correct_num, pred_num).mean().item()\n","    epoch_loss = running_loss / index\n","    epoch_acc = 100 * cum_acc / index\n","    print(f'    ==  Epoch: {epoch} | Training Loss: {epoch_loss:.6f} | Accuracy: {epoch_acc:6.4f}%  ==')\n","    Writer.add_scalar('Training loss', epoch_loss, epoch)\n","    Writer.add_scalar('Training accuracy',epoch_acc, epoch)\n","\n","    if epoch % VALIDATE_EVERY == 0:\n","        model.eval()\n","        running_loss = 0.0\n","        predictions = []\n","        truths = []\n","        with torch.no_grad():\n","            for index, data in tqdm(enumerate(val_loader)):\n","                index += 1\n","                data = data.to(device)\n","                data, labels = data_mask(data)\n","                logits = model(data)\n","                loss = loss_fn(logits.transpose(1, 2), labels)\n","                running_loss += loss.item()\n","                softmax = nn.Softmax(dim=-1)\n","                final = softmax(logits)[..., 1:-1]\n","                final = final.argmax(dim=-1) + 1\n","                predictions.append(final)\n","                truths.append(labels)\n","        val_loss = running_loss / index\n","        correct_num = ((torch.cat(truths, dim=0) != PAD_TOKEN_ID) * (torch.cat(predictions, dim=0) == torch.cat(truths, dim=0))).sum().item()\n","        val_num = (torch.cat(truths, dim=0) != PAD_TOKEN_ID).sum().item()\n","        val_acc = 100 * correct_num / val_num\n","        print(f'    ==  Epoch: {epoch} | Validation Loss: {val_loss:.6f} | Accuracy: {val_acc:6.4f}%  ==')\n","        Writer.add_scalar('Valid loss', val_loss, epoch)\n","        Writer.add_scalar('Valid accuracy',val_acc, epoch)\n","\n","    # save_ckpt(i, model, optimizerepoch_loss, model_name, ckpt_dir)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_9bfv1VTXMlu"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}