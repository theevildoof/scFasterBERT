{"cells":[{"cell_type":"markdown","metadata":{"id":"cyJkiTPbRpb-"},"source":["# This is an upgraded version of the scBERT\n","\n","## We are planning to incorporate these things:\n","\n","### Improvements to the Encoder block\n","1. Grouped Multi Query Attention\n","2. RMS Norm in place of LayerNorm for faster training\n","3. Flash attention 2.0\n","4. SwiGLU/SiLU in place of ReLU/GLU - done\n","5. Gene coexpression\n","\n","### Improvements to improve parameter count while reducing computational cost\n","1. Mixtral of Experts\n","\n","### Improvements to training stratergy\n","2. Improved Token Embeddings\n","1. Improved masking\n","\n","### For Faster training\n","1. Mixed precision training - done\n","2. Distributed Data Parallel Training - done\n","3. Faster Data Loading using MultDL\n","4. Adafactor - https://huggingface.co/docs/transformers/main/en/perf_train_gpu_one#optimizer-choice\n","5. Torch compile - https://huggingface.co/docs/transformers/main/en/perf_train_gpu_one#using-torchcompile\n","6. Data preloading - done"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":104866,"status":"ok","timestamp":1715790645801,"user":{"displayName":"Vishwa","userId":"12540788039158208250"},"user_tz":-330},"id":"rfWT4jWk5PLz","outputId":"0aec1421-39fe-439f-8af8-6117745de028"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":75268,"status":"ok","timestamp":1715790721065,"user":{"displayName":"Vishwa","userId":"12540788039158208250"},"user_tz":-330},"id":"4ozGzNvj39E5","outputId":"9950efeb-34bb-4fd6-a5ee-7edbba5fd290"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting mixture_of_experts\n","  Downloading mixture_of_experts-0.2.3-py3-none-any.whl (6.0 kB)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from mixture_of_experts) (2.2.1+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->mixture_of_experts) (3.14.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->mixture_of_experts) (4.11.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->mixture_of_experts) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->mixture_of_experts) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->mixture_of_experts) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->mixture_of_experts) (2023.6.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->mixture_of_experts)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->mixture_of_experts)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->mixture_of_experts)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->mixture_of_experts)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->mixture_of_experts)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->mixture_of_experts)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch->mixture_of_experts)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->mixture_of_experts)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->mixture_of_experts)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.19.3 (from torch->mixture_of_experts)\n","  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch->mixture_of_experts)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->mixture_of_experts) (2.2.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->mixture_of_experts)\n","  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->mixture_of_experts) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->mixture_of_experts) (1.3.0)\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, mixture_of_experts\n","Successfully installed mixture_of_experts-0.2.3 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105\n","Collecting scanpy\n","  Downloading scanpy-1.10.1-py3-none-any.whl (2.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting anndata>=0.8 (from scanpy)\n","  Downloading anndata-0.10.7-py3-none-any.whl (122 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.4/122.4 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: h5py>=3.1 in /usr/local/lib/python3.10/dist-packages (from scanpy) (3.9.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from scanpy) (1.4.2)\n","Collecting legacy-api-wrap>=1.4 (from scanpy)\n","  Downloading legacy_api_wrap-1.4-py3-none-any.whl (15 kB)\n","Requirement already satisfied: matplotlib>=3.6 in /usr/local/lib/python3.10/dist-packages (from scanpy) (3.7.1)\n","Requirement already satisfied: natsort in /usr/local/lib/python3.10/dist-packages (from scanpy) (8.4.0)\n","Requirement already satisfied: networkx>=2.7 in /usr/local/lib/python3.10/dist-packages (from scanpy) (3.3)\n","Requirement already satisfied: numba>=0.56 in /usr/local/lib/python3.10/dist-packages (from scanpy) (0.58.1)\n","Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.10/dist-packages (from scanpy) (1.25.2)\n","Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from scanpy) (24.0)\n","Requirement already satisfied: pandas>=1.5 in /usr/local/lib/python3.10/dist-packages (from scanpy) (2.0.3)\n","Requirement already satisfied: patsy in /usr/local/lib/python3.10/dist-packages (from scanpy) (0.5.6)\n","Collecting pynndescent>=0.5 (from scanpy)\n","  Downloading pynndescent-0.5.12-py3-none-any.whl (56 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scikit-learn>=0.24 in /usr/local/lib/python3.10/dist-packages (from scanpy) (1.2.2)\n","Requirement already satisfied: scipy>=1.8 in /usr/local/lib/python3.10/dist-packages (from scanpy) (1.11.4)\n","Requirement already satisfied: seaborn>=0.13 in /usr/local/lib/python3.10/dist-packages (from scanpy) (0.13.1)\n","Collecting session-info (from scanpy)\n","  Downloading session_info-1.0.0.tar.gz (24 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: statsmodels>=0.13 in /usr/local/lib/python3.10/dist-packages (from scanpy) (0.14.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from scanpy) (4.66.4)\n","Collecting umap-learn!=0.5.0,>=0.5 (from scanpy)\n","  Downloading umap_learn-0.5.6-py3-none-any.whl (85 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.7/85.7 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting array-api-compat!=1.5,>1.4 (from anndata>=0.8->scanpy)\n","  Downloading array_api_compat-1.6-py3-none-any.whl (36 kB)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anndata>=0.8->scanpy) (1.2.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->scanpy) (1.2.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->scanpy) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->scanpy) (4.51.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->scanpy) (1.4.5)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->scanpy) (9.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->scanpy) (3.1.2)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->scanpy) (2.8.2)\n","Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.56->scanpy) (0.41.1)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.5->scanpy) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.5->scanpy) (2024.1)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24->scanpy) (3.5.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy->scanpy) (1.16.0)\n","Collecting stdlib_list (from session-info->scanpy)\n","  Downloading stdlib_list-0.10.0-py3-none-any.whl (79 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: session-info\n","  Building wheel for session-info (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for session-info: filename=session_info-1.0.0-py3-none-any.whl size=8026 sha256=2205c306a688adf02e9f0105272f71e119b2bc54d28fae0b84d5327afed1f73c\n","  Stored in directory: /root/.cache/pip/wheels/6a/aa/b9/eb5d4031476ec10802795b97ccf937b9bd998d68a9b268765a\n","Successfully built session-info\n","Installing collected packages: array-api-compat, stdlib_list, legacy-api-wrap, session-info, pynndescent, anndata, umap-learn, scanpy\n","Successfully installed anndata-0.10.7 array-api-compat-1.6 legacy-api-wrap-1.4 pynndescent-0.5.12 scanpy-1.10.1 session-info-1.0.0 stdlib_list-0.10.0 umap-learn-0.5.6\n","Collecting accelerate\n","  Downloading accelerate-0.30.1-py3-none-any.whl (302 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.6/302.6 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n","Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.2.1+cu121)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.20.3)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.14.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.11.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.19.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n","Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.2.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.4.127)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.4)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n","Installing collected packages: accelerate\n","Successfully installed accelerate-0.30.1\n"]}],"source":["%pip install mixture_of_experts\n","%pip install scanpy\n","%pip install accelerate"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"cwLyKQLr4J_0","executionInfo":{"status":"ok","timestamp":1715790730135,"user_tz":-330,"elapsed":9078,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}}},"outputs":[],"source":["import scanpy as sc\n","from sklearn.model_selection import train_test_split\n","import torch\n","import numpy as np\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from mixture_of_experts import MoE\n","from torchsummary import summary\n","from torch.utils.data import Dataset, DataLoader\n","import random\n","from tqdm import tqdm\n","from functools import reduce\n","from torch.optim import AdamW\n","import math\n","import matplotlib.pyplot as plt\n","from accelerate import Accelerator\n","import pickle as pkl\n","from sklearn.model_selection import train_test_split, ShuffleSplit, StratifiedShuffleSplit, StratifiedKFold\n","import pandas as pd"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"pH3xJ3i3G08h","executionInfo":{"status":"ok","timestamp":1715790730136,"user_tz":-330,"elapsed":11,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}}},"outputs":[],"source":["accelerator = Accelerator(mixed_precision='fp16')"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"RefixN0a4MzJ","executionInfo":{"status":"ok","timestamp":1715790730136,"user_tz":-330,"elapsed":11,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}}},"outputs":[],"source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"_oE9DHqe4PqM","executionInfo":{"status":"ok","timestamp":1715790730136,"user_tz":-330,"elapsed":10,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}}},"outputs":[],"source":["torch.backends.cuda.enable_flash_sdp(True)"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"BBkF9In54QqA","executionInfo":{"status":"ok","timestamp":1715790730136,"user_tz":-330,"elapsed":10,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}}},"outputs":[],"source":["class FlashAttentionBlock(nn.Module):\n","    def __init__(self, d_model: int, h: int) -> None:\n","        super().__init__()\n","        self.d_model = d_model\n","        self.h = h\n","        assert d_model % h ==0, \"d_model is not divisble by h\"\n","        self.d_k = d_model // h\n","\n","        self.w_q = nn.Linear(d_model, d_model)\n","        self.w_k = nn.Linear(d_model, d_model)\n","        self.w_v = nn.Linear(d_model, d_model)\n","        self.w_o = nn.Linear(d_model, d_model)\n","\n","\n","    def forward(self, q, k, v):\n","        query = self.w_q (q) # (batch, seq_len, d_model) -> (batch, seq_len, d_model)\n","        key = self.w_k(k) # (batch, seq_len, d_model) -> (batch, seq_len, d_model)\n","        value = self.w_v(v) # (batch, seq_len, d_model) -> (batch, seq_len, d_model)\n","\n","        # Test code\n","        # query = q\n","        # key = k\n","        # value = v\n","\n","        # (batch, seq_len, d_model) -> (Batch, seq_len, h, d_k) -> (Batch, h, seq_len, d_k)\n","        query = query.view(query.shape[0], query.shape[1], self.h, self.d_k).transpose(1,2)\n","        key = key.view(key.shape[0], key.shape[1], self.h, self.d_k).transpose(1,2)\n","        value = value.view(value.shape[0], value.shape[1], self.h, self.d_k).transpose(1,2)\n","\n","        x = F.scaled_dot_product_attention(query,key,value, dropout_p=0.1)\n","\n","        # (Batch, h, seq_len, d_k) -> (Batch, seq_len, h, d_k) -> (Batch, seq_len, d_model)\n","        x =  x.transpose(1, 2).contiguous().view(x.shape[0], -1, self.h * self.d_k)\n","\n","        # (Batch, seq_len, d_model)  -> (Batch, seq_len, d_model)\n","        return self.w_o(x)"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"D0m_TQXc4RuW","executionInfo":{"status":"ok","timestamp":1715790730136,"user_tz":-330,"elapsed":10,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}}},"outputs":[],"source":["class RMSNorm(torch.nn.Module):\n","    def __init__(self, dim: int, eps: float = 1e-6):\n","        super().__init__()\n","        self.eps = eps\n","        self.weight = nn.Parameter(torch.ones(dim))\n","\n","    def _norm(self, x):\n","        return x * torch.rsqrt(x.pow(2).mean(-1, keepdim=True) + self.eps)\n","\n","    def forward(self, x):\n","        output = self._norm(x.float()).type_as(x)\n","        return output * self.weight"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"YP35shDE4Txm","executionInfo":{"status":"ok","timestamp":1715790730136,"user_tz":-330,"elapsed":9,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}}},"outputs":[],"source":["moe = MoE(\n","    dim = 200,\n","    num_experts =  4,               # increase the experts (# parameters) of your model without increasing computation\n","    hidden_dim = 200 * 4,           # size of hidden dimension in each expert, defaults to 4 * dimension\n","    activation = nn.SiLU,      # use your preferred activation, will default to GELU\n","    second_policy_train = 'random', # in top_2 gating, policy for whether to use a second-place expert\n","    second_policy_eval = 'random',  # all (always) | none (never) | threshold (if gate value > the given threshold) | random (if gate value > threshold * random_uniform(0, 1))\n","    second_threshold_train = 0.2,\n","    second_threshold_eval = 0.2,\n","    capacity_factor_train = 1.25,   # experts have fixed capacity per batch. we need some extra capacity in case gating is not perfectly balanced.\n","    capacity_factor_eval = 2.,      # capacity_factor_* should be set to a value >=1\n","    loss_coef = 1e-2                # multiplier on the auxiliary expert balancing auxiliary loss\n",")"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"RRekhvRm4WMi","executionInfo":{"status":"ok","timestamp":1715790730136,"user_tz":-330,"elapsed":9,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}}},"outputs":[],"source":["class Encoder(nn.Module):\n","  def __init__(self, local_heads, d_model, hidden_ff_model):\n","    super().__init__()\n","    # Embedding dimension = 200, Local_Attention heads = 10\n","    self.attention = FlashAttentionBlock(d_model= d_model, h=local_heads)\n","    self.attention_norm = RMSNorm(dim =d_model)\n","    self.ff_norm = RMSNorm(dim=d_model)\n","    self.feed_forward = MoE(dim =d_model, num_experts=8, hidden_dim= hidden_ff_model,activation = nn.SiLU, second_policy_train = 'random', second_policy_eval = 'random', second_threshold_train = 0.2, second_threshold_eval = 0.2, capacity_factor_train = 1.25,capacity_factor_eval = 2., loss_coef = 1e-2)\n","\n","\n","  def forward(self, x):\n","    x_normed = self.attention_norm(x)\n","    # print(x_normed.shape)\n","    r = self.attention(x_normed, x_normed, x_normed)\n","    h = x + r\n","    r, _ = self.feed_forward(self.ff_norm(h))\n","    out = h + r\n","    return out"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"eujUIx5t4X5Z","executionInfo":{"status":"ok","timestamp":1715790730136,"user_tz":-330,"elapsed":9,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}}},"outputs":[],"source":["class Gene2VecPositionalEmbedding(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        gene2vec_weight = np.load('/content/drive/MyDrive/scFasterBERT/data/gene2vec_16906.npy')\n","        gene2vec_weight = np.concatenate((gene2vec_weight, np.zeros((1, gene2vec_weight.shape[1]))), axis=0)\n","        gene2vec_weight = torch.from_numpy(gene2vec_weight)\n","        self.emb = nn.Embedding.from_pretrained(gene2vec_weight)\n","\n","    def forward(self, x):\n","        t = torch.arange(x.shape[1], device = device)\n","        return self.emb(t)"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"SPqtFB0w4ZJN","executionInfo":{"status":"ok","timestamp":1715790730136,"user_tz":-330,"elapsed":9,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}}},"outputs":[],"source":["#max_seq_len =16907\n","class scBERT2(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.token_emb = nn.Embedding(7, 200)\n","        self.pos_emb = Gene2VecPositionalEmbedding()\n","        self.layer1 = Encoder(local_heads=10,d_model=200, hidden_ff_model=400)\n","        self.layer2 = Encoder(local_heads=10,d_model=200, hidden_ff_model=400)\n","        self.layer3 = Encoder(local_heads=10,d_model=200, hidden_ff_model=400)\n","        self.layer4 = Encoder(local_heads=10,d_model=200, hidden_ff_model=400)\n","        self.layer5 = Encoder(local_heads=10,d_model=200, hidden_ff_model=400)\n","        self.layer6 = Encoder(local_heads=10,d_model=200, hidden_ff_model=400)\n","        self.norm = RMSNorm(200)\n","        self.classifier = nn.Linear(in_features=200, out_features=7)\n","\n","    def forward(self, x):\n","    # x = x.type(torch.int32)\n","        pos_emb = self.pos_emb(x)\n","        x = self.token_emb(x.int())\n","        # print(x.shape)\n","        x += pos_emb\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","        x = self.layer4(x)\n","        x = self.layer5(x)\n","        x = self.layer6(x)\n","        x = self.classifier(self.norm(x))\n","        return x"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"t-SYLX5b4a76","executionInfo":{"status":"ok","timestamp":1715790734332,"user_tz":-330,"elapsed":4205,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}}},"outputs":[],"source":["scbert = scBERT2()"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1715790734333,"user":{"displayName":"Vishwa","userId":"12540788039158208250"},"user_tz":-330},"id":"L_Dy8JMF4bfU","outputId":"33f58566-7e4d-493f-852e-2272c91e10c9"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["8659807"]},"metadata":{},"execution_count":14}],"source":["sum(p.numel() for p in scbert.parameters() if p.requires_grad)"]},{"cell_type":"code","source":["scbert.load_state_dict(torch.load('/content/drive/MyDrive/scFasterBERT/Final_models/scbert2_epoch1.pth'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vRRXEe5jg1xk","executionInfo":{"status":"ok","timestamp":1715790739328,"user_tz":-330,"elapsed":4998,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}},"outputId":"6b2b33fb-a453-4b66-f3c8-42776c78b90f"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["class Identity(torch.nn.Module):\n","    def __init__(self, dropout = 0., h_dim = 100, out_dim = 10):\n","        super(Identity, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 1, (1, 200))\n","        self.act = nn.ReLU()\n","        self.fc1 = nn.Linear(in_features=SEQ_LEN, out_features=512, bias=True)\n","        self.act1 = nn.ReLU()\n","        self.dropout1 = nn.Dropout(dropout)\n","        self.fc2 = nn.Linear(in_features=512, out_features=h_dim, bias=True)\n","        self.act2 = nn.ReLU()\n","        self.dropout2 = nn.Dropout(dropout)\n","        self.fc3 = nn.Linear(in_features=h_dim, out_features=out_dim, bias=True)\n","\n","    def forward(self, x):\n","        x = x[:,None,:,:]\n","        x = self.conv1(x)\n","        x = self.act(x)\n","        x = x.view(x.shape[0],-1)\n","        x = self.fc1(x)\n","        x = self.act1(x)\n","        x = self.dropout1(x)\n","        x = self.fc2(x)\n","        x = self.act2(x)\n","        x = self.dropout2(x)\n","        x = self.fc3(x)\n","        return x"],"metadata":{"id":"iZ9CSmZwhVZa","executionInfo":{"status":"ok","timestamp":1715790739328,"user_tz":-330,"elapsed":4,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}}},"execution_count":16,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3TtEj_Pp4prU"},"source":["# Training"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"bJoNKp634oGg","executionInfo":{"status":"ok","timestamp":1715790739328,"user_tz":-330,"elapsed":3,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}}},"outputs":[],"source":["SEED = 2021\n","EPOCHS = 10\n","BATCH_SIZE = 1\n","LEARNING_RATE = 1e-4\n","GRADIENT_ACCUMULATION = 60\n","SEQ_LEN = 16907\n","VALIDATE_EVERY = 1\n","CLASS = 7\n","MASK_PROB = 0.15\n","REPLACE_PROB = 0.9\n","RANDOM_TOKEN_PROB = 0.\n","MASK_TOKEN_ID = CLASS - 1\n","PAD_TOKEN_ID = CLASS - 1\n","MASK_IGNORE_TOKEN_IDS = [0]\n","POS_EMBED_USING = True"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"hK_Vi9i04tqG","executionInfo":{"status":"ok","timestamp":1715790739328,"user_tz":-330,"elapsed":3,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}}},"outputs":[],"source":["class SCDataset(Dataset):\n","    def __init__(self, data, label):\n","        super().__init__()\n","        self.data = data\n","        self.label = label\n","\n","    def __getitem__(self, index):\n","        rand_start = random.randint(0, self.data.shape[0]-1)\n","        full_seq = self.data[rand_start].toarray()[0]\n","        full_seq[full_seq > (CLASS - 2)] = CLASS - 2\n","        full_seq = torch.from_numpy(full_seq).long()\n","        full_seq = torch.cat((full_seq, torch.tensor([0]))).to(device)\n","        seq_label = self.label[rand_start]\n","        return full_seq, seq_label\n","\n","    def __len__(self):\n","        return self.data.shape[0]\n"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":4342,"status":"ok","timestamp":1715790744629,"user":{"displayName":"Vishwa","userId":"12540788039158208250"},"user_tz":-330},"id":"XatEzl_p4uUu"},"outputs":[],"source":["data = sc.read_h5ad('/content/drive/MyDrive/scFasterBERT/Final_models/preprocessed_data.h5ad')\n","label_dict, label = np.unique(np.array(data.obs['celltype']), return_inverse=True)\n","with open('label_dict', 'wb') as fp:\n","    pkl.dump(label_dict, fp)\n","with open('label', 'wb') as fp:\n","    pkl.dump(label, fp)\n","class_num = np.unique(label, return_counts=True)[1].tolist()\n","class_weight = torch.tensor([(1 - (x / sum(class_num))) ** 2 for x in class_num])\n","data = data.X\n","\n","acc = []\n","f1 = []\n","f1w = []\n","skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n","pred_list = pd.Series(['un'] * data.shape[0])\n","\n","sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=SEED)\n","\n","for index_train, index_val in sss.split(data, label):\n","   data_train, label_train = data[index_train], label[index_train]\n","   data_val, label_val = data[index_val], label[index_val]\n","   train_dataset = SCDataset(data_train, label_train)\n","   val_dataset = SCDataset(data_val, label_val)\n","\n"]},{"cell_type":"code","source":["for params in scbert.parameters():\n","  params.requires_grad=False"],"metadata":{"id":"T1p4cjSXiErU","executionInfo":{"status":"ok","timestamp":1715790744629,"user_tz":-330,"elapsed":47,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["scbert.classifier = Identity(dropout=0., h_dim=128, out_dim=label_dict.shape[0])\n","scbert = scbert.to(device)"],"metadata":{"id":"t4M4qgAbiMyv","executionInfo":{"status":"ok","timestamp":1715790744629,"user_tz":-330,"elapsed":44,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","execution_count":22,"metadata":{"id":"xUZ65Pho4yol","executionInfo":{"status":"ok","timestamp":1715790744629,"user_tz":-330,"elapsed":43,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}}},"outputs":[],"source":["optimizer = AdamW(scbert.parameters(), lr=LEARNING_RATE)\n","loss_fn = nn.CrossEntropyLoss(ignore_index = PAD_TOKEN_ID, reduction='mean').to(device)\n","softmax = nn.Softmax(dim=-1)\n","scaler = torch.cuda.amp.GradScaler()"]},{"cell_type":"code","source":["for i in range(1, EPOCHS+1):\n","    train_loader.set_epoch(i)\n","    model.train()\n","    running_loss = 0.0\n","    cum_acc = 0.0\n","    for index, (data, labels) in enumerate(train_loader):\n","        index += 1\n","        data, labels = data.to(device), labels.to(device)\n","        if index % GRADIENT_ACCUMULATION != 0:\n","            with model.no_sync():\n","                logits = model(data)\n","                loss = loss_fn(logits, labels)\n","                loss.backward()\n","        if index % GRADIENT_ACCUMULATION == 0:\n","            logits = model(data)\n","            loss = loss_fn(logits, labels)\n","            loss.backward()\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), int(1e6))\n","            optimizer.step()\n","            optimizer.zero_grad()\n","        running_loss += loss.item()\n","        softmax = nn.Softmax(dim=-1)\n","        final = softmax(logits)\n","        final = final.argmax(dim=-1)\n","        pred_num = labels.size(0)\n","        correct_num = torch.eq(final, labels).sum(dim=-1)\n","        cum_acc += torch.true_divide(correct_num, pred_num).mean().item()\n","    epoch_loss = running_loss / index\n","    epoch_acc = 100 * cum_acc / index\n","    epoch_loss = get_reduced(epoch_loss, local_rank, 0, world_size)\n","    epoch_acc = get_reduced(epoch_acc, local_rank, 0, world_size)\n","    if is_master:\n","        print(f'    ==  Epoch: {i} | Training Loss: {epoch_loss:.6f} | Accuracy: {epoch_acc:6.4f}%  ==')\n","    dist.barrier()\n","    scheduler.step()\n","\n","    if i % VALIDATE_EVERY == 0:\n","        model.eval()\n","        dist.barrier()\n","        running_loss = 0.0\n","        predictions = []\n","        truths = []\n","        with torch.no_grad():\n","            for index, (data_v, labels_v) in enumerate(val_loader):\n","                index += 1\n","                data_v, labels_v = data_v.to(device), labels_v.to(device)\n","                logits = model(data_v)\n","                loss = loss_fn(logits, labels_v)\n","                running_loss += loss.item()\n","                softmax = nn.Softmax(dim=-1)\n","                final_prob = softmax(logits)\n","                final = final_prob.argmax(dim=-1)\n","                final[np.amax(np.array(final_prob.cpu()), axis=-1) < UNASSIGN_THRES] = -1\n","                predictions.append(final)\n","                truths.append(labels_v)\n","            del data_v, labels_v, logits, final_prob, final\n","            # gather\n","            predictions = torch.cat(predictions, dim=0)\n","            truths = torch.cat(truths, dim=0)\n","            no_drop = predictions != -1\n","            predictions = np.array((predictions[no_drop]).cpu())\n","            truths = np.array((truths[no_drop]).cpu())\n","            cur_acc = accuracy_score(truths, predictions)\n","            f1 = f1_score(truths, predictions, average='macro')\n","            val_loss = running_loss / index\n","            val_loss = get_reduced(val_loss, local_rank, 0, world_size)\n","            if is_master:\n","                print(f'    ==  Epoch: {i} | Validation Loss: {val_loss:.6f} | F1 Score: {f1:.6f}  ==')\n","                print(confusion_matrix(truths, predictions))\n","                print(classification_report(truths, predictions, target_names=label_dict.tolist(), digits=4))\n","            if cur_acc > max_acc:\n","                max_acc = cur_acc\n","                trigger_times = 0\n","                save_best_ckpt(i, model, optimizer, scheduler, val_loss, model_name, ckpt_dir)\n","            else:\n","                trigger_times += 1\n","                if trigger_times > PATIENCE:\n","                    break\n","    del predictions, truths"],"metadata":{"id":"HI1Y3T-ijSLD","colab":{"base_uri":"https://localhost:8080/","height":211},"executionInfo":{"status":"error","timestamp":1715790744629,"user_tz":-330,"elapsed":42,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}},"outputId":"a3eb1e0d-f0a8-4a01-a5d4-3e629fbd97df"},"execution_count":23,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'train_loader' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-23-b184043b7ce4>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mcum_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'train_loader' is not defined"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HBXucvQjF6gD","executionInfo":{"status":"aborted","timestamp":1715790744630,"user_tz":-330,"elapsed":24,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}}},"outputs":[],"source":["def train2(model):\n","  softmax = nn.Softmax(dim=-1)\n","  train_losses =[]\n","  train_accuracies = []\n","  valid_losses =[]\n","  valid_accuracies = []\n","  for i in range(1, EPOCHS+1):\n","      model.train()\n","      running_loss = 0.0\n","      cum_acc = 0.0\n","      for index, data in enumerate(tqdm(train_loader)):\n","          index += 1\n","          data = data.to(device)\n","          data, labels = data_mask(data)\n","          logits = model(data)\n","          loss = loss_fn(logits.transpose(1, 2), labels)/ GRADIENT_ACCUMULATION\n","          accelerator.backward(loss)\n","          if index % GRADIENT_ACCUMULATION == 0:\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), int(1e2))\n","            optimizer.step()\n","            optimizer.zero_grad()\n","          running_loss += loss.item()\n","          final = softmax(logits)[..., 1:-1]\n","          final = final.argmax(dim=-1) + 1\n","          pred_num = (labels != PAD_TOKEN_ID).sum(dim=-1)\n","          correct_num = ((labels != PAD_TOKEN_ID) * (final == labels)).sum(dim=-1)\n","          cum_acc += torch.true_divide(correct_num, pred_num).mean().item()\n","      epoch_loss = running_loss / index\n","      epoch_acc = 100 * cum_acc / index\n","      train_losses.append(epoch_loss)\n","      train_accuracies.append(epoch_acc)\n","      print(f'    ==  Epoch: {i} | Training Loss: {epoch_loss:.6f} | Accuracy: {epoch_acc:6.4f}%  ==')\n","\n","      if i % VALIDATE_EVERY == 0:\n","          model.eval()\n","          running_loss = 0.0\n","          predictions = []\n","          truths = []\n","          with torch.no_grad():\n","              for index, data in enumerate(tqdm(val_loader)):\n","                  index += 1\n","                  data = data.to(device)\n","                  data, labels = data_mask(data)\n","                  logits = model(data)\n","                  loss = loss_fn(logits.transpose(1, 2), labels)\n","                  running_loss += loss.item()\n","                  softmax = nn.Softmax(dim=-1)\n","                  final = softmax(logits)[..., 1:-1]\n","                  final = final.argmax(dim=-1) + 1\n","                  predictions.append(final)\n","                  truths.append(labels)\n","          val_loss = running_loss / index\n","          correct_num = ((torch.cat(truths, dim=0) != PAD_TOKEN_ID) * (torch.cat(predictions, dim=0) == torch.cat(truths, dim=0))).sum().item()\n","          val_num = (torch.cat(truths, dim=0) != PAD_TOKEN_ID).sum().item()\n","          val_acc = 100 * correct_num / val_num\n","          valid_losses.append(val_loss)\n","          valid_accuracies.append(val_acc)\n","          print(f'    ==  Epoch: {i} | Validation Loss: {val_loss:.6f} | Accuracy: {val_acc:6.4f}%  ==')\n","      torch.save(model.state_dict(), f'scbert2_epoch{i}.pth')\n","\n","  return train_losses, train_accuracies, valid_losses, valid_accuracies"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bRoz2AWiHf4e","executionInfo":{"status":"aborted","timestamp":1715790744630,"user_tz":-330,"elapsed":23,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}}},"outputs":[],"source":["train_losses, train_accuracies, valid_losses, valid_accuracies = train2(scbert)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R09VwupeCeut","executionInfo":{"status":"aborted","timestamp":1715790744630,"user_tz":-330,"elapsed":23,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}}},"outputs":[],"source":["def plot_graphs(train_losses, train_accuracies, valid_losses, valid_accuracies):\n","  plt.plot(train_losses)\n","  plt.plot(train_accuracies)\n","  plt.plot(valid_losses)\n","  plt.plot(valid_accuracies)\n","  plt.legend(['train_loss', 'train_accuracy', 'valid_loss', 'valid_accuracy'])\n","  plt.title('Panglao_human')\n","  plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_gG9AmRcDWyt","executionInfo":{"status":"aborted","timestamp":1715790744630,"user_tz":-330,"elapsed":23,"user":{"displayName":"Vishwa","userId":"12540788039158208250"}}},"outputs":[],"source":["plot_graphs(train2.train_losses, train2.train_accuracies, train2.valid_losses, train2.valid_accuracies)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"}},"nbformat":4,"nbformat_minor":0}